# ğŸ”Œ IntÃ©gration MCP (Model Context Protocol)

## ğŸ“‹ Vue d'Ensemble

My Personal AI intÃ¨gre dÃ©sormais le **Model Context Protocol (MCP)**, un standard ouvert qui permet aux modÃ¨les d'IA (comme Ollama) d'interagir de maniÃ¨re sÃ©curisÃ©e et standardisÃ©e avec des outils locaux et des sources de donnÃ©es externes.

GrÃ¢ce Ã  cette intÃ©gration, l'IA n'est plus limitÃ©e Ã  ses connaissances internes ou Ã  la recherche web basique. Elle peut dÃ©sormais :
- Lire et Ã©crire dans votre systÃ¨me de fichiers local.
- Interagir avec des bases de donnÃ©es (SQLite, etc.).
- ExÃ©cuter des commandes Git.
- Utiliser n'importe quel serveur MCP compatible.

## ğŸ—ï¸ Architecture MCP dans My AI

L'intÃ©gration repose sur le module `core/mcp_client.py` qui agit comme un pont entre Ollama et les outils/serveurs MCP.

### 1. Outils Locaux (LocalTools)
Ce sont des fonctions Python exÃ©cutÃ©es directement dans le processus de l'application. Elles encapsulent les capacitÃ©s existantes de My AI (comme la recherche web, l'analyse de fichiers, etc.) au format standardisÃ© MCP pour qu'Ollama puisse les appeler de maniÃ¨re autonome.

### 2. Serveurs MCP Externes (MCPServers)
My AI peut se connecter Ã  des serveurs MCP externes via le transport `stdio`. Cela permet d'Ã©tendre les capacitÃ©s de l'IA de maniÃ¨re infinie en utilisant l'Ã©cosystÃ¨me grandissant des serveurs MCP (ex: serveurs pour GitHub, Slack, bases de donnÃ©es d'entreprise, etc.).

## ğŸš€ Comment Ã§a marche ?

1. **DÃ©couverte** : Au dÃ©marrage, le `mcp_client` recense tous les outils locaux disponibles et se connecte aux serveurs MCP externes configurÃ©s pour rÃ©cupÃ©rer leurs outils.
2. **Exposition** : Tous ces outils sont convertis au format JSON Schema attendu par l'API d'Ollama.
3. **DÃ©cision** : Lors d'une requÃªte utilisateur, la liste des outils est envoyÃ©e Ã  Ollama avec le prompt. Ollama dÃ©cide intelligemment s'il a besoin d'utiliser un outil pour rÃ©pondre.
4. **ExÃ©cution** : Si Ollama dÃ©cide d'utiliser un outil, le `mcp_client` intercepte l'appel, exÃ©cute l'outil local ou transfÃ¨re la requÃªte au serveur MCP externe, puis renvoie le rÃ©sultat Ã  Ollama.
5. **SynthÃ¨se** : Ollama utilise le rÃ©sultat de l'outil pour formuler sa rÃ©ponse finale Ã  l'utilisateur.

## âš™ï¸ Configuration

*(Ã€ venir : La configuration des serveurs MCP externes se fera via le fichier `config.yaml` ou une interface dÃ©diÃ©e).*

## ğŸ› ï¸ DÃ©pendances

L'intÃ©gration MCP utilise le SDK officiel `mcp` pour Python.
Si le SDK n'est pas installÃ©, My AI gÃ¨re la situation de maniÃ¨re gracieuse (dÃ©gradation gracieuse) et continue de fonctionner avec ses capacitÃ©s de base.

Pour installer le SDK MCP :
```bash
pip install mcp
```

## ğŸŒŸ Avantages

- **Autonomie** : L'IA dÃ©cide elle-mÃªme quand et comment utiliser les outils.
- **ExtensibilitÃ©** : Ajout facile de nouvelles capacitÃ©s via des serveurs MCP standards.
- **Standardisation** : Utilisation d'un protocole ouvert adoptÃ© par l'industrie (Anthropic, etc.).
