# ğŸš€ Guide d'Utilisation - FonctionnalitÃ©s AvancÃ©es

Ce guide explique comment utiliser les 3 nouvelles fonctionnalitÃ©s majeures :

## ğŸ“š Table des MatiÃ¨res

1. [RLHF Manager](#rlhf-manager)
2. [Training Manager](#training-manager)
3. [Compression Monitor](#compression-monitor)

---

## ğŸ¤– RLHF Manager

Le **RLHF Manager** collecte automatiquement le feedback utilisateur et amÃ©liore le modÃ¨le de maniÃ¨re continue.

### âœ¨ FonctionnalitÃ©s

- âœ… Collecte automatique du feedback
- âœ… DÃ©tection des patterns de succÃ¨s/Ã©chec
- âœ… Apprentissage progressif
- âœ… Statistiques dÃ©taillÃ©es
- âœ… Export des donnÃ©es d'entraÃ®nement

### ğŸ’» Utilisation

```python
from core.rlhf_manager import get_rlhf_manager

# Obtenir l'instance singleton
rlhf = get_rlhf_manager()

# Enregistrer une interaction avec feedback
interaction_id = rlhf.record_interaction(
    user_query="Comment installer Python ?",
    ai_response="Pour installer Python...",
    feedback_type="positive",  # 'positive', 'negative', 'neutral'
    feedback_score=5,  # 0-5
    intent="technical_question",
    confidence=0.9,
    model_version="llama3.2"
)

# Obtenir les statistiques
stats = rlhf.get_statistics("session")  # 'session', 'today', 'all'
print(f"Satisfaction: {stats['satisfaction_score']:.2%}")

# Voir les patterns appris
patterns = rlhf.get_learned_patterns(min_confidence=0.7)
for pattern in patterns:
    print(f"{pattern['pattern_type']}: {pattern['confidence']:.2f}")

# Exporter pour entraÃ®nement
count = rlhf.export_training_data(
    "data/rlhf_training.jsonl",
    min_score=3
)
print(f"{count} exemples exportÃ©s")
```

### ğŸ“Š MÃ©triques Disponibles

- **Taux de satisfaction** : (positifs - nÃ©gatifs) / total
- **Taux de feedback positif** : positifs / total
- **Score moyen** : moyenne des scores 0-5
- **Patterns appris** : nombre de patterns dÃ©tectÃ©s
- **Confiance** : niveau de confiance des patterns

### ğŸ¯ IntÃ©gration dans votre code

```python
# Dans votre fonction de gÃ©nÃ©ration de rÃ©ponse
response = ai_engine.generate(user_query)

# Enregistrer automatiquement
rlhf.record_interaction(
    user_query=user_query,
    ai_response=response,
    feedback_type="neutral",  # Par dÃ©faut
    intent=detected_intent,
    confidence=confidence_score
)

# L'utilisateur peut donner un feedback explicite plus tard
# qui sera liÃ© Ã  cette interaction
```

---

## ğŸ“ Training Manager

Le **Training Manager** gÃ¨re l'entraÃ®nement et le fine-tuning des modÃ¨les locaux avec monitoring en temps rÃ©el.

### âœ¨ FonctionnalitÃ©s

- âœ… EntraÃ®nement de modÃ¨les personnalisÃ©s
- âœ… Fine-tuning pour Ollama
- âœ… Checkpointing automatique
- âœ… Validation et mÃ©triques
- âœ… Callbacks pour monitoring
- âœ… Export des rÃ©sultats

### ğŸ’» Utilisation - EntraÃ®nement Standard

```python
from core.training_manager import get_training_manager

# Obtenir l'instance
trainer = get_training_manager()

# PrÃ©parer les donnÃ©es
train_data = [
    {"input": "Question ?", "target": "RÃ©ponse..."},
    # ... plus de donnÃ©es
]

val_data = [
    {"input": "Question validation ?", "target": "RÃ©ponse..."},
    # ...
]

# CrÃ©er un run d'entraÃ®nement
run_id = trainer.create_run(
    run_name="my_model",
    config={"description": "Mon modÃ¨le personnalisÃ©"}
)

# Callback pour suivre la progression
def on_epoch_end(epoch, metrics):
    print(f"Ã‰poque {epoch + 1} - Loss: {metrics['train_loss']:.4f}")

# EntraÃ®ner
results = trainer.train_model(
    train_data=train_data,
    val_data=val_data,
    epochs=5,
    batch_size=8,
    learning_rate=1e-4,
    model_name="custom_assistant",
    save_every=1,
    validate_every=1,
    on_epoch_end=on_epoch_end
)

print(f"Loss finale: {results['final_loss']:.4f}")
```

### ğŸ’» Utilisation - Fine-tuning Ollama

```python
from core.training_manager import get_training_manager

trainer = get_training_manager()

# CrÃ©er un run
trainer.create_run(run_name="ollama_custom")

# DonnÃ©es de fine-tuning
train_data = [
    {"input": "Qui es-tu ?", "target": "Je suis My AI..."},
    {"input": "Que peux-tu faire ?", "target": "Je peux..."},
    # ... plus d'exemples
]

# PrÃ©parer le fine-tuning pour Ollama
result = trainer.fine_tune_ollama_model(
    base_model="llama3.2",
    train_data=train_data,
    new_model_name="my_ai_custom",
    epochs=5
)

print(f"Modelfile crÃ©Ã©: {result['modelfile_path']}")
print(f"Voir instructions: {result['instructions_path']}")

# Ensuite, dans le terminal:
# ollama create my_ai_custom -f chemin/vers/Modelfile
```

### ğŸ“Š MÃ©triques Suivies

- **Loss d'entraÃ®nement** : par Ã©poque et par batch
- **Loss de validation** : si donnÃ©es de validation fournies
- **Accuracy** : prÃ©cision sur le jeu de validation
- **DurÃ©e** : temps par Ã©poque
- **Checkpoints** : sauvegardÃ©s automatiquement

### ğŸ¯ Structure des Outputs

```
models/training_runs/
â””â”€â”€ my_model_20260211_143052/
    â”œâ”€â”€ config.json           # Configuration de l'entraÃ®nement
    â”œâ”€â”€ summary.json          # RÃ©sumÃ© des rÃ©sultats
    â”œâ”€â”€ metrics.jsonl         # MÃ©triques par Ã©poque
    â”œâ”€â”€ checkpoints/
    â”‚   â”œâ”€â”€ checkpoint_epoch_1/
    â”‚   â”œâ”€â”€ checkpoint_epoch_2/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ INSTRUCTIONS.txt      # (pour Ollama)
```

---

## ğŸ“Š Compression Monitor

Le **Compression Monitor** analyse et expose les mÃ©triques de compression intelligente du systÃ¨me.

### âœ¨ FonctionnalitÃ©s

- âœ… Calcul des ratios de compression rÃ©els
- âœ… Analyse par type de contenu
- âœ… MÃ©triques d'efficacitÃ©
- âœ… Score de qualitÃ©
- âœ… Rapports dÃ©taillÃ©s
- âœ… Historique des compressions

### ğŸ’» Utilisation Directe

```python
from core.compression_monitor import get_compression_monitor

# Obtenir l'instance
monitor = get_compression_monitor()

# Analyser une compression
original_text = "Mon texte original trÃ¨s long..."
chunks = ["chunk 1...", "chunk 2...", "chunk 3..."]

analysis = monitor.analyze_compression(
    original_text=original_text,
    chunks=chunks,
    document_name="mon_document.txt",
    content_type="text",
    metadata={"category": "tutorial"}
)

print(f"Ratio: {analysis['compression_ratio_formatted']}")
print(f"EfficacitÃ©: {analysis['efficiency']:.1f}%")
print(f"Score qualitÃ©: {analysis['quality_score']:.1f}/100")

# Statistiques globales
stats = monitor.get_stats()
print(f"Ratio moyen: {stats['average_ratio_formatted']}")
print(f"Meilleur ratio: {stats['best_ratio_formatted']}")

# Rapport dÃ©taillÃ©
print(monitor.get_compression_report())
```

### ğŸ’» Utilisation avec VectorMemory

Le Compression Monitor est **automatiquement intÃ©grÃ©** dans VectorMemory :

```python
from memory.vector_memory import VectorMemory

memory = VectorMemory(max_tokens=1_000_000)

# Les mÃ©triques de compression sont calculÃ©es automatiquement
result = memory.add_document(
    content="Mon texte...",
    document_name="document.txt",
    metadata={"type": "text"}
)

# Les mÃ©triques sont incluses dans le rÃ©sultat
if 'compression' in result:
    comp = result['compression']
    print(f"Ratio: {comp['ratio_formatted']}")
    print(f"EfficacitÃ©: {comp['efficiency']:.1f}%")

# Statistiques complÃ¨tes avec compression
stats = memory.get_stats()
if 'compression' in stats:
    print(f"Ratio moyen: {stats['compression']['average_ratio_formatted']}")

# Rapport de compression
print(memory.get_compression_report())
```

### ğŸ“Š MÃ©triques CalculÃ©es

#### Ratios de Compression

- **Compression Ratio** : taille_originale / taille_compressÃ©e
  - `2.4:1` = compression modeste (2.4x plus efficace)
  - `10:1` = bonne compression
  - `52:1` = excellente compression

#### EfficacitÃ©

- **Overhead** : redondance due au chevauchement des chunks
- **EfficacitÃ©** : 100 - overhead_percent
- **Espace Ã©conomisÃ©** :Bytes et pourcentage

#### QualitÃ©

- **Score de qualitÃ©** : mÃ©trique composite 0-100
  - BasÃ© sur le ratio, l'efficacitÃ©, le nombre de chunks
  - Plus Ã©levÃ© = meilleure compression

### ğŸ“ˆ Analyse par Type de Contenu

Le moniteur suit sÃ©parÃ©ment chaque type :

```python
stats = monitor.get_stats()

# Stats par type
for content_type, type_stats in stats['by_content_type'].items():
    print(f"{content_type}:")
    print(f"  Documents: {type_stats['count']}")
    print(f"  Ratio: {type_stats['average_ratio']:.1f}:1")
```

Types reconnus : `text`, `code`, `pdf`, `docx`, `data`, `html`, etc.

---

## ğŸ¯ Exemples Complets

Un fichier d'exemples complets est disponible : [examples/advanced_features_demo.py](../examples/advanced_features_demo.py)

Pour l'exÃ©cuter :

```bash
python examples/advanced_features_demo.py
```

---

## ğŸ¦™ IntÃ©gration avec Ollama

### Ã€ quoi servent ces fonctionnalitÃ©s ?

#### 1. RLHF Manager - Apprendre de vos feedbacks
**ProblÃ¨me rÃ©solu :** L'IA ne "se souvient" pas de ce qui a fonctionnÃ© ou Ã©chouÃ©.

**Solution :** 
- âœ… Collecte automatique chaque fois que vous donnez un ğŸ‘ ou ğŸ‘
- âœ… DÃ©tecte les patterns : "Quand je rÃ©ponds comme Ã§a â†’ feedback positif"
- âœ… MÃ©morise ce qui fonctionne bien dans votre contexte
- âœ… Permet d'amÃ©liorer l'IA avec VOS propres donnÃ©es

**Valeur pratique :**
```
Avant : L'IA rÃ©pond toujours pareil, peu importe vos prÃ©fÃ©rences
AprÃ¨s  : L'IA apprend votre style, votre vocabulaire, votre domaine
```

#### 2. Training Manager - EntraÃ®ner sur VOS donnÃ©es
**ProblÃ¨me rÃ©solu :** Les modÃ¨les gÃ©nÃ©riques ne connaissent pas votre domaine.

**Solution :**
- âœ… CrÃ©ez un modÃ¨le spÃ©cialisÃ© sur VOS documents
- âœ… EntraÃ®nez sur le vocabulaire de votre entreprise
- âœ… Fine-tunez sur vos processus internes
- âœ… GÃ©nÃ©rez un modÃ¨le Ollama personnalisÃ©

**Valeur pratique :**
```
Avant : llama3.2 gÃ©nÃ©rique â†’ connaissances gÃ©nÃ©rales
AprÃ¨s  : llama3.2-votre-entreprise â†’ connaÃ®t vos process, votre jargon
```

#### 3. Compression Monitor - Optimiser la mÃ©moire
**ProblÃ¨me rÃ©solu :** Vous ne savez pas si votre limite de 1M tokens est bien utilisÃ©e.

**Solution :**
- âœ… Mesure en temps rÃ©el l'efficacitÃ© de la compression
- âœ… Ratios de 2.4:1 Ã  52:1 selon le type de contenu
- âœ… Identifie les documents mal compressÃ©s
- âœ… Permet d'optimiser l'utilisation des 1M tokens

**Valeur pratique :**
```
Avant : "J'ai stockÃ© 50 documents, mais combien d'espace reste-t-il ?"
AprÃ¨s  : "Ratio 15.3:1, efficacitÃ© 87%, il me reste 750k tokens disponibles"
```

### Qu'est-ce qui est automatique avec Ollama ?

| FonctionnalitÃ© | Automatique ? | DÃ©tails |
|----------------|---------------|---------|
| **Compression Monitor** | âœ… 100% | IntÃ©grÃ© dans VectorMemory, mÃ©triques en temps rÃ©el |
| **RLHF - Collecte feedback** | âœ… Automatique | Chaque interaction enregistrÃ©e automatiquement |
| **RLHF - DÃ©tection patterns** | âœ… Automatique | Analyse automatique, patterns appris en continu |
| **RLHF - Export donnÃ©es** | âš ï¸ Manuel | Vous dÃ©cidez quand exporter : `rlhf.export_training_data()` |
| **Training - PrÃ©paration donnÃ©es** | âœ… Automatique | Formatage JSONL, Modelfile gÃ©nÃ©rÃ© automatiquement |
| **Training - Fine-tuning Ollama** | âŒ Manuel | Vous devez lancer : `ollama create nom_modele -f Modelfile` |
| **Training - Utilisation nouveau modÃ¨le** | âŒ Manuel | Vous choisissez quand passer au nouveau modÃ¨le |

### Pourquoi le fine-tuning n'est-il pas automatique ?

**C'est volontaire et c'est une BONNE chose :**

1. **SÃ©curitÃ©** ğŸ”’
   - Vous contrÃ´lez quand un nouveau modÃ¨le est crÃ©Ã©
   - Pas de modification surprise de votre modÃ¨le en production
   - Vous pouvez tester avant de dÃ©ployer

2. **ContrÃ´le** ğŸ®
   - Vous dÃ©cidez quand vous avez assez de donnÃ©es (100 ? 1000 ? 10000 exemples ?)
   - Vous choisissez le bon moment (pas pendant une dÃ©mo importante)
   - Vous validez la qualitÃ© avant utilisation

3. **Transparence** ğŸ‘ï¸
   - Le Modelfile est gÃ©nÃ©rÃ© et visible
   - Les INSTRUCTIONS.txt expliquent exactement quoi faire
   - Vous comprenez ce qui se passe

### Workflow recommandÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1 : COLLECTE (1-2 semaines) - AUTOMATIQUE              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Utilisez l'IA normalement avec Ollama                     â”‚
â”‚  â€¢ Donnez des feedbacks                                      â”‚
â”‚  â€¢ RLHF collecte automatiquement toutes les interactions     â”‚
â”‚  â€¢ Compression Monitor suit l'efficacitÃ© en temps rÃ©el       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2 : ANALYSE - AUTOMATIQUE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Consultez les statistiques RLHF                           â”‚
â”‚  â€¢ VÃ©rifiez les patterns appris (confiance > 0.7)            â”‚
â”‚  â€¢ Regardez les mÃ©triques de compression                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3 : DÃ‰CISION - VOUS DÃ‰CIDEZ                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ "J'ai 500 exemples positifs, c'est suffisant ?"           â”‚
â”‚  â€¢ "Les patterns dÃ©tectÃ©s sont-ils corrects ?"               â”‚
â”‚  â€¢ "C'est le bon moment pour amÃ©liorer le modÃ¨le ?"          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 4 : FINE-TUNING - SEMI-AUTOMATIQUE (10 minutes)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Exporter : rlhf.export_training_data()    [automatique]  â”‚
â”‚  2. PrÃ©parer : trainer.fine_tune_ollama_model() [automatique]â”‚
â”‚  3. CrÃ©er modÃ¨le : ollama create ...          [VOUS]         â”‚
â”‚  4. Tester le nouveau modÃ¨le                  [VOUS]         â”‚
â”‚  5. Basculer en production si OK              [VOUS]         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 5 : AMÃ‰LIORATION CONTINUE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Recommencer le cycle avec le nouveau modÃ¨le               â”‚
â”‚  â€¢ Chaque itÃ©ration amÃ©liore davantage l'IA                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Deux faÃ§ons d'utiliser ces fonctionnalitÃ©s

#### Option A : AmÃ©lioration pÃ©riodique (RECOMMANDÃ‰)
```python
# 1. Collecte automatique pendant 2 semaines
# (juste utiliser l'IA normalement)

# 2. Tous les 15 jours : fine-tuning manuel
rlhf = get_rlhf_manager()
trainer = get_training_manager()

# Exporter les bons exemples
count = rlhf.export_training_data("data/train.jsonl", min_score=3)
print(f"{count} exemples exportÃ©s")

# PrÃ©parer le fine-tuning
result = trainer.fine_tune_ollama_model(
    base_model="llama3.2",
    train_data_path="data/train.jsonl",
    new_model_name="llama3.2-improved-v2"
)

# CrÃ©er le nouveau modÃ¨le (dans le terminal)
# ollama create llama3.2-improved-v2 -f chemin/vers/Modelfile

# Tester et basculer si satisfait
```

#### Option B : Collecte seule (insights manuels)
```python
# Collectez les donnÃ©es, mais ne faites JAMAIS de fine-tuning
# Utilisez juste les statistiques pour comprendre :

rlhf = get_rlhf_manager()

# Insights manuels
stats = rlhf.get_statistics("all")
print(f"Satisfaction globale : {stats['satisfaction_score']:.2%}")

patterns = rlhf.get_learned_patterns(min_confidence=0.8)
for p in patterns:
    print(f"Pattern type {p['pattern_type']} : confiance {p['confidence']:.2f}")
    # Vous appliquez manuellement ces insights dans votre code

# MÃ©triques de compression
monitor = get_compression_monitor()
stats = monitor.get_stats()
print(f"EfficacitÃ© moyenne : {stats['average_efficiency']:.1f}%")
# Vous optimisez manuellement selon ces informations
```

---

## ğŸ”— IntÃ©gration avec l'IA Principale

Ces modules sont conÃ§us pour s'intÃ©grer seamlessly avec le reste du systÃ¨me :

### Dans AIEngine

```python
# Dans ai_engine.py
from core.rlhf_manager import get_rlhf_manager
from core.training_manager import get_training_manager

class AIEngine:
    def __init__(self):
        # ...
        self.rlhf_manager = get_rlhf_manager()
        self.training_manager = get_training_manager()
    
    def process_query(self, query):
        response = self.model.generate(query)
        
        # Enregistrer automatiquement
        self.rlhf_manager.record_interaction(
            user_query=query,
            ai_response=response,
            # ...
        )
        
        return response
```

### Dans l'Interface GUI

```python
# Ajouter un bouton "Bon âœ“" / "Mauvais âœ—"
def on_good_feedback():
    rlhf.record_interaction(
        user_query=last_query,
        ai_response=last_response,
        feedback_type="positive",
        feedback_score=5
    )

def on_bad_feedback():
    rlhf.record_interaction(
        user_query=last_query,
        ai_response=last_response,
        feedback_type="negative",
        feedback_score=1
    )
```

---

## ğŸ“ Notes Importantes

1. **RLHF Manager**
   - Les patterns sont appris automatiquement
   - Base SQLite crÃ©Ã©e dans `data/rlhf_feedback.db`
   - Exporter rÃ©guliÃ¨rement les donnÃ©es pour entraÃ®nement

2. **Training Manager**
   - Les runs sont sauvegardÃ©s dans `models/training_runs/`
   - Checkpoints dans `models/checkpoints/`
   - Pour Ollama, suivre les instructions dans `INSTRUCTIONS.txt`

3. **Compression Monitor**
   - IntÃ©grÃ© automatiquement dans VectorMemory
   - Les mÃ©triques sont calculÃ©es en temps rÃ©el
   - Pas de stockage persistant (stats en mÃ©moire)

---

## ğŸš€ Prochaines Ã‰tapes

1. Tester les exemples fournis
2. IntÃ©grer dans votre workflow
3. Ajuster les paramÃ¨tres selon vos besoins
4. Consulter les logs pour le debugging

Pour toute question, consultez la documentation complÃ¨te dans `docs/`.
