"""
Training Manager - Pipeline d'entra√Ænement moderne pour mod√®les locaux
Entra√Ænement, fine-tuning et monitoring avec support Ollama
"""

import json
import random
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional

from utils.logger import setup_logger


class TrainingManager:
    """
    Gestionnaire d'entra√Ænement moderne pour mod√®les IA locaux

    Fonctionnalit√©s:
    - Support Ollama et mod√®les personnalis√©s
    - Checkpointing automatique
    - Monitoring en temps r√©el
    - Validation et √©valuation
    - Export des m√©triques
    """

    def __init__(
        self,
        output_dir: str = "models/training_runs",
        checkpoint_dir: str = "models/checkpoints",
    ):
        """
        Initialise le gestionnaire d'entra√Ænement

        Args:
            output_dir: R√©pertoire de sortie des runs
            checkpoint_dir: R√©pertoire des checkpoints
        """
        self.output_dir = Path(output_dir)
        self.checkpoint_dir = Path(checkpoint_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

        self.logger = setup_logger("TrainingManager")

        # √âtat de l'entra√Ænement
        self.current_run_id = None
        self.current_run_dir = None
        self.training_active = False
        self.epoch_metrics = []
        self.callback_functions = []

        self.logger.info("‚úÖ Training Manager initialis√©")

    def create_run(
        self, run_name: Optional[str] = None, config: Optional[Dict] = None
    ) -> str:
        """
        Cr√©e un nouveau run d'entra√Ænement

        Args:
            run_name: Nom du run (auto-g√©n√©r√© si None)
            config: Configuration de l'entra√Ænement

        Returns:
            ID du run
        """
        # G√©n√©rer un ID unique
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        run_name = run_name or f"run_{timestamp}"
        self.current_run_id = f"{run_name}_{timestamp}"

        # Cr√©er le r√©pertoire du run
        self.current_run_dir = self.output_dir / self.current_run_id
        self.current_run_dir.mkdir(parents=True, exist_ok=True)

        # Sauvegarder la configuration
        config = config or {}
        config["run_id"] = self.current_run_id
        config["run_name"] = run_name
        config["created_at"] = datetime.now().isoformat()

        with open(self.current_run_dir / "config.json", "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)

        self.logger.info("üöÄ Nouveau run cr√©√©: %s", self.current_run_id)

        return self.current_run_id

    def train_model(
        self,
        train_data: List[Dict[str, str]],
        val_data: Optional[List[Dict[str, str]]] = None,
        epochs: int = 3,
        batch_size: int = 8,
        learning_rate: float = 1e-4,
        model_name: str = "custom_model",
        save_every: int = 1,
        validate_every: int = 1,
        on_epoch_end: Optional[Callable] = None,
        on_batch_end: Optional[Callable] = None,
    ) -> Dict[str, Any]:
        """
        Entra√Æne un mod√®le local

        Args:
            train_data: Donn√©es d'entra√Ænement [{input, target}]
            val_data: Donn√©es de validation
            epochs: Nombre d'√©poques
            batch_size: Taille des batchs
            learning_rate: Taux d'apprentissage
            model_name: Nom du mod√®le
            save_every: Sauvegarder tous les N epochs
            validate_every: Valider tous les N epochs
            on_epoch_end: Callback apr√®s chaque √©poque
            on_batch_end: Callback apr√®s chaque batch

        Returns:
            R√©sultats de l'entra√Ænement
        """
        self.training_active = True
        self.epoch_metrics = []

        # Cr√©er un run si pas encore fait
        if not self.current_run_id:
            self.create_run(run_name=f"training_{model_name}")

        # Configuration de l'entra√Ænement
        train_config = {
            "model_name": model_name,
            "epochs": epochs,
            "batch_size": batch_size,
            "learning_rate": learning_rate,
            "train_samples": len(train_data),
            "val_samples": len(val_data) if val_data else 0,
            "started_at": datetime.now().isoformat(),
        }

        self.logger.info("üìö D√©marrage de l'entra√Ænement: %s", model_name)
        self.logger.info("   üìä %d exemples d'entra√Ænement", len(train_data))
        self.logger.info(
            "   üìä %d exemples de validation",
            len(val_data) if val_data else 0
        )
        self.logger.info("   ‚öôÔ∏è  %d √©poques, batch size %d", epochs, batch_size)

        start_time = time.time()

        # Entra√Ænement par √©poque
        for epoch in range(epochs):
            if not self.training_active:
                self.logger.info("‚è∏Ô∏è  Entra√Ænement interrompu")
                break

            epoch_start = time.time()
            separator = "=" * 60
            self.logger.info("\n%s", separator)
            self.logger.info("√âpoque %d/%d", epoch + 1, epochs)
            self.logger.info("%s", separator)

            # M√©triques de l'√©poque
            epoch_metrics = {
                "epoch": epoch + 1,
                "train_loss": 0.0,
                "train_samples": len(train_data),
                "batches": 0,
                "started_at": datetime.now().isoformat(),
            }

            # Entra√Ænement par batch
            n_batches = (len(train_data) + batch_size - 1) // batch_size

            for batch_idx in range(n_batches):
                if not self.training_active:
                    break

                # Extraire le batch
                start_idx = batch_idx * batch_size
                end_idx = min(start_idx + batch_size, len(train_data))
                batch = train_data[start_idx:end_idx]

                # Simuler l'entra√Ænement (dans une vraie impl√©mentation,
                # on appellerait le mod√®le ici)
                batch_loss = self._train_batch(batch, learning_rate)

                epoch_metrics["train_loss"] += batch_loss
                epoch_metrics["batches"] += 1

                # Callback batch
                if on_batch_end:
                    on_batch_end(batch_idx, n_batches, batch_loss)

                # Affichage progressif
                if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == n_batches:
                    avg_loss = epoch_metrics["train_loss"] / epoch_metrics["batches"]
                    progress = (batch_idx + 1) / n_batches * 100
                    self.logger.info(
                        "   Batch %d/%d (%.1f%%) - Loss: %.4f",
                        batch_idx + 1,
                        n_batches,
                        progress,
                        avg_loss
                    )

            # Moyenne de la loss
            epoch_metrics["train_loss"] /= epoch_metrics["batches"]
            epoch_metrics["duration"] = time.time() - epoch_start

            # Validation
            if val_data and (epoch + 1) % validate_every == 0:
                val_metrics = self._validate(val_data, batch_size)
                epoch_metrics.update(val_metrics)

                self.logger.info(
                    "\n   üìä Validation - Loss: %.4f, Accuracy: %.2f%%",
                    val_metrics['val_loss'],
                    val_metrics['val_accuracy'] * 100
                )

            # R√©sum√© de l'√©poque
            self.logger.info(
                "\n   ‚úÖ √âpoque %d termin√©e en %.2fs",
                epoch + 1,
                epoch_metrics['duration']
            )
            self.logger.info("   üìä Train Loss: %.4f", epoch_metrics['train_loss'])

            self.epoch_metrics.append(epoch_metrics)

            # Callback √©poque
            if on_epoch_end:
                on_epoch_end(epoch, epoch_metrics)

            # Sauvegarde checkpoint
            if (epoch + 1) % save_every == 0:
                checkpoint_path = self._save_checkpoint(epoch + 1, epoch_metrics)
                self.logger.info("   üíæ Checkpoint sauvegard√©: %s", checkpoint_path)

        # Finaliser l'entra√Ænement
        total_time = time.time() - start_time
        train_config["completed_at"] = datetime.now().isoformat()
        train_config["total_duration"] = total_time
        train_config["epochs_completed"] = len(self.epoch_metrics)

        # Sauvegarder les m√©triques
        self._save_metrics(train_config)

        self.training_active = False

        separator = "=" * 60
        self.logger.info("\n%s", separator)
        self.logger.info("‚úÖ Entra√Ænement termin√© en %.2fs", total_time)
        self.logger.info("   üìä %d √©poques compl√©t√©es", len(self.epoch_metrics))
        if self.epoch_metrics:
            final_loss = self.epoch_metrics[-1]["train_loss"]
            self.logger.info("   üìâ Loss finale: %.4f", final_loss)
        self.logger.info("%s\n", separator)

        return {
            "run_id": self.current_run_id,
            "config": train_config,
            "metrics": self.epoch_metrics,
            "final_loss": (
                self.epoch_metrics[-1]["train_loss"] if self.epoch_metrics else None
            ),
        }

    def _train_batch(self, _batch: List[Dict], _learning_rate: float) -> float:
        """
        Entra√Æne sur un batch (simulation)

        Dans une impl√©mentation r√©elle, ceci appellerait le mod√®le
        et calculerait la vraie loss

        Args:
            batch: Batch de donn√©es
            learning_rate: Taux d'apprentissage

        Returns:
            Loss du batch
        """
        # Simulation de loss d√©croissante
        base_loss = 2.0
        noise = random.uniform(-0.1, 0.1)
        # Loss diminue avec le temps
        improvement_factor = 1.0 - (len(self.epoch_metrics) * 0.1)
        loss = max(0.1, base_loss * improvement_factor + noise)

        return loss

    def _validate(self, val_data: List[Dict], batch_size: int) -> Dict[str, float]:
        """
        Valide le mod√®le

        Args:
            val_data: Donn√©es de validation
            batch_size: Taille des batchs

        Returns:
            M√©triques de validation
        """
        # Simulation de validation
        val_loss = random.uniform(0.5, 1.5)
        val_accuracy = random.uniform(0.7, 0.95)

        # Note: batch_size serait utilis√© dans une vraie impl√©mentation
        _ = batch_size  # Marquer comme utilis√©

        return {
            "val_loss": val_loss,
            "val_accuracy": val_accuracy,
            "val_samples": len(val_data),
        }

    def _save_checkpoint(self, epoch: int, metrics: Dict) -> Path:
        """
        Sauvegarde un checkpoint

        Args:
            epoch: Num√©ro de l'√©poque
            metrics: M√©triques de l'√©poque

        Returns:
            Chemin du checkpoint
        """
        checkpoint_name = f"checkpoint_epoch_{epoch}"
        checkpoint_path = self.current_run_dir / "checkpoints" / checkpoint_name
        checkpoint_path.mkdir(parents=True, exist_ok=True)

        # Sauvegarder les m√©triques
        with open(checkpoint_path / "metrics.json", "w", encoding="utf-8") as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)

        # Dans une vraie impl√©mentation, sauvegarder les poids du mod√®le ici
        # torch.save(model.state_dict(), checkpoint_path / "model.pt")

        return checkpoint_path

    def _save_metrics(self, config: Dict):
        """
        Sauvegarde les m√©triques compl√®tes

        Args:
            config: Configuration de l'entra√Ænement
        """
        # Sauvegarder config mise √† jour
        with open(self.current_run_dir / "config.json", "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)

        # Sauvegarder m√©triques par √©poque
        with open(self.current_run_dir / "metrics.jsonl", "w", encoding="utf-8") as f:
            for metrics in self.epoch_metrics:
                f.write(json.dumps(metrics, ensure_ascii=False) + "\n")

        # Cr√©er un r√©sum√©
        summary = {
            "run_id": self.current_run_id,
            "total_epochs": len(self.epoch_metrics),
            "best_train_loss": (
                min(m["train_loss"] for m in self.epoch_metrics)
                if self.epoch_metrics
                else None
            ),
            "final_train_loss": (
                self.epoch_metrics[-1]["train_loss"] if self.epoch_metrics else None
            ),
            "total_duration": config.get("total_duration", 0),
            "completed_at": config.get("completed_at", ""),
        }

        if any("val_loss" in m for m in self.epoch_metrics):
            val_losses = [m["val_loss"] for m in self.epoch_metrics if "val_loss" in m]
            summary["best_val_loss"] = min(val_losses)
            summary["final_val_loss"] = val_losses[-1]

        with open(self.current_run_dir / "summary.json", "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)

    def fine_tune_ollama_model(
        self,
        base_model: str,
        train_data: List[Dict[str, str]],
        new_model_name: str,
        epochs: int = 3,
        learning_rate: float = 1e-4,
        on_progress: Optional[Callable] = None,
    ) -> Dict[str, Any]:
        """
        Fine-tune un mod√®le Ollama

        Args:
            base_model: Nom du mod√®le de base (ex: 'llama3.2')
            train_data: Donn√©es d'entra√Ænement
            new_model_name: Nom du nouveau mod√®le
            epochs: Nombre d'√©poques
            learning_rate: Taux d'apprentissage
            on_progress: Callback de progression

        Returns:
            R√©sultats du fine-tuning
        """
        # Note: epochs, learning_rate, on_progress seraient utilis√©s pour un vrai fine-tuning
        _ = (
            epochs,
            learning_rate,
            on_progress,
        )  # Marquer comme utilis√©s pour l'impl√©mentation future

        self.logger.info("ü¶ô Fine-tuning Ollama: %s ‚Üí %s", base_model, new_model_name)

        # Cr√©er un Modelfile pour le fine-tuning
        modelfile_content = f"""FROM {base_model}

# Fine-tuned model: {new_model_name}
# Base model: {base_model}
# Training samples: {len(train_data)}
# Epochs: {epochs}
# Created: {datetime.now().isoformat()}

PARAMETER temperature 0.7
PARAMETER num_ctx 8192
PARAMETER top_p 0.9

SYSTEM You are an AI assistant that has been fine-tuned with specific knowledge. You provide helpful, accurate, and contextual responses.
"""

        # Cr√©er le Modelfile
        modelfile_path = self.current_run_dir / "Modelfile"
        with open(modelfile_path, "w", encoding="utf-8") as f:
            f.write(modelfile_content)

        # Sauvegarder les donn√©es d'entra√Ænement
        train_data_path = self.current_run_dir / "train_data.jsonl"
        with open(train_data_path, "w", encoding="utf-8") as f:
            for item in train_data:
                f.write(json.dumps(item, ensure_ascii=False) + "\n")

        self.logger.info("   üìù Modelfile cr√©√©: %s", modelfile_path)
        self.logger.info("   üìö Donn√©es sauvegard√©es: %s", train_data_path)

        # Instructions pour cr√©er le mod√®le
        instructions = f"""
Pour cr√©er le mod√®le fine-tun√© avec Ollama:

1. Cr√©er le mod√®le:
   ollama create {new_model_name} -f {modelfile_path}

2. Tester le mod√®le:
   ollama run {new_model_name}

3. Entra√Æner avec vos donn√©es:
   # Utiliser les donn√©es de {train_data_path}
"""

        instructions_path = self.current_run_dir / "INSTRUCTIONS.txt"
        with open(instructions_path, "w", encoding="utf-8") as f:
            f.write(instructions)

        self.logger.info("   üìã Instructions: %s", instructions_path)

        return {
            "run_id": self.current_run_id,
            "base_model": base_model,
            "new_model_name": new_model_name,
            "modelfile_path": str(modelfile_path),
            "train_data_path": str(train_data_path),
            "instructions_path": str(instructions_path),
            "status": "prepared",
            "message": "Modelfile cr√©√©. Voir INSTRUCTIONS.txt pour cr√©er le mod√®le avec Ollama.",
        }

    def load_train_data(self, data_path: str) -> List[Dict[str, str]]:
        """
        Charge des donn√©es d'entra√Ænement

        Args:
            data_path: Chemin vers le fichier JSONL

        Returns:
            Liste de donn√©es
        """
        data = []
        with open(data_path, "r", encoding="utf-8") as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line))

        self.logger.info("‚úÖ %d exemples charg√©s depuis %s", len(data), data_path)
        return data

    def get_run_summary(self, run_id: str) -> Optional[Dict[str, Any]]:
        """
        R√©cup√®re le r√©sum√© d'un run

        Args:
            run_id: ID du run

        Returns:
            R√©sum√© ou None
        """
        run_dir = self.output_dir / run_id
        summary_path = run_dir / "summary.json"

        if summary_path.exists():
            with open(summary_path, "r", encoding="utf-8") as f:
                return json.load(f)

        return None

    def list_runs(self) -> List[Dict[str, Any]]:
        """
        Liste tous les runs d'entra√Ænement

        Returns:
            Liste des runs avec r√©sum√©s
        """
        runs = []

        for run_dir in self.output_dir.iterdir():
            if run_dir.is_dir():
                summary = self.get_run_summary(run_dir.name)
                if summary:
                    runs.append(summary)

        # Trier par date (plus r√©cent en premier)
        runs.sort(key=lambda x: x.get("completed_at", ""), reverse=True)

        return runs

    def stop_training(self):
        """Arr√™te l'entra√Ænement en cours"""
        if self.training_active:
            self.training_active = False
            self.logger.info("‚èπÔ∏è  Arr√™t de l'entra√Ænement demand√©")


# Singleton global
_TRAINING_MANAGER_INSTANCE = None


def get_training_manager() -> TrainingManager:
    """R√©cup√®re l'instance singleton du Training Manager"""
    global _TRAINING_MANAGER_INSTANCE
    if _TRAINING_MANAGER_INSTANCE is None:
        _TRAINING_MANAGER_INSTANCE = TrainingManager()
    return _TRAINING_MANAGER_INSTANCE
