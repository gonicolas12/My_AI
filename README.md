# ü§ñ Une IA personnelle, confidentielle et locale

- üß† **Contexte Ultra-√âtendu** pour des conversations et analyses approfondies
- üóúÔ∏è **Compression Intelligente** : Ratio de compression 2.4:1 √† 52:1 selon le contenu
- üí¨ **Conversations intelligentes** avec reconnaissance d'intentions avanc√©e et m√©moire persistante
- ü§ñ **Syst√®me d'Agents IA Sp√©cialis√©s** : 9 agents experts pour des t√¢ches complexes
- üìÑ **Traitement complet** des documents **PDF** et **DOCX** avec analyse contextuelle ultra-√©tendue
- üñºÔ∏è **Analyse d'images** avec mod√®les vision Ollama (llava, llama3.2-vision, etc.)
- üíª **Analyse** et **g√©n√©ration** de **code** avec contexte massif
- üåê **Recherche internet intelligente** avec r√©sum√©s automatiques et int√©gration contextuelle
- üîç **Distinction automatique** entre questions techniques, documents et conversations g√©n√©rales
- üé® **Interface graphique moderne style Claude** avec bulles de chat optimis√©es et onglets
- ‚ú® **Formatage de texte avanc√©** avec support **gras** Unicode et blocs de code Python coloris√©s
- üèóÔ∏è **Architecture 100% Locale** avec persistance SQLite optimis√©e
- ‚ö° **Gestion automatique de la m√©moire** et optimisations en temps r√©el

## üèóÔ∏è Architecture Ultra 1M Tokens & FAQ Th√©matique

### üí• Capacit√©s R√©volutionnaires

- **1,048,576 tokens de contexte r√©el** (contre 4K-8K traditionnels)
- **Compression intelligente multi-niveaux** : texte, code, documents
- **Recherche s√©mantique ultra-rapide** avec TF-IDF et similarit√© cosinus
- **Chunking intelligent** avec d√©tection automatique de blocs logiques
- **Auto-optimisation** de la m√©moire selon l'usage

```
my_ai/
‚îú‚îÄ‚îÄ core/                                # C≈ìur de l'IA
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ agent_orchestrator.py            # Orchestrateur d'agents
‚îÇ   ‚îú‚îÄ‚îÄ ai_engine.py                     # Moteur principal IA
‚îÇ   ‚îú‚îÄ‚îÄ config.py                        # Configuration de l'IA
‚îÇ   ‚îú‚îÄ‚îÄ context_manager.py               # Gestion de contexte long
‚îÇ   ‚îú‚îÄ‚îÄ conversation.py                  # Gestion des conversations
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py            # Pr√©traitement des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ rlhf.py                          # Reinforcement Learning from Human Feedback
‚îÇ   ‚îî‚îÄ‚îÄ training_pipeline.py             # Pipeline d'entra√Ænement local
‚îú‚îÄ‚îÄ data/                                # Donn√©es d'enrichissement FAQ
‚îÇ   ‚îú‚îÄ‚îÄ enrichissement/                  # Exemples th√©matiques
‚îÇ   ‚îî‚îÄ‚îÄ data_collection.py               # Script de structuration des donn√©es
‚îú‚îÄ‚îÄ generators/                          # G√©n√©rateurs de contenu
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ document_generator.py            # G√©n√©ration docs avec contexte √©tendu
‚îÇ   ‚îî‚îÄ‚îÄ code_generator.py                # G√©n√©ration code avec analyse ultra
‚îú‚îÄ‚îÄ interfaces/                          # Interfaces utilisateur Ultra
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ agents_interface.py              # Interface graphique Agents IA
‚îÇ   ‚îú‚îÄ‚îÄ cli.py                           # Interface ligne de commande
‚îÇ   ‚îú‚îÄ‚îÄ gui_modern.py                    # Interface moderne
‚îÇ   ‚îú‚îÄ‚îÄ modern_styles.py                 # Styles et th√®mes modernes
‚îÇ   ‚îî‚îÄ‚îÄ vscode_extension.py              # Extension VS Code
‚îú‚îÄ‚îÄ memory/                              # M√©moire vectorielle
‚îÇ   ‚îú‚îÄ‚îÄ vector_store/chroma_db/          # Base de donn√©es ChromaDB
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ vector_memory.py                 # M√©moire vectorielle avec ChromaDB
‚îú‚îÄ‚îÄ models/                              # Mod√®les d'IA Ultra avec 1M tokens
‚îÇ   ‚îú‚îÄ‚îÄ mixins/                          # Mixins pour custom_ai_model
‚îÇ   ‚îú‚îÄ‚îÄ weights/                         # Poids de mod√®les entra√Æn√©s localement
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ advanced_code_generator.py       # G√©n√©rateur de code avanc√©
‚îÇ   ‚îú‚îÄ‚îÄ ai_agents.py                     # Agents IA sp√©cialis√©s
‚îÇ   ‚îú‚îÄ‚îÄ base_ai.py                       # Interface de base
‚îÇ   ‚îú‚îÄ‚îÄ conversation_memory.py           # M√©moire conversationnelle avanc√©e
‚îÇ   ‚îú‚îÄ‚îÄ custom_ai_model.py               # Mod√®le IA principal avec intentions
‚îÇ   ‚îú‚îÄ‚îÄ intelligent_code_orchestrator.py # Orchestrateur pour la g√©n√©ration de code
‚îÇ   ‚îú‚îÄ‚îÄ intelligent_document_analyzer.py # Analyseur de documents intelligent
‚îÇ   ‚îú‚îÄ‚îÄ internet_search.py               # Moteur de recherche internet
‚îÇ   ‚îú‚îÄ‚îÄ knowledge_base.py                # Base de connaissances locale
‚îÇ   ‚îú‚îÄ‚îÄ linguistic_patterns.py           # Reconnaissance d'intentions et patterns
‚îÇ   ‚îú‚îÄ‚îÄ local_llm.py                     # Gestionnaire Ollama (d√©tection + fallback)
‚îÇ   ‚îú‚îÄ‚îÄ ml_faq_model.py                  # FAQ avec ML et fuzzy matching
‚îÇ   ‚îú‚îÄ‚îÄ real_web_code_generator.py       # G√©n√©rateur de Code Bas√© sur Recherche Web Pure
‚îÇ   ‚îú‚îÄ‚îÄ reasoning_engine.py              # Moteur de raisonnement logique
‚îÇ   ‚îú‚îÄ‚îÄ smart_code_searcher.py           # Recherche de code intelligente
‚îÇ   ‚îú‚îÄ‚îÄ smart_web_searcher.py            # Syst√®me de Recherche Web Intelligent pour Code
‚îÇ   ‚îî‚îÄ‚îÄ ultra_custom_ai.py               # Mod√®le ULTRA
‚îú‚îÄ‚îÄ outputs/                             # Fichiers g√©n√©r√©es par l'IA
‚îú‚îÄ‚îÄ processors/                          # Processeurs de fichiers Ultra
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ pdf_processor.py                 # Traitement PDF avec chunking intelligent
‚îÇ   ‚îú‚îÄ‚îÄ docx_processor.py                # Traitement DOCX avec compression
‚îÇ   ‚îî‚îÄ‚îÄ code_processor.py                # Traitement de code avec analyse s√©mantique
‚îú‚îÄ‚îÄ utils/                               # Utilitaires Ultra
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ file_manager.py                  # Gestion fichiers
‚îÇ   ‚îú‚îÄ‚îÄ file_processor.py                # Gestion traitement fichiers
‚îÇ   ‚îú‚îÄ‚îÄ intelligent_calculator.py        # Calculateur intelligent
‚îÇ   ‚îú‚îÄ‚îÄ logger.py                        # Logging
‚îÇ   ‚îî‚îÄ‚îÄ validators.py                    # Validation
‚îú‚îÄ‚îÄ tests/                               # Tests unitaires
‚îú‚îÄ‚îÄ docs/                                # Documentation
‚îú‚îÄ‚îÄ main.py                              # Point d'entr√©e principal
‚îú‚îÄ‚îÄ Modelfile                            # Configuration mod√®le Ollama
‚îú‚îÄ‚îÄ requirements.txt                     # D√©pendances
‚îú‚îÄ‚îÄ launch.bat                           # Script pour lancer le programme
‚îú‚îÄ‚îÄ clean_project.bat                    # Script pour supprimer les fichiers temporaires
‚îú‚îÄ‚îÄ create_custom_model.bat              # Script pour cr√©er un mod√®le personnalis√© Ollama
‚îî‚îÄ‚îÄ config.yaml                          # Configuration
```

## üñ•Ô∏è Interface Utilisateur Moderne

### üé® Interface Graphique Style [Claude](https://claude.ai/new)
- **Design moderne** : Interface sombre √©l√©gante avec bulles de chat optimis√©es
- **Messages adaptatifs** : Bulles utilisateur √† droite, r√©ponses IA sans bulle
- **Formatage avanc√©** : Support complet du **texte en gras** avec Unicode
- **Animations fluides** : Indicateurs de r√©flexion et recherche internet
- **Responsive design** : Adaptation automatique √† tous types d'√©crans

### üñ±Ô∏è Fonctionnalit√©s Interactives
- **Raccourcis clavier** : Entr√©e (envoyer), Shift+Entr√©e (nouvelle ligne), Ctrl+L (clear)
- **Boutons d'action** : Clear Chat, Aide, chargement de fichiers sp√©cialis√©s
- **Messages non-scrollables** : Labels optimis√©s pour de meilleures performances
- **Timestamp automatique** : Horodatage discret pour chaque message

### üñ•Ô∏è Diff√©rentes Interfaces
- **GUI moderne** : Interface graphique intuitive avec gestion de l'historique
- **CLI avanc√©e** : Ligne de commande pour utilisateurs experts
- **Gestion d'erreurs** : Messages clairs et r√©cup√©ration gracieuse

![Interface Chat](docs/images/chatScreen.png)

## üöÄ Fonctionnalit√©s Principales

### ü§ñ Syst√®me d'Agents IA Sp√©cialis√©s
| Agent | Description |
|-------|-------------|
| üêç **CodeAgent** | G√©n√©ration et debug de code multi-langages |
| üìö **ResearchAgent** | Recherche et documentation technique |
| üìä **AnalystAgent** | Analyse de donn√©es et insights |
| ‚ú® **CreativeAgent** | R√©daction et contenu cr√©atif |
| üêõ **DebugAgent** | D√©tection et correction d'erreurs |
| üìã **PlannerAgent** | Planification de projets complexes |
| üõ°Ô∏è **SecurityAgent** | Audit de s√©curit√© & vuln√©rabilit√©s |
| ‚ö° **OptimizerAgent** | Optimisation & Performance |
| üß¨ **DataScienceAgent** | Data Science & Machine Learning |

- **Workflows multi-agents** : Collaboration entre agents pour t√¢ches complexes
- **Interface graphique d√©di√©e** : Onglet "Agents" dans la GUI moderne
- **CLI enrichi** : Commandes `agent` et `workflow` disponibles

![Interface Agents](docs/images/agentsScreen.png)

### ü¶ô Int√©gration Ollama (LLM Local)
- **LLM 100% local** : R√©ponses g√©n√©r√©es par llama3.2 directement sur votre machine
- **Confidentialit√© totale** : Aucune donn√©e n'est envoy√©e sur internet
- **Fallback intelligent** : Si Ollama n'est pas install√©, l'IA utilise le mode patterns
- **Mod√®le personnalisable** : Configuration via `Modelfile` (temp√©rature, contexte, system prompt)
- **Installation optionnelle** : L'application fonctionne avec ou sans Ollama

### üìö FAQ Th√©matique Prioritaire
- **Organisation par th√®mes** : Placez vos fichiers d‚Äôenrichissement dans `data/` (ex : `enrichissement_culture.jsonl`, `enrichissement_informatique.jsonl`, etc.)
- **Chargement automatique** : Toutes les questions/r√©ponses sont fusionn√©es et accessibles instantan√©ment
- **Matching prioritaire** : La FAQ r√©pond avant tout autre mod√®le
- **Personnalisation** : Ajoutez, modifiez ou supprimez des fichiers √† la vol√©e

### üß† IA Locale Avanc√©e
- **Reconnaissance d'intentions** : Diff√©rencie automatiquement salutations, questions techniques, demandes sur documents
- **M√©moire contextuelle** : Se souvient des documents trait√©s et du code analys√©
- **R√©ponses adaptatives** : Format et contenu adapt√©s au type de question
- **Apprentissage local** : Am√©lioration continue sans donn√©es externes

### üåê Recherche Internet Intelligente
- **Recherche web** : Acc√®s aux informations en temps r√©el via DuckDuckGo
- **R√©sum√©s automatiques** : Synth√®se intelligente des r√©sultats de recherche
- **Extraction de contenu** : Analyse des pages web avec BeautifulSoup
- **Traitement parall√®le** : Analyse simultan√©e de plusieurs sources
- **R√©ponses contextuelles** : Adaptation du format selon le type de recherche

## üèÉ‚Äç‚ôÇÔ∏è D√©marrage Rapide

### Clonez ce d√©p√¥t
```bash
git clone https://github.com/gonicolas12/My_AI
cd My_AI
```

### Installation
##### Installation des d√©pendances
```bash
pip install -r requirements.txt
```

### Installation Ollama (Optionnel mais Recommand√©)

Pour des r√©ponses de qualit√© LLM, installez Ollama :

```bash
# 1. T√©l√©charger depuis https://ollama.com/download
# 2. Installer le mod√®le texte (choisir selon votre RAM)
ollama pull llama3.2         # Mod√®le plus l√©ger pour des r√©ponses plus rapides (8 GB RAM)
# OU
ollama pull llama3.1:8b      # Mod√®le plus lourd pour des r√©ponses plus d√©taill√©es (16 GB RAM)

# 3. [OPTIONNEL] Installer un mod√®le vision pour l'analyse d'images
ollama pull llava            # Mod√®le vision recommand√©
# OU
ollama pull llama3.2-vision  # Alternative plus r√©cente

# 4. Cr√©er le mod√®le personnalis√©
.\create_custom_model.bat

# Note : Adaptez la 3√®me ligne du 'Modelfile' selon le mod√®le choisi (llama3.2 ou llama3.1:8b)
```

> **Sans Ollama**, l'IA fonctionne en mode fallback avec des patterns/r√®gles.

### Lancement
##### Lancement avec script batch (recommand√©)
```bash
.\launch.bat
```
S√©lectionnez **l'option 1 (Interface Graphique)**, puis patientez...

##### Nettoyage des fichiers temporaires
```bash
.\clean_project.bat
```
Si apr√®s avoir lanc√© plusieurs fois l'**IA** vous avez des **probl√®mes inexpliqu√©s**, des **erreurs** ou des **comportements inattendus**, lancez ce **script** pour supprimer les **fichiers temporaires** g√©n√©r√©s par l'application (logs, caches, historiques, etc.). Cela permet de repartir sur une base **propre** avant de relancer l'**IA**.

### Premiers Pas
1. **Saluer l'IA** : "Salut", "Bonjour", "slt" - L'IA reconna√Ætra votre salutation
2. **Poser une question technique** : "Comment cr√©er une liste en Python ?"
3. **Analyser un document** : Importez un fichier PDF/DOCX, puis "r√©sume ce document"
4. **Vider le chat** : Utilisez le bouton "Clear Chat" pour recommencer

### Exemples d'Usage
```
ü§ñ Vous : slt
ü§ñ IA : Salut ! Comment puis-je t'aider aujourd'hui ?

ü§ñ Vous : Comment d√©boguer du code Python ?
ü§ñ IA : [R√©ponse technique d√©taill√©e sur le d√©bogage Python]

ü§ñ Vous : r√©sume le pdf
ü§ñ IA : [R√©sum√© du document PDF pr√©c√©demment charg√©]

ü§ñ Vous : cherche sur internet les actualit√©s Python
ü§ñ IA : [Recherche et r√©sum√© des derni√®res actualit√©s Python]

ü§ñ Vous : trouve-moi des informations sur l'IA en 2025
ü§ñ IA : [Recherche et synth√®se d'informations r√©centes sur l'IA]
```

## üîë Utilisation de la cl√© API GitHub

Si vous n'avez pas **[Ollama](#installation-ollama-optionnel-mais-recommand√©)** d'install√©, la **g√©n√©ration de code** n√©cessite une cl√© **API GitHub**. Pour que **votre IA** ai acc√®s √† **Github**, c'est simple :

### 1. G√©n√©rer une cl√© API GitHub
1. **Rendez-vous** sur [github.com/settings/tokens](https://github.com/settings/tokens)
2. Cliquez sur **"Generate new token"** (classic ou fine-grained)
3. Donnez les **permissions n√©cessaires** (repo, user, etc.)
4. Copiez la **cl√© g√©n√©r√©e**

### 2. Configurer la cl√© API sur votre machine
Dans votre **terminal**, entrez‚ÄØ:
```powershell
$env:GITHUB_TOKEN="votre_token_github"
```
Et voil√† ! Votre **IA personnelle** aura acc√®s √† l'**API Github**.

### 3. Utilisation sans cl√© API
Si **aucune cl√©** n'est configur√©e, l'**IA** utilisera automatiquement le **backend local**. Les fonctionnalit√©s d√©pendantes de **GitHub** seront **d√©sactiv√©es**.

N'h√©sitez pas √† consulter le fichier `config.yaml` pour personnaliser les backends et mod√®les utilis√©s.

## üìñ Documentation Compl√®te

- **[Architecture](docs/ARCHITECTURE.md)** : Structure technique d√©taill√©e
- **[Installation](docs/INSTALLATION.md)** : Guide d'installation complet
- **[Recherche Internet](docs/INTERNET_SEARCH.md)** : Guide complet sur la recherche web
- **[Optimisation](docs/OPTIMIZATION.md)** : Conseils et techniques d'optimisation locale
- **[Ultra 1M Tokens](docs/ULTRA_1M_TOKENS.md)** : D√©tails sur la gestion du contexte √©tendu
- **[Usage](docs/USAGE.md)** : Exemples d'utilisation et workflows
- **[Changelog](docs/CHANGELOG.md)** : Historique des mises √† jour
- **[FAQ](docs/FAQ.md)** : Questions fr√©quentes et r√©ponses d√©taill√©es
- **[G√©n√©ration de Fichiers](docs/FILE_GENERATION.md)** : Guide sur la g√©n√©ration de fichiers via l'IA
- **[Agents IA](docs/AGENTS.md)** : Documentation compl√®te sur les agents IA sp√©cialis√©s

## üîß Caract√©ristiques Techniques

- **Hybride Local/Internet** : IA locale avec recherche internet optionnelle
- **Multiplateforme** : Windows, macOS, Linux
- **L√©ger** : Fonctionnement optimal sur machines modestes
- **Extensible** : Architecture modulaire pour ajouts futurs
- **S√©curis√©** : Donn√©es locales prot√©g√©es, recherche internet anonyme
- **Smart Search** : Moteur de recherche DuckDuckGo avec r√©sum√©s intelligents

## üöÄ √âvolutions Futures

- üìä **Am√©lioration interface**
- üåê **Application Web**
- üíª **Extension VS Code**
- üß© **Nouveaux agents sp√©cialis√©s**
- üîÑ **Int√©gration avec d'autres LLM locaux**