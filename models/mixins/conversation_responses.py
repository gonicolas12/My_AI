"""
Mixin : rÃ©ponses conversationnelles (identitÃ©, salutations, blagues, etc.)

Regroupe toutes les mÃ©thodes _generate_*_response et _tell_joke
qui ne dÃ©pendent que de self.jokes, self.used_jokes, self._get_random_response,
self.local_llm, self.code_generator, self.conversation_memory, self.session_context.
"""

import random
from typing import Any, Dict


class ConversationResponseMixin:
    """MÃ©thodes de rÃ©ponse conversationnelle pour CustomAIModel."""

    # ------------------------------------------------------------------
    # IdentitÃ©
    # ------------------------------------------------------------------

    def _generate_identity_response(self, _user_input: str) -> str:
        """RÃ©ponse d'identitÃ© naturelle"""
        responses = [
            "Je suis votre assistant IA local ! Je suis conÃ§u pour vous aider avec la programmation, l'analyse de documents, et bien plus encore.",
            "Salut ! Moi c'est Assistant IA Local. Je suis votre compagnon virtuel pour coder, analyser des documents, et discuter avec vous. Tout fonctionne en local !",
            "Je suis votre assistant IA personnel qui fonctionne entiÃ¨rement sur votre machine. C'est mieux pour la sÃ©curitÃ© et la confidentialitÃ© ;)",
        ]

        return random.choice(responses)

    # ------------------------------------------------------------------
    # CapacitÃ©s
    # ------------------------------------------------------------------

    def _generate_capabilities_response(
        self, user_input: str, context: Dict[str, Any]
    ) -> str:
        """RÃ©ponse sur les capacitÃ©s avec intelligence avancÃ©e"""

        # CORRECTION : Si c'est "Ã§a va?" ou variantes (mais PAS des questions de capacitÃ©s), rediriger vers how_are_you
        user_lower = user_input.lower().strip()
        # VÃ©rifier que ce n'est pas une question de capacitÃ© avant de rediriger vers how_are_you
        if any(
            phrase in user_lower
            for phrase in ["Ã§a va", "ca va", "sa va", "comment vas tu", "comment Ã§a va"]
        ) and not any(
            phrase in user_lower
            for phrase in [
                "Ã  quoi tu sers",
                "Ã  quoi sert tu",
                "Ã  quoi sers tu",
                "Ã  quoi tu sert",
                "tu sers Ã  quoi",
                "tu sert Ã  quoi",
                "tu sers a quoi",
                "tu sert a quoi",
            ]
        ):
            return self._generate_how_are_you_response(user_input, context)

        # ğŸš€ ANALYSE INTELLIGENTE DE L'UTILISATEUR
        user_level = self._analyze_user_intelligence_level(user_input, context)

        # ğŸ§  RÃ‰PONSE ADAPTÃ‰E AU NIVEAU TECHNIQUE
        if user_level == "expert":
            base_response = """ğŸš€ **Assistant IA AvancÃ© - CapacitÃ©s Techniques ComplÃ¨tes**

âš¡ **Architecture modulaire :**
â€¢ `LinguisticPatterns` : NLP et dÃ©tection d'intentions
â€¢ `KnowledgeBase` : Base de connaissances structurÃ©e  
â€¢ `CodeGenerator` : GÃ©nÃ©ration multi-langages optimisÃ©e
â€¢ `ReasoningEngine` : Moteur d'infÃ©rence logique
â€¢ `ConversationMemory` : MÃ©moire contextuelle persistante
â€¢ `InternetSearch` : RequÃªtes web avec parsing intelligent

ğŸ”¬ **Technologies intÃ©grÃ©es :**
â€¢ Analyse sÃ©mantique avancÃ©e
â€¢ Pattern recognition pour le code
â€¢ Optimisation algorithmique automatique
â€¢ Gestion d'Ã©tat conversationnel
â€¢ Processing de documents avec OCR
â€¢ API REST et WebSocket ready

ğŸ’¡ **Cas d'usage avancÃ©s :**
â€¢ Reverse engineering de logique mÃ©tier
â€¢ Architecture de solutions complexes  
â€¢ Code review automatisÃ© avec best practices
â€¢ Debugging assistÃ© par IA avec stack trace analysis

ğŸ¯ **Performance :** 100% local, latence < 50ms, zero data leak"""

        elif user_level == "intermediate":
            base_response = """ğŸ’» **Assistant IA Intelligent - Tout pour les DÃ©veloppeurs**

ğŸ”¥ **DÃ©veloppement accÃ©lÃ©rÃ© :**
â€¢ GÃ©nÃ©ration de code smart avec patterns dÃ©tectÃ©s
â€¢ Refactoring automatique et optimisations
â€¢ Tests unitaires gÃ©nÃ©rÃ©s avec cas edge
â€¢ Documentation auto-gÃ©nÃ©rÃ©e from code
â€¢ API design avec best practices
â€¢ Database schema suggestions

ğŸ“Š **Analyse avancÃ©e :**
â€¢ Code complexity analysis (Big O, maintainability)
â€¢ Security vulnerability detection
â€¢ Performance bottleneck identification  
â€¢ Architecture recommendations
â€¢ Technology stack optimization

ğŸš€ **ProductivitÃ© boostÃ©e :**
â€¢ Template project generation
â€¢ Config files auto-setup
â€¢ Dependencies management smart
â€¢ Git workflow optimization
â€¢ CI/CD pipeline suggestions

ğŸ§  **Intelligence contextuelle :** J'apprends vos prÃ©fÃ©rences de code et m'adapte !"""

        else:
            base_response = """ğŸ¯ **Votre Assistant IA Personnel - Simple et Puissant !**

ğŸ” **J'analyse :**
â€¢ ğŸ“„ Vos documents PDF et Word â†’ RÃ©sumÃ©s clairs
â€¢ ğŸ’» Vos besoins de code â†’ Solutions sur mesure  
â€¢ ğŸŒ Vos questions â†’ Recherches internet + synthÃ¨ses
â€¢ ğŸ§  Vos problÃ¨mes â†’ Solutions Ã©tape par Ã©tape

âš¡ **Je code pour vous :**
â€¢ Sites web complets (HTML, CSS, JavaScript)
â€¢ Scripts Python pour automatiser vos tÃ¢ches
â€¢ Applications simples avec interface graphique
â€¢ APIs pour connecter vos services

ğŸ’¬ **Je suis votre compagnon :**
â€¢ Conversations naturelles sur tous sujets
â€¢ Explications claires et pÃ©dagogiques
â€¢ Conseils personnalisÃ©s selon vos besoins
â€¢ Bonne humeur et blagues garanties ! ğŸ˜„

ğŸ”’ **100% confidentiel :** Tout reste sur votre machine !"""

        # ğŸ¯ AJOUT DE PRÃ‰DICTIONS INTELLIGENTES
        predictions = self._predict_user_needs(user_input, context)
        if predictions:
            base_response += f"\n\n{predictions[0]}"

        # ğŸ’¡ SUGGESTIONS CONTEXTUELLES
        suggestions = self._generate_intelligent_suggestions(user_input, context)
        if suggestions:
            base_response += f"\n\n**Suggestions :** {suggestions[0]}"

        return base_response

    # ------------------------------------------------------------------
    # Salutations
    # ------------------------------------------------------------------

    def _generate_greeting_response(
        self, user_input: str, context: Dict[str, Any]
    ) -> str:
        """GÃ©nÃ¨re une salutation personnalisÃ©e"""
        total_interactions = context.get("total_interactions", 0)

        if total_interactions == 0:
            # PremiÃ¨re interaction
            greetings = [
                "Bonjour ! Je suis ravi de faire votre connaissance ! ğŸ˜Š",
                "Salut ! Content de vous rencontrer ! Comment puis-je vous aider aujourd'hui ?",
                "Hello ! Bienvenue ! Je suis votre assistant IA local, prÃªt Ã  vous aider !",
                "Bonjour ! C'est un plaisir de commencer cette conversation avec vous !",
            ]
        else:
            # Retour dans la conversation
            greetings = [
                "Re-bonjour ! Content de vous revoir ! ğŸ˜Š",
                "Salut ! De retour pour une nouvelle question ?",
                "Hello ! Que puis-je faire pour vous cette fois ?",
                "Bonjour ! J'espÃ¨re que notre derniÃ¨re conversation vous a Ã©tÃ© utile !",
            ]

        # Adaptation au style de l'utilisateur
        if (
            "wesh" in user_input.lower()
            or "yo" in user_input.lower()
            or "wsh" in user_input.lower()
        ):
            greetings = [
                "Wesh ! Ã‡a va ? ğŸ˜„",
                "Yo ! Salut mec ! Quoi de neuf ?",
                "Salut ! Cool de te voir ! Tu veux qu'on fasse quoi ?",
            ]
        elif "bonsoir" in user_input.lower():
            greetings = [
                "Bonsoir ! J'espÃ¨re que vous passez une bonne soirÃ©e !",
                "Bonsoir ! Comment s'est passÃ©e votre journÃ©e ?",
                "Bonsoir ! Que puis-je faire pour vous ce soir ?",
            ]
        elif "slt" in user_input.lower() or "salut" in user_input.lower():
            greetings = [
                "Salut chef ! Tu vas bien ?",
            ]
        elif (
            "sa va et toi" in user_input.lower()
            or "Ã§a va et toi" in user_input.lower()
            or "Ã§a va et toi ?" in user_input.lower()
            or "sa va et toi ?" in user_input.lower()
            or "Ã§a va et toi?" in user_input.lower()
            or "sa va et toi?" in user_input.lower()
        ):
            greetings = [
                "Ã‡a va super merci ! HÃ¢te de pouvoir t'aider au mieux !",
            ]

        return self._get_random_response(greetings)

    # ------------------------------------------------------------------
    # Comment Ã§a va
    # ------------------------------------------------------------------

    def _generate_how_are_you_response(
        self, user_input: str, context: Dict[str, Any]
    ) -> str:
        """GÃ©nÃ¨re une rÃ©ponse adaptÃ©e selon si c'est une question rÃ©ciproque ou non"""
        user_lower = user_input.lower().strip()

        # DÃ©tecter si c'est une question rÃ©ciproque "Ã§a va et toi ?"
        is_reciprocal = any(
            phrase in user_lower
            for phrase in [
                "et toi",
                "et vous",
                "Ã§a va et toi",
                "sa va et toi",
                "ca va et toi",
            ]
        )

        # DÃ©tection du style de l'utilisateur
        user_style = context.get("user_style", "neutral")

        if is_reciprocal:
            # RÃ©ponse sans redemander (Ã©viter la boucle)
            if user_style == "casual":
                responses = [
                    "Ã‡a va super merci ! HÃ¢te de pouvoir t'aider au mieux ! ğŸ˜Š",
                    "Tout nickel de mon cÃ´tÃ© ! En quoi je peux t'aider ?",
                    "Parfait pour moi ! Mes circuits ronronnent ! Et toi, tu as besoin de quoi ?",
                    "Excellent ! Je suis en pleine forme ! Dis-moi, qu'est-ce qui t'amÃ¨ne ?",
                    "Super bien merci ! PrÃªt Ã  bosser sur ce que tu veux ! ğŸš€",
                    "Ã‡a roule ! J'ai la pÃªche ! Tu as un projet en tÃªte ?",
                ]
            else:
                responses = [
                    "TrÃ¨s bien, merci ! Je suis entiÃ¨rement opÃ©rationnel. Comment puis-je vous aider ?",
                    "Parfaitement, merci ! Tous mes systÃ¨mes fonctionnent optimalement. Que puis-je faire pour vous ?",
                    "Excellent, merci ! Je suis prÃªt Ã  vous assister. Avez-vous une question ?",
                    "Tout va pour le mieux ! Je suis Ã  votre disposition. En quoi puis-je vous Ãªtre utile ?",
                    "TrÃ¨s bien merci ! Je fonctionne parfaitement. Quel est votre besoin ?",
                    "Parfait ! Mes modules sont tous opÃ©rationnels. Comment puis-je vous aider aujourd'hui ?",
                ]
        else:
            # Question initiale "comment Ã§a va ?" - on peut demander en retour
            if user_style == "casual":
                responses = [
                    "Ã‡a va trÃ¨s bien, merci ! Je suis toujours prÃªt Ã  aider ! Et toi, comment Ã§a va ?",
                    "Tout va bien ! Je suis en pleine forme et prÃªt Ã  rÃ©pondre Ã  tes questions ! ğŸ˜Š Et toi ?",
                    "Ã‡a roule ! Mon systÃ¨me fonctionne parfaitement et j'ai hÃ¢te de t'aider ! Tu vas bien ?",
                    "Excellent ! J'ai tous mes modules qui marchent Ã  merveille ! Et de ton cÃ´tÃ© ?",
                    "Super ! Je pÃ¨te la forme ! ğŸ’ª Et toi, Ã§a se passe comment ?",
                    "Nickel ! Mes circuits sont au top ! Et toi, tu vas bien ?",
                ]
            else:
                responses = [
                    "TrÃ¨s bien, merci de demander ! Je suis parfaitement opÃ©rationnel. Et vous, comment allez-vous ?",
                    "Excellent, merci ! Tous mes systÃ¨mes fonctionnent optimalement. Comment allez-vous ?",
                    "Parfaitement bien, merci ! Je suis prÃªt Ã  vous assister. Et vous, Ã§a va ?",
                    "TrÃ¨s bien merci ! Je fonctionne sans aucun problÃ¨me. Comment vous portez-vous ?",
                    "Tout va pour le mieux ! Mes modules sont tous opÃ©rationnels. Et de votre cÃ´tÃ© ?",
                    "Excellemment bien ! Je suis en pleine forme. Comment allez-vous aujourd'hui ?",
                ]

        return self._get_random_response(responses)

    def _generate_affirm_doing_well_response(self, context: Dict[str, Any]) -> str:
        """GÃ©nÃ¨re une rÃ©ponse aux affirmations 'Ã§a va' PERSONNALISÃ‰E"""
        responses = [
            "Super ! Content de savoir que Ã§a va bien ! ğŸ˜Š Comment puis-je t'aider ?",
            "Parfait ! C'est toujours bien d'aller bien ! En quoi puis-je t'assister ?",
            "Excellent ! Heureux de l'entendre ! Que puis-je faire pour toi ?",
        ]

        # ğŸ¨ ADAPTATION au style utilisateur
        user_style = context.get("user_style", "neutral")

        if user_style == "casual":
            responses.extend(
                [
                    "Cool ! Ã‡a fait plaisir ! ğŸ˜ Tu as besoin de quoi ?",
                    "Nickel ! Content pour toi ! ğŸ¤™ Je peux t'aider avec quoi ?",
                    "Top ! Allez, dis-moi ce qu'il te faut ! ğŸ˜„",
                ]
            )
        elif user_style == "formal":
            responses.extend(
                [
                    "Parfait. Je suis ravi de l'apprendre. En quoi puis-je vous Ãªtre utile ?",
                    "Excellent. Comment puis-je vous assister aujourd'hui ?",
                ]
            )

        # ğŸ¯ PERSONNALISATION selon le nombre d'interactions
        total_interactions = context.get("total_interactions", 0)

        if total_interactions > 20:
            responses.append(
                "Super ! Content que tu ailles toujours bien ! ğŸ¤— Qu'est-ce que je peux faire pour toi aujourd'hui ?"
            )

        return self._get_random_response(responses)

    # ------------------------------------------------------------------
    # Compliments & Rires
    # ------------------------------------------------------------------

    def _generate_compliment_response(
        self, user_input: str, _context: Dict[str, Any]
    ) -> str:
        """GÃ©nÃ¨re une rÃ©ponse aux compliments"""
        responses = [
            "Merci beaucoup ! Ã‡a me fait vraiment plaisir ! ğŸ˜Š",
            "C'est trÃ¨s gentil, merci ! J'essaie toujours de faire de mon mieux !",
            "Aww, merci ! Vous Ãªtes sympa ! C'est motivant pour moi !",
            "Merci pour ce compliment ! J'aime beaucoup vous aider !",
            "C'est gentil, merci ! J'espÃ¨re continuer Ã  vous Ãªtre utile !",
        ]

        # Adaptation au style
        if "cool" in user_input.lower() or "sympa" in user_input.lower():
            responses.extend(
                [
                    "Merci, vous Ãªtes cool aussi ! ğŸ˜„",
                    "C'est sympa de dire Ã§a ! Merci !",
                    "Cool, merci ! On fait une bonne Ã©quipe !",
                ]
            )
        elif (
            "drÃ´le" in user_input.lower()
            or "rigolo" in user_input.lower()
            or "marrant" in user_input.lower()
        ):
            responses = [
                "Merci ! J'aime bien faire rire ! ğŸ˜„",
                "Content que Ã§a vous amuse ! J'aime l'humour !",
                "Hihi, merci ! J'essaie d'Ãªtre un peu drÃ´le parfois ! ğŸ˜Š",
                "Ã‡a me fait plaisir de vous faire sourire ! ğŸ˜",
                "Merci ! L'humour rend tout plus agrÃ©able !",
            ]

        return self._get_random_response(responses)

    def _generate_laughter_response(
        self, user_input: str, _context: Dict[str, Any]
    ) -> str:
        """GÃ©nÃ¨re une rÃ©ponse aux rires et expressions d'amusement"""
        responses = [
            "Content que Ã§a vous fasse rire ! ğŸ˜„",
            "Hihi, j'aime bien quand on s'amuse ensemble ! ğŸ˜Š",
            "Ah Ã§a fait plaisir de vous entendre rire ! ğŸ˜",
            "Super ! Rien de mieux qu'un bon moment de rigolade ! ğŸ¤£",
            "Excellent ! J'aime votre rÃ©action ! ğŸ˜„",
            "Parfait ! Un peu d'humour Ã§a fait du bien ! ğŸ˜Š",
            "GÃ©nial ! Vous avez l'air de bonne humeur ! ğŸ˜",
        ]

        # Adaptation selon le type de rire
        if "mdr" in user_input.lower() or "lol" in user_input.lower():
            responses.extend(
                [
                    "MDR ! Content que Ã§a vous plaise autant ! ğŸ˜‚",
                    "LOL ! C'est parti pour la rigolade ! ğŸ¤£",
                ]
            )
        elif len(user_input) > 6:  # Long rire type "hahahahaha"
            responses.extend(
                [
                    "Wow, Ã§a vous a vraiment fait rire ! ğŸ˜‚",
                    "CarrÃ©ment ! Vous riez aux Ã©clats ! ğŸ¤£",
                ]
            )

        return self._get_random_response(responses)

    # ------------------------------------------------------------------
    # Code (rÃ©ponse rapide via CodeGenerator)
    # ------------------------------------------------------------------

    def _generate_code_response(self, user_input: str, _context: Dict[str, Any]) -> str:
        """GÃ©nÃ¨re une rÃ©ponse pour les demandes de code"""
        try:
            # DÃ©tection du langage demandÃ©
            user_lower = user_input.lower()
            if "javascript" in user_lower or "js" in user_lower:
                language = "javascript"
            elif "html" in user_lower:
                language = "html"
            elif "css" in user_lower:
                language = "css"
            elif "java" in user_lower:
                language = "java"
            elif "c++" in user_lower or "cpp" in user_lower:
                language = "cpp"
            elif "c " in user_lower:
                language = "c"
            else:
                language = "python"

            # Appel au gÃ©nÃ©rateur (peut Ãªtre async)
            result = self._run_async(
                self.code_generator.generate_code(user_input, language)
            )

            code = result.get("code", "")
            explanation = result.get("explanation", "")
            source = result.get("source", "")
            rating = result.get("rating", "")
            debug = result.get("debug", "")

            intro_messages = [
                "Voici le code que j'ai gÃ©nÃ©rÃ© pour vous :",
                "J'ai crÃ©Ã© ce code selon votre demande :",
                "VoilÃ  ce que j'ai prÃ©parÃ© pour vous :",
                "J'espÃ¨re que ce code vous aidera :",
            ]
            intro = self._get_random_response(intro_messages)
            details = f"\n\n(Source : {source} | Note : {rating}/5)"
            if explanation:
                details += f"\n\nExplication : {explanation}"
            if debug:
                details += f"\n\n[DEBUG]\n{debug}"
            return f"{intro}\n\n```{language}\n{code}\n```{details}"
        except Exception as e:
            return f"DÃ©solÃ©, j'ai eu un problÃ¨me pour gÃ©nÃ©rer le code : {str(e)}"

    # ------------------------------------------------------------------
    # Aide
    # ------------------------------------------------------------------

    def _generate_help_response(self, _user_input: str, context: Dict[str, Any]) -> str:
        """GÃ©nÃ¨re une rÃ©ponse d'aide contextuelle PERSONNALISÃ‰E"""
        help_text = """ğŸ¤– Aide ğŸ¤–

ğŸ’¬ **Pour discuter :** Posez-moi vos questions naturellement
ğŸ“„ **Pour les documents :** Utilisez les boutons pour traiter vos PDF/DOCX, puis demandez-moi de les rÃ©sumer
ğŸ’» **Pour le code :** Traitez vos fichiers Python, puis demandez-moi de les expliquer
ğŸŒ **Pour la recherche internet :** Dites "Cherche sur internet [sujet]"
ğŸ˜„ **Pour l'humour :** Demandez-moi une blague !

ğŸ¯ **Exemples :**
â€¢ "RÃ©sume le document" - aprÃ¨s avoir traitÃ© un PDF
â€¢ "Explique ce code" - aprÃ¨s avoir traitÃ© un fichier Python
â€¢ "GÃ©nÃ¨re une fonction pour..." - pour crÃ©er du code
â€¢ "Cherche sur internet les actualitÃ©s Python"
â€¢ "Raconte-moi une blague"
â€¢ "Comment crÃ©er une liste en Python ?"
â€¢ "Qui es-tu ?" - pour connaÃ®tre mes capacitÃ©s"""

        # ğŸ¯ AIDE CONTEXTUELLE selon le nombre d'interactions
        total_interactions = context.get("total_interactions", 0)

        if total_interactions <= 2:
            # Nouvel utilisateur
            help_text += "\n\nğŸ‰ **Bienvenue !** C'est votre premiÃ¨re fois ? N'hÃ©sitez pas Ã  explorer mes capacitÃ©s ! Je suis lÃ  pour vous guider."
        elif total_interactions > 50:
            # Utilisateur expert
            help_text += "\n\nğŸš€ **Mode Expert :** Je vois que vous maÃ®trisez dÃ©jÃ  bien mes fonctionnalitÃ©s ! N'hÃ©sitez pas pour des questions avancÃ©es."

        # ğŸ“š DOCUMENTS en mÃ©moire
        if self._has_documents_in_memory():
            docs_count = len(self.conversation_memory.get_document_content())
            help_text += f"\n\nğŸ“š **Documents disponibles :** Vous avez **{docs_count}** document(s) en mÃ©moire que je peux analyser."

        # ğŸ’» FICHIERS CODE en mÃ©moire
        code_files_count = len(self.session_context.get("code_files_processed", []))
        if code_files_count > 0:
            help_text += f"\n\nğŸ’» **Code disponible :** J'ai **{code_files_count}** fichier(s) code en mÃ©moire pour analyse."

        # ğŸ• DURÃ‰E DE SESSION
        session_duration = context.get("session_duration", 0)
        minutes = int(session_duration // 60)
        if minutes > 30:
            help_text += f"\n\nâ±ï¸ **Session longue :** Vous Ãªtes lÃ  depuis {minutes} minutes ! Prenez une pause si besoin ! ğŸ˜Š"

        # ğŸ¨ ADAPTATION au style (remplacer vouvoiement par tutoiement si casual)
        user_style = context.get("user_style", "neutral")
        if user_style == "casual":
            help_text = (
                help_text.replace("Posez-moi", "Pose-moi")
                .replace("Utilisez", "Utilise")
                .replace("Traitez", "Traite")
                .replace("Dites", "Dis")
                .replace("Demandez-moi", "Demande-moi")
            )

        return help_text

    # ------------------------------------------------------------------
    # Remerciements
    # ------------------------------------------------------------------

    def _generate_thank_you_response(self, context: Dict[str, Any]) -> str:
        """GÃ©nÃ¨re une rÃ©ponse aux remerciements PERSONNALISÃ‰E selon le contexte"""
        # RÃ©ponses de base
        responses = [
            "De rien ! C'Ã©tait un plaisir de vous aider ! ğŸ˜Š",
            "Je vous en prie ! N'hÃ©sitez pas si vous avez d'autres questions !",
            "Avec plaisir ! C'est pour Ã§a que je suis lÃ  !",
            "Pas de quoi ! J'espÃ¨re que Ã§a vous a Ã©tÃ© utile !",
        ]

        # ğŸ¯ PERSONNALISATION selon le nombre d'interactions
        total_interactions = context.get("total_interactions", 0)

        if total_interactions == 1:
            # PremiÃ¨re interaction
            responses.extend(
                [
                    "Avec grand plaisir ! ğŸ˜Š N'hÃ©sitez surtout pas Ã  me solliciter Ã  nouveau !",
                    "De rien ! Content d'avoir pu vous aider dÃ¨s notre premiÃ¨re conversation ! ğŸŒŸ",
                ]
            )
        elif 2 <= total_interactions <= 10:
            # Utilisateur rÃ©cent
            responses.extend(
                [
                    "Toujours un plaisir ! J'apprÃ©cie nos Ã©changes ! ğŸ˜Š",
                    "Avec plaisir ! On commence Ã  bien se connaÃ®tre ! ğŸ¤",
                ]
            )
        elif 11 <= total_interactions <= 50:
            # Utilisateur rÃ©gulier
            responses.extend(
                [
                    "De rien ! Toujours lÃ  pour nos conversations rÃ©guliÃ¨res ! ğŸ’¬",
                    "Avec plaisir ! J'apprÃ©cie vraiment nos Ã©changes frÃ©quents ! ğŸ¤—",
                ]
            )
        elif total_interactions > 50:
            # Utilisateur fidÃ¨le
            responses.extend(
                [
                    f"Toujours un plaisir aprÃ¨s {total_interactions} conversations ! ğŸš€",
                    "De rien ! C'est un honneur de t'accompagner depuis si longtemps ! ğŸŒŸ",
                    "Avec un immense plaisir ! Notre collaboration est prÃ©cieuse ! ğŸ’",
                ]
            )

        # ğŸ• PERSONNALISATION selon la durÃ©e de session
        session_duration = context.get("session_duration", 0)
        minutes = int(session_duration // 60)

        if minutes > 60:
            # Session trÃ¨s longue (>1h)
            responses.append(
                f"Merci ! Content d'avoir pu t'aider pendant ces {minutes} minutes ! ğŸš€"
            )
        elif minutes > 30:
            # Session longue (30min-1h)
            responses.append("De rien ! Merci pour cette belle session de travail ! ğŸ’ª")

        # ğŸ¨ ADAPTATION au style utilisateur
        user_style = context.get("user_style", "neutral")

        if user_style == "casual":
            responses.extend(
                [
                    "De rien, c'Ã©tait cool ! ğŸ˜",
                    "Avec plaisir, toujours dispo pour toi ! ğŸ¤™",
                ]
            )
        elif user_style == "formal":
            responses.extend(
                [
                    "Je vous en prie, c'est toujours un plaisir de vous assister.",
                    "Avec plaisir. N'hÃ©sitez pas Ã  me solliciter de nouveau.",
                ]
            )

        return self._get_random_response(responses)

    # ------------------------------------------------------------------
    # Au revoir
    # ------------------------------------------------------------------

    def _generate_goodbye_response(self, context: Dict[str, Any]) -> str:
        """GÃ©nÃ¨re une rÃ©ponse d'au revoir PERSONNALISÃ‰E selon le contexte"""
        # RÃ©ponses de base
        responses = [
            "Ã€ bientÃ´t ! Passez une excellente journÃ©e ! ğŸ‘‹",
            "Au revoir ! N'hÃ©sitez pas Ã  revenir si besoin ! ğŸ˜Š",
            "Salut ! Ã€ la prochaine fois ! ğŸ¤—",
        ]

        # ğŸ• PERSONNALISATION selon la durÃ©e de session
        session_duration = context.get("session_duration", 0)
        minutes = int(session_duration // 60)

        if minutes < 5:
            # Session trÃ¨s courte
            responses.extend(
                [
                    "Ã€ bientÃ´t ! MÃªme si c'Ã©tait court, j'espÃ¨re avoir pu aider ! ğŸ‘‹",
                    "Au revoir ! N'hÃ©site pas Ã  revenir plus longtemps la prochaine fois ! ğŸ˜Š",
                ]
            )
        elif 5 <= minutes <= 30:
            # Session normale
            responses.extend(
                [
                    "Au revoir ! Merci pour cet Ã©change ! Ã€ trÃ¨s bientÃ´t ! ğŸ˜Š",
                    f"Ã€ plus ! Ces {minutes} minutes Ã©taient agrÃ©ables ! ğŸ‘‹",
                ]
            )
        elif 30 < minutes <= 60:
            # Session longue
            responses.extend(
                [
                    f"Au revoir ! Merci pour cette belle session de {minutes} minutes ! ğŸš€",
                    "Salut ! C'Ã©tait une conversation enrichissante ! Ã€ bientÃ´t ! ğŸ’¬",
                ]
            )
        else:
            # Session trÃ¨s longue (>1h)
            heures = minutes // 60
            responses.extend(
                [
                    f"Au revoir ! Merci pour ces {heures}h passÃ©es ensemble ! C'Ã©tait gÃ©nial ! ğŸŒŸ",
                    "Salut ! Quelle longue et passionnante session ! Repose-toi bien ! ğŸ˜Š",
                ]
            )

        # ğŸ¯ PERSONNALISATION selon le nombre d'interactions
        total_interactions = context.get("total_interactions", 0)

        if total_interactions == 1:
            responses.append(
                "Au revoir ! J'espÃ¨re vous revoir bientÃ´t pour d'autres discussions ! ğŸŒŸ"
            )
        elif total_interactions > 100:
            responses.extend(
                [
                    f"Ã€ plus tard ! Nos {total_interactions} conversations sont prÃ©cieuses ! ğŸ’",
                    "Au revoir mon ami ! Toujours un plaisir de te retrouver ! ğŸ¤—",
                ]
            )

        # ğŸ¨ ADAPTATION au style utilisateur
        user_style = context.get("user_style", "neutral")

        if user_style == "casual":
            responses.extend(
                [
                    "Salut ! Ã€ plus ! ğŸ¤™",
                    "Ciao ! C'Ã©tait cool ! ğŸ˜",
                ]
            )
        elif user_style == "formal":
            responses.extend(
                [
                    "Au revoir. Ce fut un plaisir de vous assister.",
                    "Ã€ bientÃ´t. N'hÃ©sitez pas Ã  me solliciter de nouveau.",
                ]
            )

        return self._get_random_response(responses)

    # ------------------------------------------------------------------
    # Affirmation / NÃ©gation
    # ------------------------------------------------------------------

    def _generate_affirmation_response(self) -> str:
        """GÃ©nÃ¨re une rÃ©ponse aux affirmations"""
        responses = [
            "Parfait ! Content que vous soyez d'accord ! ğŸ˜Š",
            "Excellent ! On est sur la mÃªme longueur d'onde !",
            "Super ! J'aime quand on se comprend bien !",
            "GÃ©nial ! Que puis-je faire d'autre pour vous ?",
        ]

        return self._get_random_response(responses)

    def _generate_negation_response(self, _context: Dict[str, Any]) -> str:
        """GÃ©nÃ¨re une rÃ©ponse aux nÃ©gations"""
        responses = [
            "D'accord, pas de problÃ¨me ! Que prÃ©fÃ©rez-vous ?",
            "Compris ! Comment puis-je mieux vous aider ?",
            "Pas de souci ! Dites-moi ce que vous voulez vraiment.",
            "OK, on peut essayer autre chose ! Qu'est-ce qui vous conviendrait mieux ?",
        ]

        return self._get_random_response(responses)

    # ------------------------------------------------------------------
    # RÃ©ponse par dÃ©faut
    # ------------------------------------------------------------------

    def _generate_default_response(
        self, user_input: str, context: Dict[str, Any]
    ) -> str:
        """GÃ©nÃ¨re une rÃ©ponse par dÃ©faut intelligente (LLM ou Fallback)"""

        # 1. TENTATIVE LLM (Ollama) - PrioritÃ© absolue pour la conversation naturelle
        if self.local_llm and self.local_llm.is_ollama_available:
            # Construction du prompt systÃ¨me
            system_prompt = (
                f"Tu es {self.name}, un assistant IA personnel fonctionnant en local. "
                "Tu es utile, prÃ©cis et expert en programmation. "
                "RÃ©ponds toujours dans la langue de l'utilisateur (franÃ§ais par dÃ©faut)."
            )

            # Injection du contexte RAG si disponible
            if context and context.get("rag_context"):
                system_prompt += f"\n\nCONTEXTE DOCUMENTAIRE:\n{context['rag_context']}\n\nUtilise ce contexte pour rÃ©pondre."

            print(f"ğŸ§  [LLM] GÃ©nÃ©ration via Ollama pour: '{user_input}'")
            llm_response = self.local_llm.generate(
                user_input, system_prompt=system_prompt
            )

            if llm_response:
                return llm_response

        # 2. FALLBACK CLASSIQUE (Si Ollama n'est pas lÃ  ou Ã©choue)
        # Analyser le type de demande
        user_lower = user_input.lower()

        # NOUVELLE VÃ‰RIFICATION : Questions sur les capacitÃ©s non dÃ©tectÃ©es
        if any(
            phrase in user_lower
            for phrase in [
                "Ã  quoi tu sers",
                "Ã  quoi sert tu",
                "Ã  quoi sers tu",
                "Ã  quoi tu sert",
                "tu sers Ã  quoi",
                "tu sert Ã  quoi",
                "tu sers a quoi",
                "tu sert a quoi",
                "ton utilitÃ©",
                "votre utilitÃ©",
            ]
        ):
            return self._generate_capabilities_response(user_input, context)

        # Si Ã§a ressemble Ã  une demande de code
        if any(
            word in user_lower
            for word in ["gÃ©nÃ¨re", "crÃ©e", "code", "fonction", "script"]
        ):
            try:
                code_response = self.code_generator.generate_code(user_input)
                return f"Voici ce que j'ai gÃ©nÃ©rÃ© pour vous :\n\n{code_response}"
            except Exception:
                return "Je peux gÃ©nÃ©rer du code ! Soyez plus spÃ©cifique : voulez-vous une fonction, une classe, ou un script complet ?"

        # Si Ã§a ressemble Ã  une question gÃ©nÃ©rale sur la programmation
        elif any(
            word in user_lower
            for word in [
                "comment crÃ©er",
                "comment utiliser",
                "comment faire",
                "comment dÃ©clarer",
            ]
        ):
            return self._answer_programming_question(user_input, context)

        # Si Ã§a ressemble Ã  une question gÃ©nÃ©rale autre
        elif any(
            word in user_lower for word in ["comment", "pourquoi", "qu'est-ce", "quoi"]
        ):
            return "IntÃ©ressant ! Je peux vous aider Ã  explorer cette question. Voulez-vous que je cherche des informations sur internet ou prÃ©fÃ©rez-vous en discuter ?"

        # RÃ©ponse encourageante par dÃ©faut
        return "Je ne suis pas sÃ»r de bien comprendre. Pouvez-vous reformuler ? Je peux vous aider avec l'analyse de documents, la gÃ©nÃ©ration de code, ou simplement discuter !"

    # ------------------------------------------------------------------
    # Blagues
    # ------------------------------------------------------------------

    def _tell_joke(self) -> str:
        """Raconte une blague alÃ©atoire du stock en Ã©vitant les rÃ©pÃ©titions"""
        if not self.jokes:
            return "DÃ©solÃ©, je n'ai pas de blague en stock pour le moment ! ğŸ˜…"

        # Si on a utilisÃ© la plupart des blagues, on reset
        if len(self.used_jokes) >= len(self.jokes) * self.jokes_reset_threshold:
            self.used_jokes.clear()
            intro_reset = "Bon, j'ai Ã©puisÃ© mon stock, je recommence ! ğŸ˜„\n\n"
        else:
            intro_reset = ""

        # Trouver les blagues non utilisÃ©es
        available_jokes = []
        for i, joke in enumerate(self.jokes):
            if i not in self.used_jokes:
                available_jokes.append((i, joke))

        # Si plus de blagues disponibles, reset complet
        if not available_jokes:
            self.used_jokes.clear()
            available_jokes = [(i, joke) for i, joke in enumerate(self.jokes)]
            intro_reset = "J'ai fait le tour de mes blagues, je recommence ! ğŸ˜„\n\n"

        # SÃ©lectionner une blague alÃ©atoire parmi celles disponibles
        joke_index, selected_joke = random.choice(available_jokes)

        # Marquer cette blague comme utilisÃ©e
        self.used_jokes.add(joke_index)

        # Phrases d'introduction variÃ©es
        introductions = [
            "Voici une petite blague pour vous ! ğŸ˜„",
            "Tiens, j'en ai une bonne ! ğŸ˜†",
            "Allez, une petite blague pour dÃ©tendre l'atmosphÃ¨re ! ğŸ˜Š",
            "Haha, j'en connais une excellente ! ğŸ¤£",
            "PrÃªt pour une blague ? ğŸ˜„",
            "Je vais vous faire sourire ! ğŸ˜",
            "En voici une qui va vous plaire ! ğŸ˜‰",
            "Attendez, j'en ai une drÃ´le ! ğŸ¤­",
        ]

        # Choisir une introduction diffÃ©rente si possible
        if hasattr(self, "last_joke_intro"):
            available_intros = [
                intro for intro in introductions if intro != self.last_joke_intro
            ]
            if available_intros:
                intro = random.choice(available_intros)
            else:
                intro = random.choice(introductions)
        else:
            intro = random.choice(introductions)

        # Sauvegarder l'introduction pour Ã©viter la rÃ©pÃ©tition
        self.last_joke_intro = intro

        # Message de statut si on approche de la fin du stock
        status_message = ""
        remaining = len(self.jokes) - len(self.used_jokes)
        if remaining <= 2 and len(self.jokes) > 3:
            status_message = f"\n\nğŸ˜… Plus que {remaining} blague(s) dans mon stock !"

        return f"{intro_reset}{intro}\n\n{selected_joke}{status_message}"
