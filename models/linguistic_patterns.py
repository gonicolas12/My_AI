"""
Patterns linguistiques pour l'analyse s√©mantique
"""

from typing import Dict, List, Any
import re


class LinguisticPatterns:
    """Gestionnaire de patterns linguistiques am√©lior√©s"""
    
    def __init__(self):
        self.patterns = self._load_patterns()
        self.tolerance_dict = self._load_tolerance_dictionary()
        self.context_memory = {}
    
    def _load_tolerance_dictionary(self) -> Dict[str, List[str]]:
        """Dictionnaire de tol√©rance aux fautes d'orthographe et variantes"""
        return {
            # Salutations avec fautes
            "bonjour": ["bonjour", "bnjour", "bonjourr", "bonj", "bjr", "bj", "bonsoir", "bsr", "bonsoirr"],
            "salut": ["salut", "salu", "saluu", "slt", "sl", "cc", "coucou", "ccc", "kikoo", "kikou"],
            "hello": ["hello", "helo", "hllo", "hi", "hey", "yo", "wesh", "wsh"],
            
            # Questions avec fautes
            "comment": ["comment", "commen", "comant", "cmnt", "coment"],
            "√ßa_va": ["√ßa va", "sa va", "ca va", "sa va?", "√ßa roule", "sa roule", "ca roule"],
            
            # Mots de politesse
            "merci": ["merci", "mercy", "mrci", "thx", "thanks", "remercie"],
            "s'il_vous_pla√Æt": ["s'il vous pla√Æt", "svp", "stp", "s'il te pla√Æt", "sil vous plait"],
            
            # Code et programmation
            "fonction": ["fonction", "fontion", "function", "func", "def", "methode", "m√©thode"],
            "classe": ["classe", "class", "klass", "clsse"],
            "g√©n√®re": ["g√©n√®re", "genere", "generate", "cr√©er", "creer", "create", "faire", "fais", "fait"],
            "code": ["programme", "script", "fichier", "game"],
            
            # Expressions famili√®res
            "ok": ["ok", "okay", "okey", "d'accord", "daccord", "dacord", "oui", "yes", "yep"],
            "non": ["non", "no", "nope", "pas", "jamais", "nan"],
            
            # Erreurs courantes
            "qu'est_ce_que": ["qu'est-ce que", "quest ce que", "quest-ce que", "kestke", "keskeske"],
            "pourquoi": ["pourquoi", "pourkoi", "pq", "pk", "pour quoi"],
            "comment_faire": ["comment faire", "coment faire", "cmnt faire", "comment on fait"],
            
            # Familier/argot
            "√ßa_marche": ["√ßa marche", "sa marche", "ca marche", "√ßa roule", "sa roule"],
            "c'est_cool": ["c'est cool", "cest cool", "c cool", "cool", "sympa", "bien"],
            "pas_mal": ["pas mal", "pa mal", "pas male", "bien", "correct"],
            
            # Variations avec ponctuation
            "aide": ["aide", "aider", "help", "secours", "assistance", "aidez-moi", "aide moi"],
            "expliquer": ["expliquer", "expliquez", "explique", "explain", "dire", "montrer"],
            "r√©sume": ["resume", "r√©sum√©", "resumer"],
            "document": ["fichier", "pdf", "doc", "docx"],
            
            # Questions sur l'identit√©
            "tu_es_qui": ["tu es qui", "qui es-tu", "qui es tu", "tu es qui ?", "qui es-tu ?", "qui tu es", "tu es quoi"],
            "qui_es_tu": ["qui es tu", "qui est tu", "qui es-tu", "qui √™tes vous", "qui etes vous", "quel est ton nom", "ton nom", "comment tu t'appelles", "comment tu t'appelle", "comment t'appelles tu", "comment t'appelle tu", "tu es qui", "tu es quoi"],
            "qu_est_ce_que_tu_es": ["qu'est-ce que tu es", "quest ce que tu es", "qu est ce que tu es"],
            
            # Questions sur les capacit√©s
            "que_peux_tu": ["que peux-tu", "que peux tu", "que peut tu", "que peut-tu", "qu'est-ce que tu peux"],
            "que_sais_tu": ["que sais-tu", "que sais tu", "que sait tu", "que sait-tu", "qu'est-ce que tu sais"],
            "tu_peux": ["tu peux", "tu peut", "peux-tu", "peut-tu", "est-ce que tu peux"],
            
            # R√©ponses courtes
            "oui": ["oui", "yes", "yep", "ouais", "ok", "d'accord", "daccord"],
            "non": ["non", "no", "nope", "pas", "jamais", "nan", "nenni"],
            
            # Expressions de satisfaction
            "super": ["super", "g√©nial", "parfait", "excellent", "cool", "top", "bien"],
            "√ßa_va": ["√ßa va", "ca va", "sa va", "√ßa roule", "sa roule", "ca roule"],
            
            # Demandes d'information
            "dis_moi": ["dis-moi", "dis moi", "dites-moi", "dites moi", "raconte", "raconte-moi"],
            "parle_moi": ["parle-moi", "parle moi", "parlez-moi", "parlez moi"],
            
            # Expressions de politesse √©tendues
            "s'il_te_pla√Æt": ["s'il te pla√Æt", "stp", "s'il te plait", "sil te plait", "steuplait"],
            "merci_beaucoup": ["merci beaucoup", "merci bcp", "merci bien", "grand merci"],
            "de_rien": ["de rien", "pas de quoi", "il n'y a pas de quoi", "je vous en prie"],
            
            # Expressions informelles
            "wesh": ["wesh", "salut", "hey", "yo", "coucou", "wsh"],
            "mec": ["mec", "gars", "mon pote", "buddy", "bro"],
            "c'est_parti": ["c'est parti", "go", "allons-y", "on y va", "lets go"],
        }
    
    def _load_patterns(self) -> Dict[str, Any]:
        """Charge les patterns linguistiques am√©lior√©s"""
        return {
            "intent_detection": {
                "identity_question": {
                    "patterns": [
                        r"(?:qui|quel|comment).+(?:es[- ]tu|√™tes[- ]vous|est ton nom|t'appelles?[- ]tu)",
                        r"tu es qui\b",
                        r"tu es quoi\b",
                        r"\bton nom\b",
                        r"comment (?:tu t'appelles?|t'appelles?[- ]tu)",
                        r"qui √™tes[-\s]vous",
                        r"quel est ton nom"
                    ],
                    "indicators": ["qui", "nom", "appelle", "identit√©"],
                    "weight": 1.0,
                    "priority": "high"
                },
                
                "capabilities_question": {
                    "patterns": [
                        r"(?:que|qu'est[- ]ce que|quoi).+(?:peux[- ]tu|sais[- ]tu|fais[- ]tu|es[- ]tu capable)",
                        r"(?:montre|liste|dis)[- ]moi.+(?:capacit√©s|ce que tu peux faire)",
                        r"que sais[-\s]tu faire",
                        r"quelles sont tes capacit√©s",
                        r"tu peux faire quoi"
                    ],
                    "indicators": ["capable", "peux", "sais", "faire", "capacit√©s"],
                    "weight": 1.0,
                    "priority": "high",
                    "exclude_if": ["code", "fichier", "programme", "script", "fonction"]
                },
                
                # ‚úÖ NOUVEAU: Questions r√©ciproques "√ßa va et toi ?"
                "how_are_you": {
                    "patterns": [
                        r"^comment\s+(√ßa|sa|ca)\s+va\s*\??$",
                        r"^(√ßa|sa|ca)\s+va\s+(et\s+toi|et\s+vous)\s*\??$",
                        r"^(√ßa|sa|ca)\s+va\s+et\s+toi\s*\??$",
                        r"^(sa|ca|√ßa)\s+va\s+et\s+toi\s*\??$",
                        r"^comment\s+tu\s+vas\s*\??$",
                        r"^comment\s+vous\s+allez\s*\??$",
                        r"^tu\s+vas\s+bien\s*\??$",
                        r"^vous\s+allez\s+bien\s*\??$",
                        r"^(√ßa|sa|ca)\s+va\s*\?\s*$"
                    ],
                    "indicators": ["comment", "√ßa", "va", "et toi", "et vous", "?"],
                    "weight": 1.0,
                    "priority": "high",
                    "exclude_if": ["python", "liste", "cr√©er", "fonction", "variable", "code", "programme", "script", "programmation", "habitants", "population", "combien", "nombre", "statistiques", "chiffres", "france", "pays"]
                },
                
                # ‚úÖ NOUVEAU: Affirmations simples "√ßa va" (sans question)
                "affirm_doing_well": {
                    "patterns": [
                        r"^(√ßa|sa|ca)\s+va\s*$",
                        r"^(√ßa|sa|ca)\s+va\s+bien\s*$",
                        r"^(√ßa|sa|ca)\s+va\s+super\s*!*$",
                        r"^(√ßa|sa|ca)\s+va\s+tr√®s\s+bien\s*!*$",
                        r"^(√ßa|sa|ca)\s+roule\s*$",
                        r"^je\s+vais\s+bien\s*$",
                        r"^tout\s+va\s+bien\s*$",
                        r"^tr√®s\s+bien\s*$",
                        r"^bien\s*$",
                        r"^super\s*!*$",
                        r"^nickel\s*!*$",
                        r"^parfait\s*!*$",
                        r"^excellent\s*!*$",
                        r"^g√©nial\s*!*$"
                    ],
                    "indicators": ["√ßa", "va", "bien", "roule", "tout", "super", "parfait", "excellent", "g√©nial"],
                    "weight": 0.9,
                    "priority": "medium"
                }, 
                "document_question": {
                    "patterns": [
                        r"^r√©sume$",  # r√©sume seul
                        r"^resume$",  # resume seul  
                        r"^r√©sum√©$",  # r√©sum√© seul
                        r"r√©sume\s+(?:le\s+)?(?:pdf|document|fichier|doc)",
                        r"resume\s+(?:le\s+)?(?:pdf|document|fichier|doc)",
                        r"(?:explique|analyse).+(?:document|fichier|pdf|docx)",
                        r"(?:que dit|que contient).+(?:le|ce|du|dans le).+(?:document|pdf|fichier)",
                        r"(?:premier|dernier|pr√©c√©dent).+(?:document|fichier|pdf)",
                        r"le\s+(?:pdf|document|fichier)"
                    ],
                    "indicators": ["document", "pdf", "fichier", "r√©sume", "resume", "contient"],
                    "weight": 1.2,
                    "priority": "high"
                },
                "code_question": {
                    "patterns": [
                        r"(?:explique|expliquer).+(?:code|programme|script|fonction|game\.py)",
                        r"(?:que fait|comment fonctionne).+(?:le|ce|du|cette).+(?:code|programme|fonction|script)",
                        r"(?:analyse|analyser).+(?:code|programme|fichier\.py)",
                        r"explique[-\s]moi.+(?:game\.py|le programme|ce code)",
                        r"comment (?:marche|fonctionne).+(?:ce|le).+(?:code|programme)"
                    ],
                    "indicators": ["code", "programme", "script", "fonction", "game.py", "python"],
                    "weight": 1.1,
                    "priority": "high",
                    "context_boost": ["code_file_processed"]
                },
                
                "code_generation": {
                    "patterns": [
                        r"(?:g√©n√®re|genere|generate|cr√©e|cree|create|√©cris|ecris|write|d√©veloppe|developpe|develop).+(?:fonction|function|def|code|programme|script)",
                        r"(?:g√©n√®re|genere|generate|cr√©e|cree|create).+(?:une|un|des).+(?:fonction|classe|class|api|script|programme)",
                        r"(?:√©cris|ecris|write|fais|fait|faire).+(?:du|un|une|le|la).+(?:code|programme|fonction|script|classe)",
                        r"(?:g√©n√®re|genere|generate).+(?:code|programme).+(?:pour|qui|de).+",
                        r"(?:cr√©e|cree|create).+(?:fonction|classe|script).+(?:pour|qui|de).+",
                        r"(?:d√©veloppe|developpe|develop).+(?:une|un).+(?:application|api|fonction|classe)",
                        r"(?:impl√©mente|implemente|implement).+(?:fonction|algorithme|classe|code)",
                        r"peux[- ]tu\s+(?:g√©n√®re|genere|cr√©e|cree|√©cris|ecris|faire|cr√©er).+(?:code|fonction|classe|script)",
                        r"j'ai besoin d'(?:une|un).+(?:fonction|code|script|classe).+(?:pour|qui|de)",
                        r"(?:code|programme|script|fonction).+(?:pour|qui).+(?:ajoute|concat|lit|lire|tri|trier|calcul)"
                    ],
                    "indicators": ["g√©n√®re", "genere", "generate", "cr√©e", "cree", "create", "√©cris", "ecris", "write", "fonction", "code", "programme", "script", "classe", "d√©veloppe", "impl√©mente"],
                    "weight": 2.0,  # Poids tr√®s √©lev√© pour prioriser la g√©n√©ration
                    "priority": "highest"
                },

                "programming_question": {
                    "patterns": [
                        r"comment\s+(?:utiliser|employer|se servir de).+(?:python|javascript|html|css)",
                        r"qu[\'']?est[- ]ce qu[\'']?(?:une|un).+(?:liste|dictionnaire|fonction|variable|classe|objet|array)",
                        r"comment\s+(?:on|peut[- ]on|faire|declare|d√©clare).+(?:variable|liste|fonction|dictionnaire)",
                        r"(?:syntaxe|√©criture).+(?:python|liste|fonction|boucle|condition)",
                        r"comment\s+(?:√©crit|ecrire|programmer|coder).+(?:en\s+python|une\s+fonction|une\s+liste)",
                        r"(?:apprendre|comprendre).+(?:python|programmation|les\s+listes|les\s+fonctions)",
                        r"(?:diff√©rence|difference)\s+entre.+(?:liste|dict|tuple|set)",
                        r"comment\s+(?:marche|fonctionne).+(?:les\s+listes|les\s+dictionnaires|python)",
                        r"c'est quoi.+(?:une liste|un dictionnaire|une fonction|une classe)"
                    ],
                    "indicators": ["python", "liste", "dictionnaire", "fonction", "variable", "comment", "syntaxe", "programmation", "diff√©rence"],
                    "weight": 1.3,
                    "priority": "high"
                },
                
                "internet_search": {
                    "patterns": [
                        r"^(?:cherche|recherche|trouve|search).+(?:sur internet|sur le web|en ligne|sur google)",
                        r"(?:cherche|recherche)\s+(?:sur\s+)?(?:internet|web|google|en ligne)\s+.+",
                        r"(?:recherche|trouve|cherche)\s+(?:moi\s+)?(?:des\s+)?(?:informations?\s+)?(?:sur|√† propos de)\s+.+",
                        r"(?:que dit|qu[\'']?est[- ]ce que dit|quelles sont les informations sur).+(?:internet|web)",
                        r"cherche[- ]moi\s+.+",
                        r"peux[- ]tu\s+(?:chercher|rechercher|trouver)\s+.+",
                        r"(?:informations?|info|donn√©es|news|actualit√©s?)\s+(?:sur|√† propos de|concernant)\s+.+",
                        r"(?:derni√®res?\s+)?(?:actualit√©s?|news|nouvelles?)\s+(?:sur|de|√† propos de)\s+.+",
                        r"qu[\'']?est[- ]ce\s+qu[\'']?on\s+dit\s+(?:sur|de)\s+.+\s+(?:sur internet|en ligne)",
                        r"(?:web|internet|google)\s+search\s+.+",
                        r"combien\s+(?:d[\'']?\s*)?(?:habitants?|personnes?|gens?).+(?:en?\s+)?(?:france|paris|lyon|marseille|toulouse)",
                        r"population\s+(?:de\s+la\s+)?france",
                        r"nombre\s+(?:d[\'']?\s*)?habitants?\s+(?:en?\s+)?france"
                    ],
                    "indicators": ["cherche", "recherche", "internet", "web", "google", "informations", "actualit√©s", "trouve", "news", "combien", "habitants", "population", "nombre", "france"],
                    "weight": 2.0,  # Augment√© encore plus pour garantir la priorit√©
                    "priority": "highest"
                },
                
                "greeting": {
                    "patterns": [
                        r"^(?:bonjour|salut|hello|hi|hey|coucou|slt|bjr|bsr)\b",
                        r"^(?:bonsoir|good evening)\b",
                        r"^(?:wesh|yo|wsh)\b"
                    ],
                    "indicators": ["bonjour", "salut", "hello", "slt", "bjr"],
                    "weight": 0.9,
                    "priority": "medium"
                },
                
                "help": {
                    "patterns": [
                        r"(?:aide|help|assist).+moi",
                        r"j'ai besoin d'aide",
                        r"^(?:aide|help)$"
                    ],
                    "indicators": ["aide", "help", "besoin"],
                    "weight": 0.9,
                    "priority": "medium"
                },
                
                "thank_you": {
                    "patterns": [
                        r"^merci\s*$",
                        r"^merci\s+beaucoup\s*$",
                        r"^merci\s+bien\s*$",
                        r"^merci\s+bcp\s*$",
                        r"^grand\s+merci\s*$",
                        r"^je\s+te\s+remercie\s*$",
                        r"^je\s+vous\s+remercie\s*$",
                        r"^thanks?\s*$",
                        r"^thx\s*$",
                        r"^mercy\s*$",
                        r"^mrci\s*$",
                        r"^(?:oui\s+)?merci\s*!*$",
                        r"^merci\s+vraiment\s*$",
                        r"^merci\s+√©norm√©ment\s*$",
                        r"^merci\s+infiniment\s*$"
                    ],
                    "indicators": ["merci", "thanks", "thx", "remercie"],
                    "weight": 1.0,
                    "priority": "high"
                },
                
                "goodbye": {
                    "patterns": [
                        r"^(?:au revoir|bye|√† bient√¥t|salut|ciao)\s*$",
                        r"^(?:je dois y aller|je me sauve|√† plus|@\+)\s*$",
                        r"^(?:bonne journ√©e|bonne soir√©e|bonne nuit)\s*$"
                    ],
                    "indicators": ["au revoir", "bye", "bient√¥t", "journ√©e", "soir√©e"],
                    "weight": 0.9,
                    "priority": "medium"
                },
                
                "affirmation": {
                    "patterns": [
                        r"^(?:oui|yes|yep|ouais|ok|d'accord|daccord)\s*$",
                        r"^(?:parfait|excellent|super|g√©nial|cool|top)\s*$",
                        r"^(?:tr√®s bien|c'est bon|√ßa marche)\s*$"
                    ],
                    "indicators": ["oui", "ok", "parfait", "bien", "marche"],
                    "weight": 0.8,
                    "priority": "medium"
                },
                
                "laughter": {
                    "patterns": [
                        r"^(?:ha+h*a+|h√©+h√©+|hi+hi+|ho+ho+)\s*$",
                        r"^(?:mdr|lol|ptdr|üòÇ|üòÑ|üòÅ|ü§£)\s*$",
                        r"^(?:haha+|ahah+|h√©h√©+|hihi+|hoho+)\s*$",
                        r"^(?:xd|xDD|:D|:p|:-D)\s*$"
                    ],
                    "indicators": ["haha", "h√©h√©", "hihi", "mdr", "lol", "üòÇ", "üòÑ"],
                    "weight": 1.0,
                    "priority": "high"
                },
                
                "compliment": {
                    "patterns": [
                        r"^(?:c'est dr√¥le|c'est rigolo|c est drole|c est rigolo)\s*!*$",
                        r"^(?:tu es dr√¥le|tu es rigolo|t'es dr√¥le|t'es rigolo|tu es drole)\s*!*$",
                        r"^(?:c'est marrant|c est marrant|marrant)\s*!*$",
                        r"^(?:c'est cool|c est cool|cool|sympa|g√©nial|super)\s*!*$",
                        r"^(?:bien jou√©|bravo|excellent|parfait|top)\s*!*$",
                        r"^(?:j'aime bien|j aime bien|tr√®s bien|tres bien)\s*!*$",
                        r"^(?:c'est bien|c est bien|pas mal|nice)\s*!*$"
                    ],
                    "indicators": ["dr√¥le", "rigolo", "marrant", "cool", "sympa", "g√©nial", "bravo", "excellent"],
                    "weight": 1.0,
                    "priority": "high"
                },
                
                "negation": {
                    "patterns": [
                        r"^(?:non|no|nope|pas|jamais|nan)\s*$",
                        r"^(?:pas du tout|absolument pas|certainement pas)\s*$"
                    ],
                    "indicators": ["non", "pas", "jamais", "absolument"],
                    "weight": 0.8,
                    "priority": "medium"
                }
            }
        }
    
    def detect_intent(self, text: str, context: Dict[str, Any] = None) -> Dict[str, float]:
        """D√©tecte l'intention avec am√©lioration contextuelle"""
        if not text or not isinstance(text, str):
            return {"unknown": 0.0}
            
        text_lower = text.lower().strip()
        normalized_text = self._normalize_text(text_lower)
        
        if context is None:
            context = {}
        
        scores = {}
        
        # Tri des intentions par priorit√©
        intents_by_priority = self._sort_intents_by_priority()
        
        for intent in intents_by_priority:
            config = self.patterns["intent_detection"][intent]
            score = 0.0
            
            # V√©rifier les exclusions
            exclude_terms = config.get("exclude_if", [])
            if any(term in normalized_text for term in exclude_terms):
                continue
            
            # V√©rification des patterns regex
            patterns = config.get("patterns", [])
            for pattern in patterns:
                try:
                    if re.search(pattern, normalized_text, re.IGNORECASE):
                        score += config.get("weight", 1.0) * 0.8
                        break  # Un seul pattern suffit
                except re.error:
                    continue
            
            # V√©rification des indicateurs
            indicators = config.get("indicators", [])
            for indicator in indicators:
                if self._fuzzy_match(indicator, normalized_text):
                    score += config.get("weight", 1.0) * 0.3
            
            # Boost contextuel
            context_boosts = config.get("context_boost", [])
            for boost_key in context_boosts:
                if context.get(boost_key, False):
                    score += 0.5
            
            if score > 0:
                scores[intent] = min(score, 1.0)
        
        # Si plusieurs intentions d√©tect√©es, privil√©gier celle avec la priorit√© la plus haute
        if len(scores) > 1:
            scores = self._resolve_intent_conflicts(scores)
        
        return scores if scores else {"unknown": 0.0}
    
    def _sort_intents_by_priority(self) -> List[str]:
        """Trie les intentions par priorit√©"""
        high_priority = []
        medium_priority = []
        low_priority = []
        
        for intent, config in self.patterns["intent_detection"].items():
            priority = config.get("priority", "low")
            if priority == "high":
                high_priority.append(intent)
            elif priority == "medium":
                medium_priority.append(intent)
            else:
                low_priority.append(intent)
        
        return high_priority + medium_priority + low_priority
    
    def _resolve_intent_conflicts(self, scores: Dict[str, float]) -> Dict[str, float]:
        """R√©sout les conflits entre intentions"""
        if not scores:
            return scores
        
        # R√®gles de priorit√© sp√©cifiques
        priority_rules = {
            "document_question": ["capabilities_question", "help"],  # Document > capacit√©s
            "code_question": ["capabilities_question", "help"],     # Code > capacit√©s  
            "identity_question": ["capabilities_question"],         # Identit√© > capacit√©s
        }
        
        for primary_intent, secondary_intents in priority_rules.items():
            if primary_intent in scores:
                for secondary in secondary_intents:
                    if secondary in scores:
                        # R√©duire le score de l'intention secondaire
                        scores[secondary] *= 0.3
        
        return scores
    
    def _normalize_text(self, text: str) -> str:
        """Normalise le texte avec tol√©rance aux fautes"""
        normalized = text
        
        # Corrections communes
        corrections = {
            r'\bslt\b': 'salut',
            r'\bbjr\b': 'bonjour', 
            r'\bexpliques?\b': 'explique',
            r'\bresumes?\b': 'r√©sume',
            r'\bgame\.py\b': 'game.py',
            r'\bprogrammes?\b': 'programme'
        }
        
        for pattern, replacement in corrections.items():
            normalized = re.sub(pattern, replacement, normalized, flags=re.IGNORECASE)
        
        return normalized
    
    def _fuzzy_match(self, target: str, text: str) -> bool:
        """Correspondance floue am√©lior√©e"""
        # V√©rification exacte
        if target.lower() in text.lower():
            return True
        
        # V√©rification avec variations
        variations = {
            "code": ["programme", "script", "fichier", "game"],
            "explique": ["expliquer", "expliques", "analyse", "analyser"],
            "r√©sume": ["resume", "r√©sum√©", "resumer"],
            "document": ["fichier", "pdf", "doc", "docx"]
        }
        
        if target in variations:
            return any(var in text.lower() for var in variations[target])
        
        return False
    
    def _similar_word(self, word1: str, word2: str) -> bool:
        """V√©rifie si deux mots sont similaires (tol√©rance aux fautes)"""
        if abs(len(word1) - len(word2)) > 2:
            return False
        
        # Calcul simple de distance d'√©dition
        differences = 0
        min_len = min(len(word1), len(word2))
        
        for i in range(min_len):
            if word1[i].lower() != word2[i].lower():
                differences += 1
                if differences > 2:  # Maximum 2 diff√©rences
                    return False
        
        return differences <= 2
    
    def extract_entities(self, text: str) -> Dict[str, List[str]]:
        """Extrait les entit√©s du texte"""
        text_lower = text.lower()
        entities = {}
        
        for entity_type, patterns in self.patterns["entity_extraction"].items():
            found_entities = []
            
            for pattern in patterns:
                matches = re.findall(pattern, text_lower, re.IGNORECASE)
                found_entities.extend(matches)
            
            if found_entities:
                entities[entity_type] = list(set(found_entities))
        
        return entities
    
    def analyze_context(self, text: str) -> Dict[str, Any]:
        """Analyse le contexte du texte"""
        text_lower = text.lower()
        context = {}
        
        for context_type, indicators in self.patterns["context_indicators"].items():
            found_indicators = []
            
            for indicator in indicators:
                if indicator.lower() in text_lower:
                    found_indicators.append(indicator)
            
            if found_indicators:
                context[context_type] = found_indicators
        
        return context
    
    def get_semantic_tokens(self, text: str) -> List[str]:
        """Extrait les tokens s√©mantiques du texte"""
        # Tokenisation basique
        tokens = re.findall(r'\b\w+\b', text.lower())
        
        # Filtrage des mots vides
        stop_words = {'le', 'la', 'les', 'un', 'une', 'des', 'de', 'du', 'et', 'ou', 'mais', 'donc', 'or', 'car', 'ni', 'que', 'qui', 'quoi', 'dont', 'o√π', 'il', 'elle', 'ils', 'elles', 'je', 'tu', 'nous', 'vous', 'me', 'te', 'se', 'ce', 'cet', 'cette', 'ces', 'mon', 'ton', 'son', 'ma', 'ta', 'sa', 'mes', 'tes', 'ses', 'notre', 'votre', 'leur', 'leurs', 'dans', 'sur', 'sous', 'avec', 'sans', 'pour', 'par', 'vers', 'chez', 'en', '√†', 'au', 'aux', 'du', 'des', 'est', 'sont', '√©t√©', '√™tre', 'avoir', 'ai', 'as', 'a', 'avons', 'avez', 'ont'}
        
        semantic_tokens = [token for token in tokens if token not in stop_words and len(token) > 2]
        
        return semantic_tokens
