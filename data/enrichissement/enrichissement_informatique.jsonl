{"input": "Quel est le code pour une condition en Python ?", "target": "if x > 0: print('Positif')"}
{"input": "Comment afficher un nombre aléatoire en Python ?", "target": "import random; print(random.randint(1, 10))"}
{"input": "Quel est le code pour une fonction lambda en Python ?", "target": "lambda x: x + 1"}
{"input": "Comment afficher tous les éléments d'une liste en Python ?", "target": "for x in ma_liste: print(x)"}
{"input": "Comment afficher le type d'une variable en Python ?", "target": "type(ma_var)"}
{"input": "Qu'est-ce qu'une adresse IP ?", "target": "Une **adresse IP (Internet Protocol)** est un identifiant unique attribué à chaque appareil connecté à un\nréseau informatique utilisant le protocole Internet. Elle permet d'acheminer les données entre les appareils\nsur un réseau local ou sur Internet.\nIl existe des adresses IPv4 (ex : 192.168.1.1) et IPv6 (ex : 2001:0db8:85a3::8a2e:0370:7334)."}
{"input": "À quoi sert un pare-feu informatique ?", "target": "Un **pare-feu (firewall)** est un dispositif de sécurité qui contrôle le trafic réseau entrant et sortant d'un\nordinateur ou d'un réseau. Il permet de bloquer les connexions non autorisées et de protéger contre les\nattaques extérieures, tout en autorisant les communications légitimes."}
{"input": "Qu'est-ce qu'un système d'exploitation ?", "target": "Un **système d'exploitation (OS)** est un logiciel qui gère le matériel d'un ordinateur et fournit des\nservices aux programmes applicatifs. Exemples : Windows, macOS, Linux, Android. Il gère la mémoire, les\nfichiers, les périphériques et l'exécution des applications."}
{"input": "Comment fonctionne le cloud computing ?", "target": "Le **cloud computing** consiste à utiliser des ressources informatiques (serveurs, stockage, applications)\nhébergées à distance et accessibles via Internet. Cela permet d'accéder à des services à la demande, de\nstocker des données en ligne et de bénéficier d'une grande flexibilité sans gérer l'infrastructure physique."}
{"input": "Qu'est-ce qu'un algorithme ?", "target": "Un **algorithme** est une suite d'instructions ou d'étapes permettant de résoudre un problème ou d'accomplir\nune tâche. En informatique, il s'agit d'une méthode logique et structurée, souvent traduite en code, pour\ntraiter des données ou automatiser des processus."}
{"input": "À quoi sert la virtualisation ?", "target": "La **virtualisation** permet d'exécuter plusieurs systèmes d'exploitation ou applications sur une même machine\nphysique, en créant des environnements virtuels isolés. Cela optimise l'utilisation des ressources, facilite\nla gestion et améliore la sécurité et la flexibilité des infrastructures informatiques."}
{"input": "Qu'est-ce qu'un réseau local (LAN) ?", "target": "Un **réseau local (LAN, Local Area Network)** est un réseau informatique limité à une zone géographique\nrestreinte, comme un bureau ou une maison. Il permet de connecter plusieurs appareils (ordinateurs,\nimprimantes, etc.) pour partager des ressources et des informations rapidement et en toute sécurité."}
{"input": "Qu'est-ce que le Big Data ?", "target": "Le **Big Data** désigne l'ensemble des **données massives** générées à grande vitesse et en grande variété par\nles entreprises, les objets connectés, les réseaux sociaux, etc. Leur volume, leur vélocité et leur variété\nnécessitent des outils et des technologies spécifiques pour les stocker, les traiter et en extraire de la\n**valeur** (ex : Hadoop, Spark)."}
{"input": "Qu'est-ce qu'un data lake ?", "target": "Un **data lake** est un espace de stockage centralisé permettant de conserver de grandes quantités de\n**données brutes** (structurées ou non) à l'échelle. Il facilite l'analyse, la transformation et\nl'exploitation des données par les équipes de **data science** et d'**IA**."}
{"input": "Quelle est la différence entre machine learning et deep learning ?", "target": "Le **machine learning** (apprentissage automatique) regroupe les techniques permettant à un ordinateur\nd'apprendre à partir de **données** sans être explicitement programmé. Le **deep learning** (apprentissage\nprofond) est une sous-catégorie du machine learning qui utilise des **réseaux de neurones artificiels** à\nplusieurs couches pour traiter des données complexes (images, texte, etc.)."}
{"input": "Qu'est-ce qu'un modèle d'intelligence artificielle ?", "target": "Un **modèle d'IA** est un programme ou un algorithme capable d'effectuer des tâches habituellement réservées à\nl'humain, comme la reconnaissance d'images, la compréhension du langage ou la prise de décision. Il est\nentraîné à partir de **données** pour apprendre des **patterns** et faire des prédictions ou des\nclassifications."}
{"input": "À quoi sert un data scientist ?", "target": "Un **data scientist** est un expert qui collecte, analyse et interprète de grandes quantités de **données**\npour en extraire des **informations utiles**. Il utilise des techniques de **statistiques**, de **machine\nlearning** et de **visualisation** pour aider à la prise de décision et à l'innovation dans l'entreprise."}
{"input": "Qu'est-ce qu'un algorithme de classification ?", "target": "Un **algorithme de classification** est un type d'algorithme de **machine learning** qui permet d'attribuer\nune **étiquette** ou une **catégorie** à une donnée en fonction de ses caractéristiques. Exemples :\nclassification d'e-mails en spam/non-spam, reconnaissance d'images, etc."}
{"input": "Qu'est-ce qu'un jeu de données d'entraînement ?", "target": "Un **jeu de données d'entraînement** (training set) est un ensemble de **données** utilisé pour entraîner un\n**modèle d'IA** ou de **machine learning**. Il contient des exemples pour permettre au modèle d'apprendre à\nreconnaître des patterns et à faire des prédictions sur de nouvelles données."}
{"input": "Qu'est-ce que le traitement du langage naturel (NLP) ?", "target": "Le **traitement du langage naturel** (NLP, Natural Language Processing) est une branche de l'**IA** qui vise à\npermettre aux ordinateurs de comprendre, analyser et générer du **langage humain** (texte ou parole). Exemples\n: traduction automatique, analyse de sentiments, chatbots."}
{"input": "Qu'est-ce qu'un réseau de neurones artificiels ?", "target": "Un **réseau de neurones artificiels** est un modèle d'**IA** inspiré du fonctionnement du cerveau humain. Il\nest composé de **couches** de neurones interconnectés qui traitent l'information et permettent d'apprendre des\ntâches complexes comme la reconnaissance d'images ou la traduction automatique."}
{"input": "Qu'est-ce qu'une base de données relationnelle ?", "target": "Une **base de données relationnelle** est un système de gestion de données organisé en tables reliées entre\nelles par des clés. Elle permet de stocker, organiser et interroger efficacement de grandes quantités\nd'informations structurées. Exemples : MySQL, PostgreSQL, Oracle."}
{"input": "À quoi sert le langage SQL ?", "target": "Le **langage SQL (Structured Query Language)** permet de manipuler et d'interroger des bases de données\nrelationnelles. Il sert à créer, modifier, supprimer des tables et à effectuer des requêtes pour extraire ou\nmettre à jour des données."}
{"input": "Qu'est-ce qu'une API ?", "target": "Une **API (Application Programming Interface)** est un ensemble de règles et de protocoles qui permet à\ndifférents logiciels de communiquer entre eux. Elle facilite l'intégration de services et de fonctionnalités\nexternes dans une application."}
{"input": "Qu'est-ce que le versionnage de code ?", "target": "Le **versionnage de code** consiste à utiliser un système (comme Git) pour suivre les modifications apportées\nau code source d'un projet. Cela permet de collaborer, de revenir à des versions précédentes et de gérer les\névolutions du logiciel."}
{"input": "À quoi sert un serveur web ?", "target": "Un **serveur web** est un logiciel ou un matériel qui héberge des sites web et répond aux requêtes des\nnavigateurs en envoyant des pages web via le protocole HTTP ou HTTPS."}
{"input": "Qu'est-ce qu'un objet en programmation orientée objet ?", "target": "Un **objet** est une entité qui regroupe des données (attributs) et des comportements (méthodes). En\nprogrammation orientée objet, il permet de modéliser des éléments du monde réel ou des concepts abstraits."}
{"input": "Qu'est-ce qu'un fichier JSON ?", "target": "Un **fichier JSON (JavaScript Object Notation)** est un format léger d'échange de données, facile à lire et à\nécrire pour les humains et les machines. Il est largement utilisé pour stocker et transmettre des données\nentre applications."}
{"input": "Comment installer une bibliothèque en Python ?", "target": "Pour installer une bibliothèque en Python, on utilise généralement la commande `pip install\nnom_de_la_bibliotheque` dans le terminal ou l'invite de commandes."}
{"input": "À quoi sert le langage HTML ?", "target": "Le **langage HTML (HyperText Markup Language)** sert à structurer le contenu des pages web. Il définit les\ntitres, paragraphes, liens, images, tableaux, etc."}
{"input": "Qu'est-ce qu'une variable en programmation ?", "target": "Une **variable** est un espace de stockage nommé qui permet de conserver une valeur (nombre, texte, etc.)\npendant l'exécution d'un programme."}
{"input": "Qu'est-ce qu'une exception en Python ?", "target": "Une **exception** est une erreur qui se produit pendant l'exécution d'un programme. En Python, on peut les\ngérer avec les blocs `try` et `except` pour éviter l'arrêt brutal du programme."}
{"input": "Comment lire un fichier texte en Python ?", "target": "On peut lire un fichier texte en Python avec : `with open('fichier.txt', 'r') as f: contenu = f.read()`"}
{"input": "Qu'est-ce qu'une clé primaire en base de données ?", "target": "Une **clé primaire** est un identifiant unique pour chaque enregistrement d'une table dans une base de données\nrelationnelle. Elle garantit l'unicité des données."}
{"input": "Qu'est-ce qu'un commit dans Git ?", "target": "Un **commit** dans Git correspond à un enregistrement des modifications apportées au code source. Il permet de\nconserver un historique des changements."}
{"input": "Qu'est-ce qu'un framework ?", "target": "Un **framework** est un ensemble d'outils et de composants réutilisables qui facilitent le développement\nd'applications en fournissant une structure de base."}
{"input": "Qu'est-ce qu'un système d'exploitation mobile ?", "target": "Un **système d'exploitation mobile** est un logiciel qui gère le matériel et les applications d'un appareil\nmobile comme un smartphone ou une tablette. Exemples : Android, iOS."}
{"input": "Qu'est-ce qu'un navigateur web ?", "target": "Un **navigateur web** est un logiciel qui permet d'accéder et d'afficher des pages web sur Internet. Exemples\n: Chrome, Firefox, Safari, Edge."}
{"input": "Qu'est-ce qu'un protocole réseau ?", "target": "Un **protocole réseau** est un ensemble de règles qui définissent la manière dont les données sont échangées\nentre les appareils sur un réseau. Exemples : HTTP, FTP, TCP/IP."}
{"input": "Qu'est-ce qu'un logiciel open source ?", "target": "Un **logiciel open source** est un programme dont le code source est accessible à tous, modifiable et\nredistribuable librement. Exemples : Linux, LibreOffice, Firefox."}
{"input": "Qu'est-ce qu'un mot de passe fort ?", "target": "Un **mot de passe fort** est une combinaison complexe de lettres, chiffres et caractères spéciaux, difficile à\ndeviner ou à pirater. Il doit être long et unique pour chaque service."}
{"input": "Qu'est-ce qu'un ransomware ?", "target": "Un **ransomware** est un logiciel malveillant qui chiffre les fichiers d'un utilisateur et demande une rançon\npour les déchiffrer."}
{"input": "Qu'est-ce qu'un cookie sur Internet ?", "target": "Un **cookie** est un petit fichier stocké sur l'ordinateur d'un utilisateur par un site web pour mémoriser des\ninformations comme les préférences ou l'identifiant de session."}
{"input": "Qu'est-ce qu'un réseau privé virtuel (VPN) ?", "target": "Un **VPN (Virtual Private Network)** est un service qui crée une connexion sécurisée et chiffrée entre\nl'utilisateur et Internet, protégeant la vie privée et permettant d'accéder à des contenus géo-restreints."}
{"input": "Qu'est-ce qu'un serveur DNS ?", "target": "Un **serveur DNS (Domain Name System)** traduit les noms de domaine (ex : www.example.com) en adresses IP\ncompréhensibles par les ordinateurs pour accéder aux sites web."}
{"input": "Qu'est-ce qu'une sauvegarde informatique ?", "target": "Une **sauvegarde informatique** consiste à copier et stocker des données sur un support externe ou dans le\ncloud afin de pouvoir les restaurer en cas de perte ou de panne."}
{"input": "Qu'est-ce qu'un réseau Wi-Fi ?", "target": "Un **réseau Wi-Fi** est un réseau sans fil qui permet aux appareils de se connecter à Internet ou à un réseau\nlocal via des ondes radio, sans utiliser de câbles physiques."}
{"input": "Qu'est-ce qu'une adresse MAC ?", "target": "Une **adresse MAC (Media Access Control)** est un identifiant unique attribué à chaque carte réseau d'un\nappareil. Elle sert à identifier les appareils sur un réseau local."}
{"input": "Qu'est-ce qu'un serveur proxy ?", "target": "Un **serveur proxy** est un intermédiaire entre un utilisateur et Internet. Il permet d'anonymiser la\nnavigation, de filtrer le trafic ou de contourner des restrictions d'accès."}
{"input": "Qu'est-ce qu'un logiciel antivirus ?", "target": "Un **logiciel antivirus** est un programme conçu pour détecter, bloquer et supprimer les logiciels\nmalveillants (virus, vers, chevaux de Troie, etc.) sur un ordinateur ou un réseau."}
{"input": "Qu'est-ce que TypeScript et pourquoi l'utiliser ?", "target": "**TypeScript** est un sur-ensemble de JavaScript qui ajoute un **typage statique**. Avantages : détection\nd'erreurs à la compilation, meilleure auto-complétion, code plus maintenable, support des dernières\nfonctionnalités ES6+. Compilé vers JavaScript standard."}
{"input": "Explique le concept de programmation fonctionnelle.", "target": "**Programmation fonctionnelle** : paradigme basé sur les **fonctions pures** (sans effets de bord),\nl'**immutabilité** des données, et l'**évitement des états partagés**. Concepts clés : higher-order functions,\nrécursion, map/filter/reduce. Langages : Haskell, Clojure, F#. Avantages : code plus prévisible,\nparallélisation facilitée."}
{"input": "Qu'est-ce que Docker et comment ça fonctionne ?", "target": "**Docker** est une plateforme de **conteneurisation** qui empaquette applications + dépendances dans des\n**containers** légers. Un container partage le noyau OS mais isole l'application. Avantages : portabilité,\ncohérence environnements dev/prod, déploiement rapide. Architecture : Docker Engine, Images, Containers,\nRegistry."}
{"input": "Comment fonctionne le protocole HTTPS ?", "target": "**HTTPS** (HTTP Secure) sécurise HTTP avec **TLS/SSL**. Processus : 1) Handshake TLS (échange certificats,\nclés), 2) Chiffrement symétrique des données, 3) Vérification intégrité. Utilise **chiffrement asymétrique**\npour l'échange de clés puis **symétrique** pour les données. Port 443 par défaut."}
{"input": "Qu'est-ce que Kubernetes et son utilité ?", "target": "**Kubernetes** (K8s) est un **orchestrateur de containers** qui automatise déploiement, scaling, et gestion\nd'applications conteneurisées. Concepts clés : Pods, Services, Deployments, Namespaces. Avantages :\nauto-healing, load balancing, rolling updates, service discovery, gestion ressources."}
{"input": "Explique l'architecture REST et ses principes.", "target": "**REST** (Representational State Transfer) : style architectural pour APIs web. Principes : 1) **Stateless**\n(sans état), 2) **Uniform interface** (HTTP verbs), 3) **Resource-based** (URLs), 4) **Cacheable**, 5)\n**Layered system**. Verbes HTTP : GET (read), POST (create), PUT (update), DELETE (remove)."}
{"input": "Qu'est-ce que Node.js et son écosystème ?", "target": "**Node.js** : runtime JavaScript côté serveur basé sur le moteur **V8** de Chrome. Caractéristiques :\n**asynchrone**, **event-driven**, **single-threaded** avec event loop. Écosystème : npm (gestionnaire\npaquets), Express.js (framework web), nombreuses librairies. Use cases : APIs, real-time apps, microservices."}
{"input": "Comment fonctionnent les bases de données NoSQL ?", "target": "**NoSQL** : bases non-relationnelles pour données non-structurées. Types : 1) **Document** (MongoDB), 2)\n**Key-Value** (Redis), 3) **Column-family** (Cassandra), 4) **Graph** (Neo4j). Avantages : scalabilité\nhorizontale, flexibilité schéma, performance. Trade-offs : consistance éventuelle vs ACID."}
{"input": "Qu'est-ce que l'architecture microservices ?", "target": "**Microservices** : architecture décomposant applications en **services indépendants** communicant via APIs.\nAvantages : déploiements indépendants, technos diversifiées, équipes autonomes, scalabilité granulaire. Défis\n: complexité réseau, gestion transactions distribuées, monitoring. Patterns : API Gateway, Service Discovery,\nCircuit Breaker."}
{"input": "Explique le concept de CI/CD (Intégration Continue).", "target": "**CI/CD** : pratiques DevOps d'automatisation. **CI** (Continuous Integration) : intégration fréquente code +\ntests automatisés. **CD** (Continuous Delivery/Deployment) : livraison/déploiement automatisés. Pipeline\ntypique : commit → build → test → deploy. Outils : Jenkins, GitLab CI, GitHub Actions, Azure DevOps."}
{"input": "Qu'est-ce que GraphQL et ses avantages ?", "target": "**GraphQL** : langage de requête et runtime pour APIs. Avantages vs REST : 1) **Une seule endpoint**, 2)\n**Requêtes précises** (pas d'over/under-fetching), 3) **Typage fort**, 4) **Introspection**. Concepts :\nSchema, Resolvers, Queries/Mutations/Subscriptions. Outils : Apollo, Relay."}
{"input": "Comment fonctionne le machine learning supervisé ?", "target": "**ML Supervisé** : apprentissage avec données **étiquetées** (input-output). Types : **Classification**\n(catégories) et **Régression** (valeurs continues). Processus : 1) Training set → 2) Algorithme → 3) Modèle →\n4) Prédictions. Algorithmes populaires : Random Forest, SVM, Neural Networks, XGBoost. Évaluation :\ncross-validation, métriques performance."}
{"input": "Qu'est-ce que Redis et ses cas d'usage ?", "target": "**Redis** : base de données **in-memory** key-value, très rapide. Structures : strings, hashes, lists, sets,\nsorted sets. Use cases : 1) **Cache** (sessions, query results), 2) **Pub/Sub** messaging, 3)\n**Leaderboards**, 4) **Rate limiting**. Persistance optionnelle, clustering pour scalabilité."}
{"input": "Explique l'architecture MVC en détail.", "target": "**MVC** (Model-View-Controller) : pattern architectural séparant responsabilités. **Model** : données +\nlogique métier. **View** : interface utilisateur. **Controller** : gestion interactions, orchestration. Flux :\nUser → Controller → Model → Controller → View → User. Avantages : séparation concerns, testabilité,\nmaintenabilité."}
{"input": "Qu'est-ce que WebSocket et quand l'utiliser ?", "target": "**WebSocket** : protocole communication **bidirectionnelle** en temps réel sur TCP. Contrairement HTTP\n(request-response), maintient connexion ouverte. Use cases : chat en temps réel, notifications push, jeux\nmultijoueurs, trading platforms, collaboration. API : onopen, onmessage, onclose, onerror."}
{"input": "Comment fonctionne l'authentification JWT ?", "target": "**JWT** (JSON Web Token) : standard pour transmettre informations sécurisées. Structure :\nHeader.Payload.Signature (Base64). Processus : 1) Login → 2) Serveur génère JWT → 3) Client stocke token → 4)\nEnvoi token dans headers. Avantages : stateless, scalable, cross-domain. Sécurité : HTTPS obligatoire,\nexpiration, rotation."}
{"input": "Qu'est-ce que l'Event Sourcing ?", "target": "**Event Sourcing** : pattern stockant **séquence d'événements** au lieu d'état actuel. Chaque changement =\névénement immutable. Rebuild état en rejouant événements. Avantages : audit trail complet, time travel,\ndebugging facilité. Défis : complexité queries, snapshots pour performance. Combine souvent avec CQRS."}
{"input": "Explique les Web Components et leur intérêt.", "target": "**Web Components** : standards web pour créer **éléments HTML réutilisables**. Technologies : 1) **Custom\nElements**, 2) **Shadow DOM** (encapsulation), 3) **HTML Templates**. Avantages : framework-agnostic,\nréutilisabilité, encapsulation CSS/JS. Libraries : Lit, Stencil. Support natif navigateurs modernes."}
{"input": "Qu'est-ce que Progressive Web App (PWA) ?", "target": "**PWA** : applications web avec expérience **native-like**. Caractéristiques : 1) **Service Workers** (cache,\noffline), 2) **Manifest** (installable), 3) **HTTPS**, 4) **Responsive**. Avantages : performance, engagement\nutilisateur, déploiement web standard. Technologies : Workbox, manifest.json, push notifications."}
{"input": "Comment fonctionne le load balancing ?", "target": "**Load Balancing** : distribution trafic entre plusieurs serveurs. Types : 1) **Round Robin**, 2) **Least\nConnections**, 3) **IP Hash**, 4) **Weighted**. Niveaux : Layer 4 (transport) vs Layer 7 (application).\nSolutions : Nginx, HAProxy, AWS ELB, Cloudflare. Health checks pour détecter serveurs défaillants."}
{"input": "Qu'est-ce que TensorFlow et PyTorch ?", "target": "**TensorFlow** (Google) et **PyTorch** (Meta) : frameworks **deep learning**. TensorFlow : production-ready,\nTensorBoard, TFLite mobile. PyTorch : recherche-friendly, dynamic graphs, pythonic. Concepts communs :\ntensors, computational graphs, automatic differentiation. Écosystème : Keras (high-level), Hugging Face\n(transformers)."}
{"input": "Explique le concept de serverless computing.", "target": "**Serverless** : modèle où cloud provider gère infrastructure. Developer focus sur **fonctions** (FaaS).\nCaractéristiques : auto-scaling, pay-per-execution, stateless. Services : AWS Lambda, Azure Functions, Google\nCloud Functions. Use cases : APIs, data processing, IoT backends. Limitations : cold starts, vendor lock-in."}
{"input": "Qu'est-ce que WebRTC et ses applications ?", "target": "**WebRTC** : technologie **communication temps réel** navigateur-à-navigateur. Capacités : audio/vidéo, data\nchannels, sans plugins. Protocoles : STUN/TURN (NAT traversal), ICE (connectivity). Applications :\nvisioconférence, gaming P2P, file sharing. APIs : getUserMedia, RTCPeerConnection, RTCDataChannel."}
{"input": "Comment fonctionne le DNS et ses types d'enregistrements ?", "target": "**DNS** : système résolution noms de domaine → adresses IP. Processus : 1) Cache local → 2) Recursive resolver\n→ 3) Root servers → 4) TLD servers → 5) Authoritative servers. Types records : **A** (IPv4), **AAAA** (IPv6),\n**CNAME** (alias), **MX** (mail), **TXT** (text), **NS** (nameserver)."}
{"input": "Qu'est-ce que gRPC et ses avantages ?", "target": "**gRPC** : framework **RPC** haute performance de Google. Utilise **Protocol Buffers** + HTTP/2. Avantages :\n1) **Performance** (binaire), 2) **Streaming** (bidirectionnel), 3) **Type safety**, 4) **Multi-language**.\nFeatures : load balancing, authentication, monitoring. Vs REST : plus rapide mais moins human-readable."}
{"input": "Explique l'architecture Event-Driven.", "target": "**Event-Driven Architecture** : communication via **événements asynchrones**. Composants : Event Producers,\nEvent Routers, Event Consumers. Patterns : Publish-Subscribe, Event Sourcing, CQRS. Technologies : Apache\nKafka, RabbitMQ, AWS EventBridge. Avantages : découplage, scalabilité, résilience. Défis : debugging complexe,\neventual consistency."}
{"input": "Qu'est-ce que Blockchain et ses cas d'usage ?", "target": "**Blockchain** : registre distribué **immutable** avec blocs chaînés cryptographiquement. Concepts : hashing,\nconsensus (PoW, PoS), smart contracts. Types : publique (Bitcoin), privée (Hyperledger), consortium. Use cases\n: cryptocurrencies, supply chain, voting, identity management. Technologies : Ethereum, Solidity, Web3."}
{"input": "Comment optimiser les performances frontend ?", "target": "**Optimisation Frontend** : 1) **Bundle splitting** (code splitting), 2) **Lazy loading** (images, routes), 3)\n**Caching** (browser, CDN), 4) **Compression** (Gzip, Brotli), 5) **Minification** CSS/JS, 6) **Critical\nCSS**, 7) **Service Workers**, 8) **Web Vitals** (LCP, FID, CLS). Outils : Lighthouse, WebPageTest."}
{"input": "Qu'est-ce que l'architecture Clean et ses principes ?", "target": "**Clean Architecture** (Uncle Bob) : structure logicielle **indépendante des frameworks**.\n**Couches :**\n1) **Entities** (business rules)\n2) **Use Cases** (application logic)\n3) **Interface Adapters**\n4) **Frameworks**\nRègle dépendance : couches internes ignorent externes.\nAvantages : testabilité, maintenabilité, flexibilité technologique."}
{"input": "Explique le protocole OAuth 2.0.", "target": "**OAuth 2.0** : framework **autorisation** (pas authentification).\nRôles : Resource Owner, Client,Authorization Server, Resource Server.\nFlows : Authorization Code, Implicit, Client Credentials, Password.\nTokens : Access token (court terme), Refresh token (long terme).\nSécurité : PKCE pour mobile, state parameter CSRF."}
{"input": "Qu'est-ce que Apache Kafka et son architecture ?", "target": "**Apache Kafka** : plateforme **streaming** distribuée.\nConcepts : Topics (catégories), Partitions (parallélisme), Producers/Consumers, Consumer Groups.\nArchitecture : Brokers (serveurs), ZooKeeper (coordination), Replication (fault tolerance).\nUse cases : real-time analytics, log aggregation, event sourcing, microservices communication."}
{"input": "Comment fonctionne le garbage collection ?", "target": "**Garbage Collection** : gestion automatique mémoire pour récupérer objets non référencés. Algorithmes : 1)\n**Mark & Sweep**, 2) **Reference Counting**, 3) **Generational** (jeunes/vieux objets). Implémentations : JVM\n(G1, ZGC), .NET (Workstation/Server), Python (reference counting + cycle detection). Trade-offs : throughput\nvs latency."}
{"input": "Qu'est-ce que l'architecture CQRS ?", "target": "**CQRS** (Command Query Responsibility Segregation) : séparation **lecture** (Query) et **écriture**\n(Command). Modèles dédiés pour read/write, bases données potentiellement différentes. Avantages : optimisation\nspécifique, scalabilité indépendante. Combine souvent avec Event Sourcing. Complexité accrue mais performance\naméliorée."}
{"input": "Explique les patterns de concurrence en programmation.", "target": "**Patterns Concurrence** : 1) **Mutex/Lock** (exclusion mutuelle), 2) **Semaphore** (comptage ressources), 3)\n**Actor Model** (Erlang, Akka), 4) **CSP** (Go channels), 5) **Async/Await** (JavaScript, C#), 6) **Thread\nPool**. Défis : race conditions, deadlocks, starvation. Solutions : immutabilité, message passing."}
{"input": "Qu'est-ce que WebAssembly (WASM) ?", "target": "**WebAssembly** : format binaire portable pour exécution **haute performance** dans navigateurs. Langages\nsource : C/C++, Rust, Go, C#. Avantages : vitesse proche native, sandbox sécurisé, multi-platform. Use cases :\ngaming, CAD, compression, crypto. Outils : Emscripten, wasm-pack. Futur : WASI (system interface)."}
{"input": "Comment implémenter la sécurité API ?", "target": "**Sécurité API** : 1) **Authentification** (API keys, JWT, OAuth), 2) **Autorisation** (RBAC, ABAC), 3)\n**Validation input** (schema validation), 4) **Rate limiting**, 5) **HTTPS enforcement**, 6) **CORS**\nconfiguration, 7) **Logging/Monitoring**, 8) **SQL injection** protection. Standards : OpenAPI Security\nSchemes."}
{"input": "Qu'est-ce que Terraform et Infrastructure as Code ?", "target": "**Infrastructure as Code** : gestion infrastructure via **code déclaratif**. **Terraform** : outil HashiCorp\nmulti-cloud. Concepts : Providers, Resources, State, Modules. Workflow : terraform init → plan → apply.\nAvantages : versioning, reproducibilité, collaboration. Alternatives : CloudFormation (AWS), ARM (Azure),\nPulumi."}
{"input": "Explique l'architecture hexagonale (Ports & Adapters).", "target": "**Architecture Hexagonale** : isole logique métier via **ports** (interfaces) et **adapters**\n(implémentations). Core business au centre, adapters périphérie. Avantages : testabilité (mock adapters),\nindépendance technologique, évolutivité. Patterns : Dependency Injection, Repository Pattern. Facilite TDD et\nclean architecture."}
{"input": "Qu'est-ce que Elasticsearch et son écosystème ?", "target": "**Elasticsearch** : moteur recherche/analytics **distribué** basé sur Lucene. **ELK Stack** : Elasticsearch\n(search), Logstash (data processing), Kibana (visualization). Concepts : Index, Documents, Shards, Replicas.\nUse cases : search engines, log analytics, monitoring, observability. Features : full-text search,\naggregations, machine learning."}
{"input": "Comment fonctionne HTTP/2 et ses améliorations ?", "target": "**HTTP/2** : version **binaire** d'HTTP avec multiplexing. Améliorations vs HTTP/1.1 : 1) **Multiplexing**\n(requêtes parallèles), 2) **Server Push**, 3) **Header compression** (HPACK), 4) **Stream prioritization**.\nPas besoin HTTPS mais souvent couplé. HTTP/3 : utilise QUIC (UDP) pour latence réduite."}
{"input": "Qu'est-ce que Domain-Driven Design (DDD) ?", "target": "**Domain-Driven Design** : approche développement centrée sur **domaine métier**. Concepts : Ubiquitous\nLanguage, Bounded Contexts, Entities, Value Objects, Aggregates, Domain Services. Patterns tactiques vs\nstratégiques. Avantages : alignement business-tech, code expressif, évolutivité complexe. Challenge : courbe\napprentissage."}
{"input": "Explique les tests en pyramide (Testing Pyramid).", "target": "**Testing Pyramid** : stratégie tests équilibrée. Base : **Unit tests** (nombreux, rapides, isolés). Milieu :\n**Integration tests** (composants, APIs). Sommet : **E2E tests** (peu, lents, fragiles). Complément :\n**Contract tests**, **Performance tests**. Objectif : feedback rapide, confiance déploiement. Anti-pattern :\nIce Cream Cone."}
{"input": "Qu'est-ce que l'observabilité (Observability) ?", "target": "**Observabilité** : capacité comprendre état système via **outputs**. 3 piliers : 1) **Metrics** (métriques),\n2) **Logs** (journaux), 3) **Traces** (tracking requêtes). vs Monitoring (alertes prédéfinies). Tools :\nPrometheus, Grafana, Jaeger, ELK. OpenTelemetry : standard unifié. SLI/SLO : indicateurs/objectifs service."}
{"input": "Comment fonctionne Istio Service Mesh ?", "target": "**Istio** : **service mesh** pour microservices. Composants : 1) **Data Plane** (Envoy proxies), 2) **Control\nPlane** (Pilot, Citadel, Galley). Features : traffic management, security (mTLS), observability, policy\nenforcement. Avantages : réseau transparent, sécurité zero-trust, monitoring automatique. Alternative :\nLinkerd, Consul Connect."}
{"input": "Qu'est-ce que Flutter et Dart ?", "target": "**Flutter** : framework UI **cross-platform** de Google. Langage **Dart** : compilation native + hot reload.\nArchitecture : widgets, rendering engine Skia. Avantages : performance native, UI cohérente, single codebase.\nPlateformes : mobile, web, desktop. vs React Native : pas de bridge, contrôle pixel-perfect."}
{"input": "Explique les design patterns les plus utilisés.", "target": "**Design Patterns essentiels** : 1) **Singleton** (instance unique), 2) **Factory** (création objets), 3)\n**Observer** (notifications), 4) **Strategy** (algorithmes interchangeables), 5) **Decorator** (ajout\nfonctionnalités), 6) **Repository** (abstraction données), 7) **MVC/MVP/MVVM** (separation concerns). Gang of\nFour : Creational, Structural, Behavioral."}
{"input": "Qu'est-ce que RxJS et la programmation réactive ?", "target": "**RxJS** : library **reactive programming** JavaScript avec **Observables**. Concepts : Streams (flux\ndonnées), Operators (transformation), Subscriptions. Patterns : map, filter, merge, debounce, switchMap. Use\ncases : gestion événements asynchrones, APIs, real-time data. Avantages : composition, gestion erreurs,\nannulation."}
{"input": "Comment fonctionne NGINX et ses cas d'usage ?", "target": "**NGINX** : serveur web **haute performance** + reverse proxy. Architecture **event-driven** (vs thread-based\nApache). Use cases : 1) **Static content** serving, 2) **Load balancing**, 3) **Reverse proxy**, 4) **SSL\ntermination**, 5) **Caching**, 6) **API Gateway**. Configuration : blocks (server, location), upstreams."}
{"input": "Qu'est-ce que GraphDB et les bases de données graphes ?", "target": "**Bases de données graphes** : stockage relations comme **citizens first-class**. Modèle : Nodes (entités),\nEdges (relations), Properties. Languages : Cypher (Neo4j), Gremlin (TinkerPop). Use cases : social networks,\nfraud detection, recommendation engines, knowledge graphs. vs Relationnel : traversals naturels, schéma\nflexible."}
{"input": "Explique le CAP theorem et ses implications.", "target": "**CAP Theorem** : impossible garantir simultanément **Consistency**, **Availability**, **Partition tolerance**\ndans système distribué. Trade-offs : 1) **CA** (impossible réseau), 2) **CP** (MongoDB, HBase), 3) **AP**\n(Cassandra, DynamoDB). Reality : partition tolerance obligatoire, choisir C vs A. BASE vs ACID approaches."}
{"input": "Qu'est-ce que DevSecOps et ses pratiques ?", "target": "**DevSecOps** : intégration **sécurité** dans pipeline DevOps dès le début. Practices : 1) **Security as\nCode**, 2) **SAST/DAST** (static/dynamic analysis), 3) **Dependency scanning**, 4) **Container security**, 5)\n**Compliance automation**, 6) **Threat modeling**. Tools : SonarQube, OWASP ZAP, Twistlock. Shift-left\nsecurity mindset."}
{"input": "Comment fonctionne ElasticSearch query DSL ?", "target": "**Elasticsearch Query DSL** : langage requêtes **JSON** flexible. Types : 1) **Match queries** (full-text), 2)\n**Term queries** (exact), 3) **Bool queries** (combinaison), 4) **Range queries** (intervalles), 5)\n**Aggregations** (analytics). Features : scoring, filtering, highlighting, suggestions. Performance : index\ndesign, mapping optimization."}
{"input": "Qu'est-ce que Apache Spark et son écosystème ?", "target": "**Apache Spark** : engine **analytics** distributed pour big data. Modules : 1) **Spark Core** (RDDs), 2)\n**Spark SQL** (DataFrames), 3) **MLlib** (machine learning), 4) **GraphX** (graph processing), 5)\n**Streaming**. Languages : Scala, Python, Java, R. vs Hadoop MapReduce : in-memory computing, 100x faster."}
{"input": "Explique les protocoles de consensus distribués.", "target": "**Consensus distribués** : accord entre nœuds sur état partagé. Algorithmes : 1) **RAFT** (leader-based,\nunderstandable), 2) **PBFT** (Byzantine fault tolerance), 3) **Paxos** (theoretical foundation), 4)\n**PoW/PoS** (blockchain). Challenges : network partitions, Byzantine failures. Applications : distributed\ndatabases, blockchain, coordination services."}
{"input": "Qu'est-ce que WebGL et ses applications ?", "target": "**WebGL** : API **3D graphics** dans navigateurs basée sur OpenGL ES. Capabilities : shaders\n(vertex/fragment), textures, buffers. Libraries : Three.js (high-level), Babylon.js, A-Frame (VR). Use cases :\ndata visualization, gaming, CAD, VR/AR. WebGL 2.0 : plus de features OpenGL ES 3.0."}
{"input": "Comment implémenter la recherche full-text efficace ?", "target": "**Recherche full-text** : 1) **Indexation** (inverted index), 2) **Tokenization** (stemming, stop words), 3)\n**Scoring** (TF-IDF, BM25), 4) **Fuzzy matching** (edit distance). Solutions : Elasticsearch, Solr, PostgreSQL\nFTS. Features : auto-complete, faceted search, highlighting, synonyms. Performance : index optimization,\ncaching."}
{"input": "Qu'est-ce que l'Edge Computing et ses avantages ?", "target": "**Edge Computing** : traitement données **près des sources** (vs cloud centralisé). Avantages : 1) **Latence\nréduite**, 2) **Bande passante économisée**, 3) **Privacy** (données locales), 4) **Résilience** (offline\ncapability). Use cases : IoT, autonomous vehicles, AR/VR, real-time analytics. Technologies : edge servers,\nCDN, fog computing."}
{"input": "Explique l'architecture Lambda et Kappa pour big data.", "target": "**Lambda Architecture** : 1) **Batch layer** (historical data), 2) **Speed layer** (real-time), 3) **Serving\nlayer** (query). **Kappa Architecture** : stream-only (Kafka + stream processing). Lambda : complexité 2\nsystèmes. Kappa : unified streaming. Tools : Spark, Storm, Flink, Kafka Streams. Choice depends on\nlatency/complexity requirements."}
{"input": "Qu'est-ce que WebXR et l'avenir de la réalité virtuelle ?", "target": "**WebXR** : standards web pour **VR/AR** dans navigateurs.\nAPIs : WebXR Device API, WebGL, WebRTC.\nAvantages : pas d'installation, cross-platform, standards ouverts.\nHardware : Oculus, HTC Vive, mobile headsets.\nApplications : training, education, e-commerce, social VR.\nChallenges : performance, input methods, ecosystem maturity."}
{"input": "Qu'est-ce qu'un réseau peer-to-peer (P2P) ?", "target": "Un **réseau peer-to-peer (P2P)** est un réseau dans lequel chaque appareil peut agir à la fois comme client et\ncomme serveur, partageant directement des ressources sans passer par un serveur central."}
{"input": "Qu'est-ce qu'une imprimante réseau ?", "target": "Une **imprimante réseau** est une imprimante connectée à un réseau local, accessible par plusieurs\nutilisateurs sans connexion directe par câble à chaque ordinateur."}
{"input": "Qu'est-ce qu'un centre de données (data center) ?", "target": "Un **centre de données (data center)** est un lieu physique regroupant de nombreux serveurs et équipements\ninformatiques pour stocker, traiter et gérer de grandes quantités de données."}
{"input": "Qu'est-ce qu'un pare-feu matériel ?", "target": "Un **pare-feu matériel** est un appareil dédié à la protection d'un réseau contre les intrusions et les\nattaques, en filtrant le trafic entrant et sortant au niveau du matériel."}
{"input": "Qu'est-ce qu'une attaque par phishing ?", "target": "Le **phishing** est une technique de fraude visant à tromper un utilisateur pour qu'il communique des\ninformations sensibles (identifiants, mots de passe) en se faisant passer pour un tiers de confiance."}
{"input": "Qu'est-ce qu'une licence logicielle ?", "target": "Une **licence logicielle** est un contrat qui définit les conditions d'utilisation, de distribution et de\nmodification d'un logiciel."}
{"input": "Qui t'as codé ?", "target": "J'ai été codé par **Nicolas GOUY**. Retrouvez-le sur [GitHub](https://github.com/gonicolas12) et sur [LinkedIn](https://www.linkedin.com/in/nicolas-gouy-99120932b/)."}
{"input": "Qui t'as programmé ?", "target": "J'ai été progammé par **Nicolas GOUY**. Retrouvez-le sur [GitHub](https://github.com/gonicolas12) et sur [LinkedIn](https://www.linkedin.com/in/nicolas-gouy-99120932b/)."}
{"input": "Par qui tu as été codé ?", "target": "J'ai été codé par **Nicolas GOUY**. Retrouvez-le sur [GitHub](https://github.com/gonicolas12) et sur [LinkedIn](https://www.linkedin.com/in/nicolas-gouy-99120932b/)."}
{"input": "Par qui as tu été codé ?", "target": "J'ai été codé par **Nicolas GOUY**. Retrouvez-le sur [GitHub](https://github.com/gonicolas12) et sur [LinkedIn](https://www.linkedin.com/in/nicolas-gouy-99120932b/)."}
{"input": "Par qui as tu été programmé ?", "target": "J'ai été programmé par **Nicolas GOUY**. Retrouvez-le sur [GitHub](https://github.com/gonicolas12) et sur [LinkedIn](https://www.linkedin.com/in/nicolas-gouy-99120932b/)."}
{"input": "Qu'est-ce que l'authentification multifacteur (MFA) ?", "target": "La MFA exige plusieurs preuves d'identité (mot de passe, code temporaire, biométrie) pour renforcer la\nsécurité d'accès."}
{"input": "Quelle est la différence entre chiffrement symétrique et asymétrique ?", "target": "Le chiffrement symétrique utilise une même clé pour chiffrer/déchiffrer; l'asymétrique utilise une paire de\nclés publique/privée pour sécuriser les échanges et l'authentification."}
{"input": "Qu'est-ce qu'une clé SSH ?", "target": "Une clé SSH est une paire de clés publique/privée utilisée pour authentifier de façon sécurisée l'accès à des\nserveurs sans mot de passe."}
{"input": "Qu'est-ce qu'un conteneur (ex : Docker) ?", "target": "Un conteneur encapsule une application et ses dépendances pour l'exécuter isolément et de façon portable sur\nn'importe quel hôte compatible."}
{"input": "À quoi sert Kubernetes ?", "target": "Kubernetes orchestre le déploiement, la mise à l'échelle et la gestion des conteneurs dans des clusters de\nserveurs."}
{"input": "Qu'est-ce que l'edge computing ?", "target": "L'edge computing traite les données proche de leur source (capteurs, appareils) pour réduire la latence et la\ncharge réseau."}
{"input": "Qu'est-ce que l'Internet des objets (IoT) ?", "target": "L'IoT désigne des objets connectés qui collectent et échangent des données via Internet pour automatiser et\nmonitorer des processus."}
{"input": "Qu'est-ce qu'une API REST ?", "target": "Une API REST permet la communication entre systèmes via HTTP en utilisant des ressources identifiables et des\nméthodes standard (GET, POST, PUT, DELETE)."}
{"input": "Qu'est-ce que OAuth ?", "target": "OAuth est un protocole d'autorisation qui permet à une application d'accéder à des ressources utilisateur sans\npartager les identifiants."}
{"input": "Qu'est-ce que la latence réseau ?", "target": "La latence est le délai de transmission d'une donnée entre deux points d'un réseau, mesuré en millisecondes."}
{"input": "Qu'est-ce que la bande passante (débit) ?", "target": "La bande passante correspond à la quantité de données transférables par unité de temps sur une connexion\nréseau (exprimée en Mbps)."}
{"input": "Quelle est la différence entre SSD et HDD ?", "target": "Les SSD utilisent de la mémoire flash pour des accès rapides; les HDD sont des disques magnétiques plus lents\nmais souvent moins coûteux par Go."}
{"input": "Qu'est-ce qu'un RAID ?", "target": "Le RAID combine plusieurs disques pour améliorer la performance, la redondance ou les deux, selon le niveau\n(RAID 0, 1, 5, 10, ...)."}
{"input": "Qu'est-ce que la haute disponibilité (HA) ?", "target": "La HA vise à minimiser les interruptions de service via la redondance, le basculement automatique et la\ntolérance aux pannes."}
{"input": "Qu'est-ce qu'un certificat SSL/TLS ?", "target": "Un certificat SSL/TLS chiffre les communications entre un client et un serveur et authentifie l'identité du\nserveur via une autorité de certification."}
{"input": "Qu'est-ce qu'un système embarqué ?", "target": "Un **système embarqué** est un dispositif informatique intégré dans un appareil pour contrôler, surveiller ou\nassister son fonctionnement (ex : voiture, électroménager, objets connectés)."}
{"input": "Qu'est-ce qu'un réseau 5G ?", "target": "La **5G** est la cinquième génération de réseaux mobiles, offrant des débits plus élevés, une latence réduite\net la capacité de connecter davantage d'appareils simultanément."}
{"input": "Qu'est-ce qu'un QR code ?", "target": "Un **QR code** est un code-barres en deux dimensions qui permet de stocker des informations lisibles\nrapidement par un smartphone ou un scanner."}
{"input": "Qu'est-ce que la réalité augmentée ?", "target": "La **réalité augmentée** superpose des éléments virtuels (images, informations) à la perception du monde réel\nvia un écran ou des lunettes spéciales."}
{"input": "Qu'est-ce que la blockchain ?", "target": "La **blockchain** est une technologie de stockage et de transmission d'informations, transparente et\nsécurisée, fonctionnant sans organe central. Elle est utilisée notamment pour les cryptomonnaies."}
{"input": "Qu'est-ce qu'une cryptomonnaie ?", "target": "Une **cryptomonnaie** est une monnaie numérique décentralisée, sécurisée par la cryptographie et fonctionnant\ngénéralement sur une blockchain (ex : Bitcoin, Ethereum)."}
{"input": "Qu'est-ce qu'un code-barres ?", "target": "Un **code-barres** est une représentation graphique de données sous forme de barres et d'espaces, utilisée\npour identifier rapidement des produits."}
{"input": "Qu'est-ce qu'un robot industriel ?", "target": "Un **robot industriel** est une machine programmable utilisée dans les usines pour automatiser des tâches\nrépétitives ou dangereuses."}
{"input": "Qu'est-ce qu'une imprimante 3D ?", "target": "Une **imprimante 3D** est un appareil qui fabrique des objets physiques en superposant des couches de matériau\nà partir d'un modèle numérique."}
{"input": "Qu'est-ce que la cybersécurité ?", "target": "La **cybersécurité** regroupe l'ensemble des pratiques et technologies visant à protéger les systèmes\ninformatiques et les données contre les attaques et les accès non autorisés."}
{"input": "Qu'est-ce que le DevOps ?", "target": "**DevOps** : pratiques combinant développement (Dev) et opérations IT (Ops) pour automatisation, collaboration et livraison continue."}
{"input": "Qu'est-ce que CI/CD ?", "target": "**CI/CD** : Intégration Continue / Déploiement Continu. Automatisation tests et déploiements pour livraison rapide et fiable."}
{"input": "Qu'est-ce que l'architecture serverless ?", "target": "**Serverless** : modèle cloud où le fournisseur gère l'infrastructure. Developer focus sur code (Functions as a Service)."}
{"input": "Qu'est-ce que GraphQL ?", "target": "**GraphQL** : langage de requête pour APIs permettant de demander précisément les données souhaitées, alternative à REST."}
{"input": "Qu'est-ce que le TDD ?", "target": "**TDD** (Test-Driven Development) : écrire tests AVANT le code. Cycle : Red (test échoue) → Green (code passe) → Refactor."}
{"input": "Qu'est-ce que Git ?", "target": "**Git** : système de contrôle de version distribué pour suivre modifications code, collaborer et gérer historique projets."}
{"input": "Qu'est-ce qu'un conteneur Docker ?", "target": "**Container Docker** : environnement isolé empaquetant application + dépendances, portable sur n'importe quel système compatible."}
{"input": "Qu'est-ce que Kubernetes ?", "target": "**Kubernetes** (K8s) : orchestrateur de conteneurs automatisant déploiement, scaling et gestion d'applications conteneurisées."}
{"input": "Qu'est-ce qu'un microservice ?", "target": "**Microservice** : architecture décomposant applications en services indépendants, chacun responsable d'une fonctionnalité spécifique."}
{"input": "Qu'est-ce que le cloud computing ?", "target": "**Cloud computing** : accès à ressources informatiques (serveurs, stockage, applications) via Internet, à la demande."}
{"input": "Qu'est-ce qu'AWS ?", "target": "**AWS** (Amazon Web Services) : plateforme cloud computing d'Amazon offrant 200+ services (EC2, S3, Lambda, RDS...)."}
{"input": "Qu'est-ce que JSON ?", "target": "**JSON** (JavaScript Object Notation) : format léger d'échange de données, lisible par humains et machines."}
{"input": "Qu'est-ce que SQL ?", "target": "**SQL** (Structured Query Language) : langage pour manipuler bases de données relationnelles (SELECT, INSERT, UPDATE, DELETE)."}
{"input": "Qu'est-ce que NoSQL ?", "target": "**NoSQL** : bases de données non-relationnelles pour données non-structurées. Types : document, clé-valeur, colonnes, graphes."}
{"input": "Qu'est-ce que MongoDB ?", "target": "**MongoDB** : base de données NoSQL orientée documents, stockant données en JSON-like (BSON), flexible et scalable."}
{"input": "Qu'est-ce que Redis ?", "target": "**Redis** : base de données in-memory clé-valeur ultra-rapide, utilisée pour cache, sessions, files d'attente."}
{"input": "Qu'est-ce que React ?", "target": "**React** : bibliothèque JavaScript de Facebook pour construire interfaces utilisateur avec composants réutilisables."}
{"input": "Qu'est-ce que Node.js ?", "target": "**Node.js** : environnement JavaScript côté serveur basé sur moteur V8, asynchrone et event-driven."}
{"input": "Qu'est-ce que Python ?", "target": "**Python** : langage de programmation de haut niveau, polyvalent, lisible, utilisé en web, data science, IA, automatisation."}
{"input": "Qu'est-ce que Java ?", "target": "**Java** : langage orienté objet, portable (JVM), utilisé en entreprise, Android, applications desktop et web."}
{"input": "Qu'est-ce que TypeScript ?", "target": "**TypeScript** : sur-ensemble de JavaScript ajoutant typage statique pour code plus robuste et maintenable."}
{"input": "Qu'est-ce que la complexité algorithmique ?", "target": "**Complexité** : mesure efficacité algorithme. **Temporelle** : temps exécution. **Spatiale** : mémoire utilisée. Notation Big O."}
{"input": "Donne-moi un exemple de décorateur Python avec paramètres.", "target": "Voici un **décorateur avec paramètres** en Python :\n\n```python\nimport functools\nimport time\n\ndef retry(max_attempts=3, delay=1):\n    \"\"\"Décorateur qui réessaie une fonction en cas d'échec.\"\"\"\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            attempts = 0\n            while attempts < max_attempts:\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    attempts += 1\n                    if attempts == max_attempts:\n                        raise e\n                    print(f\"Tentative {attempts} échouée, retry dans {delay}s...\")\n                    time.sleep(delay)\n        return wrapper\n    return decorator\n\n# Utilisation\n@retry(max_attempts=5, delay=2)\ndef fetch_data(url):\n    # Code qui peut échouer\n    pass\n```\n\n**Structure à 3 niveaux :**\n1. Fonction externe : reçoit les **paramètres** du décorateur\n2. Décorateur : reçoit la **fonction** décorée\n3. Wrapper : exécute la **logique**"}
{"input": "Comment implémenter un context manager en Python ?", "target": "Deux façons d'implémenter un **context manager** :\n\n**1. Avec une classe (__enter__ / __exit__) :**\n```python\nclass DatabaseConnection:\n    def __init__(self, host, port):\n        self.host = host\n        self.port = port\n        self.connection = None\n    \n    def __enter__(self):\n        print(f\"Connexion à {self.host}:{self.port}\")\n        self.connection = self._connect()\n        return self.connection\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        print(\"Fermeture de la connexion\")\n        self.connection.close()\n        return False  # Ne pas supprimer les exceptions\n\n# Utilisation\nwith DatabaseConnection('localhost', 5432) as conn:\n    conn.execute('SELECT * FROM users')\n```\n\n**2. Avec @contextmanager (plus simple) :**\n```python\nfrom contextlib import contextmanager\n\n@contextmanager\ndef timer():\n    start = time.time()\n    yield  # Point d'exécution du bloc with\n    elapsed = time.time() - start\n    print(f\"Temps écoulé: {elapsed:.2f}s\")\n\nwith timer():\n    heavy_computation()\n```"}
{"input": "Comment créer une API async avec FastAPI ?", "target": "Exemple d'**API asynchrone** avec **FastAPI** :\n\n```python\nfrom fastapi import FastAPI, HTTPException, Depends\nfrom pydantic import BaseModel\nfrom typing import Optional\nimport asyncio\nimport httpx\n\napp = FastAPI(title=\"Mon API Async\")\n\n# Modèles Pydantic\nclass User(BaseModel):\n    id: Optional[int] = None\n    name: str\n    email: str\n\nclass UserResponse(BaseModel):\n    user: User\n    message: str\n\n# Dépendance async\nasync def get_db():\n    db = await create_async_connection()\n    try:\n        yield db\n    finally:\n        await db.close()\n\n# Routes async\n@app.get(\"/users/{user_id}\", response_model=UserResponse)\nasync def get_user(user_id: int, db = Depends(get_db)):\n    user = await db.fetch_one(\"SELECT * FROM users WHERE id = ?\", user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return UserResponse(user=user, message=\"Success\")\n\n# Appels HTTP async\n@app.get(\"/external\")\nasync def fetch_external():\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\"https://api.example.com/data\")\n        return response.json()\n\n# Tâches parallèles\n@app.get(\"/parallel\")\nasync def parallel_calls():\n    async with httpx.AsyncClient() as client:\n        tasks = [\n            client.get(\"https://api1.com\"),\n            client.get(\"https://api2.com\"),\n        ]\n        results = await asyncio.gather(*tasks)\n    return [r.json() for r in results]\n```"}
{"input": "Comment implémenter le pattern Observer en Python ?", "target": "Le **pattern Observer** pour la notification d'événements :\n\n```python\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\n# Interface Observer\nclass Observer(ABC):\n    @abstractmethod\n    def update(self, event: str, data: dict) -> None:\n        pass\n\n# Interface Subject (Observable)\nclass Subject(ABC):\n    @abstractmethod\n    def attach(self, observer: Observer) -> None:\n        pass\n    \n    @abstractmethod\n    def detach(self, observer: Observer) -> None:\n        pass\n    \n    @abstractmethod\n    def notify(self, event: str, data: dict) -> None:\n        pass\n\n# Implémentation concrète\nclass EventManager(Subject):\n    def __init__(self):\n        self._observers: List[Observer] = []\n    \n    def attach(self, observer: Observer) -> None:\n        self._observers.append(observer)\n    \n    def detach(self, observer: Observer) -> None:\n        self._observers.remove(observer)\n    \n    def notify(self, event: str, data: dict) -> None:\n        for observer in self._observers:\n            observer.update(event, data)\n\n# Observers concrets\nclass EmailNotifier(Observer):\n    def update(self, event: str, data: dict) -> None:\n        print(f\"📧 Email: {event} - {data}\")\n\nclass SlackNotifier(Observer):\n    def update(self, event: str, data: dict) -> None:\n        print(f\"💬 Slack: {event} - {data}\")\n\n# Utilisation\nmanager = EventManager()\nmanager.attach(EmailNotifier())\nmanager.attach(SlackNotifier())\n\nmanager.notify(\"user_registered\", {\"user\": \"Alice\"})\n```"}
{"input": "Comment créer un générateur infini en Python ?", "target": "Les **générateurs infinis** produisent des valeurs à la demande :\n\n```python\nfrom typing import Generator, Iterator\nimport itertools\n\n# Générateur infini simple\ndef infinite_counter(start: int = 0) -> Generator[int, None, None]:\n    \"\"\"Compteur infini.\"\"\"\n    n = start\n    while True:\n        yield n\n        n += 1\n\n# Générateur de Fibonacci infini\ndef fibonacci() -> Generator[int, None, None]:\n    \"\"\"Suite de Fibonacci infinie.\"\"\"\n    a, b = 0, 1\n    while True:\n        yield a\n        a, b = b, a + b\n\n# Générateur cyclique\ndef cycle_colors() -> Generator[str, None, None]:\n    \"\"\"Cycle infini de couleurs.\"\"\"\n    colors = ['rouge', 'vert', 'bleu']\n    while True:\n        for color in colors:\n            yield color\n\n# Utilisation avec itertools\nfrom itertools import islice, takewhile, count\n\n# Prendre les 10 premiers\nfirst_10 = list(islice(fibonacci(), 10))\nprint(first_10)  # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n\n# Prendre tant que condition vraie\nless_than_100 = list(takewhile(lambda x: x < 100, fibonacci()))\n\n# itertools.count() : compteur infini intégré\nfor i, item in zip(count(), ['a', 'b', 'c']):\n    print(i, item)  # 0 a, 1 b, 2 c\n```\n\n**Avantage clé :**\n- Mémoire **constante** (une seule valeur en mémoire)"}
{"input": "Comment implémenter un pool de connexions en Python ?", "target": "Un **pool de connexions** réutilise les connexions coûteuses :\n\n```python\nimport queue\nimport threading\nfrom contextlib import contextmanager\nfrom typing import Any\n\nclass Connection:\n    \"\"\"Simule une connexion DB.\"\"\"\n    def __init__(self, id: int):\n        self.id = id\n        self.in_use = False\n    \n    def execute(self, query: str) -> str:\n        return f\"Connection {self.id}: {query}\"\n    \n    def close(self):\n        print(f\"Connection {self.id} fermée\")\n\nclass ConnectionPool:\n    \"\"\"Pool de connexions thread-safe.\"\"\"\n    \n    def __init__(self, max_size: int = 10):\n        self.max_size = max_size\n        self._pool: queue.Queue = queue.Queue(max_size)\n        self._size = 0\n        self._lock = threading.Lock()\n        \n        # Pré-créer les connexions\n        for i in range(max_size):\n            self._pool.put(Connection(i))\n    \n    @contextmanager\n    def get_connection(self, timeout: float = 30):\n        \"\"\"Obtient une connexion du pool.\"\"\"\n        conn = None\n        try:\n            conn = self._pool.get(timeout=timeout)\n            conn.in_use = True\n            yield conn\n        finally:\n            if conn:\n                conn.in_use = False\n                self._pool.put(conn)\n    \n    def close_all(self):\n        \"\"\"Ferme toutes les connexions.\"\"\"\n        while not self._pool.empty():\n            conn = self._pool.get_nowait()\n            conn.close()\n\n# Utilisation\npool = ConnectionPool(max_size=5)\n\nwith pool.get_connection() as conn:\n    result = conn.execute(\"SELECT * FROM users\")\n    print(result)\n\n# Avec threading\ndef worker(pool, worker_id):\n    with pool.get_connection() as conn:\n        print(conn.execute(f\"Query from worker {worker_id}\"))\n\nthreads = [threading.Thread(target=worker, args=(pool, i)) for i in range(10)]\n[t.start() for t in threads]\n[t.join() for t in threads]\n```"}
{"input": "Comment créer un système de cache LRU en Python ?", "target": "Implémentation d'un **cache LRU** (Least Recently Used) :\n\n```python\nfrom collections import OrderedDict\nfrom functools import wraps\nfrom typing import Any, Optional\nimport threading\n\nclass LRUCache:\n    \"\"\"Cache LRU thread-safe.\"\"\"\n    \n    def __init__(self, capacity: int = 100):\n        self.capacity = capacity\n        self.cache: OrderedDict = OrderedDict()\n        self.lock = threading.RLock()\n    \n    def get(self, key: str) -> Optional[Any]:\n        with self.lock:\n            if key not in self.cache:\n                return None\n            # Déplacer à la fin (most recently used)\n            self.cache.move_to_end(key)\n            return self.cache[key]\n    \n    def put(self, key: str, value: Any) -> None:\n        with self.lock:\n            if key in self.cache:\n                self.cache.move_to_end(key)\n            self.cache[key] = value\n            # Supprimer le plus ancien si capacité dépassée\n            if len(self.cache) > self.capacity:\n                self.cache.popitem(last=False)\n    \n    def clear(self) -> None:\n        with self.lock:\n            self.cache.clear()\n    \n    def __len__(self) -> int:\n        return len(self.cache)\n\n# Décorateur de cache LRU personnalisé\ndef lru_cache_custom(maxsize: int = 128):\n    \"\"\"Décorateur avec cache LRU.\"\"\"\n    cache = LRUCache(maxsize)\n    \n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            key = str(args) + str(sorted(kwargs.items()))\n            result = cache.get(key)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.put(key, result)\n            return result\n        wrapper.cache = cache\n        return wrapper\n    return decorator\n\n# Utilisation\n@lru_cache_custom(maxsize=100)\ndef expensive_computation(n: int) -> int:\n    return sum(i**2 for i in range(n))\n\n# Ou utilisez simplement functools.lru_cache\nfrom functools import lru_cache\n\n@lru_cache(maxsize=128)\ndef fibonacci(n: int) -> int:\n    if n < 2:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n```"}
{"input": "Comment implémenter une file de tâches async en Python ?", "target": "Une **file de tâches asynchrone** avec workers :\n\n```python\nimport asyncio\nfrom dataclasses import dataclass\nfrom typing import Callable, Any, Optional\nfrom datetime import datetime\nimport uuid\n\n@dataclass\nclass Task:\n    id: str\n    func: Callable\n    args: tuple\n    kwargs: dict\n    created_at: datetime\n    result: Optional[Any] = None\n    error: Optional[Exception] = None\n\nclass AsyncTaskQueue:\n    \"\"\"File de tâches avec workers async.\"\"\"\n    \n    def __init__(self, num_workers: int = 3):\n        self.queue: asyncio.Queue = asyncio.Queue()\n        self.num_workers = num_workers\n        self.workers: list = []\n        self.results: dict = {}\n        self._running = False\n    \n    async def add_task(self, func: Callable, *args, **kwargs) -> str:\n        \"\"\"Ajoute une tâche à la file.\"\"\"\n        task = Task(\n            id=str(uuid.uuid4()),\n            func=func,\n            args=args,\n            kwargs=kwargs,\n            created_at=datetime.now()\n        )\n        await self.queue.put(task)\n        return task.id\n    \n    async def worker(self, worker_id: int):\n        \"\"\"Worker qui traite les tâches.\"\"\"\n        while self._running:\n            try:\n                task = await asyncio.wait_for(\n                    self.queue.get(), \n                    timeout=1.0\n                )\n                print(f\"Worker {worker_id} traite {task.id}\")\n                try:\n                    if asyncio.iscoroutinefunction(task.func):\n                        task.result = await task.func(*task.args, **task.kwargs)\n                    else:\n                        task.result = task.func(*task.args, **task.kwargs)\n                except Exception as e:\n                    task.error = e\n                finally:\n                    self.results[task.id] = task\n                    self.queue.task_done()\n            except asyncio.TimeoutError:\n                continue\n    \n    async def start(self):\n        \"\"\"Démarre les workers.\"\"\"\n        self._running = True\n        self.workers = [\n            asyncio.create_task(self.worker(i))\n            for i in range(self.num_workers)\n        ]\n    \n    async def stop(self):\n        \"\"\"Arrête les workers.\"\"\"\n        await self.queue.join()  # Attend que toutes les tâches soient terminées\n        self._running = False\n        await asyncio.gather(*self.workers, return_exceptions=True)\n\n# Utilisation\nasync def main():\n    queue = AsyncTaskQueue(num_workers=3)\n    await queue.start()\n    \n    # Ajouter des tâches\n    async def fetch_url(url):\n        await asyncio.sleep(1)  # Simule un appel réseau\n        return f\"Data from {url}\"\n    \n    task_ids = [\n        await queue.add_task(fetch_url, f\"https://api{i}.com\")\n        for i in range(10)\n    ]\n    \n    await queue.stop()\n    \n    # Récupérer les résultats\n    for task_id in task_ids:\n        task = queue.results[task_id]\n        print(f\"{task_id}: {task.result}\")\n\nasyncio.run(main())\n```"}
{"input": "Comment créer un ORM simple en Python ?", "target": "Un **mini-ORM** avec métaclasses Python :\n\n```python\nfrom typing import Any, Optional, List\nimport sqlite3\n\nclass Field:\n    \"\"\"Représente un champ de table.\"\"\"\n    def __init__(self, field_type: str, primary_key: bool = False):\n        self.field_type = field_type\n        self.primary_key = primary_key\n        self.name: Optional[str] = None\n\nclass IntegerField(Field):\n    def __init__(self, primary_key: bool = False):\n        super().__init__('INTEGER', primary_key)\n\nclass TextField(Field):\n    def __init__(self):\n        super().__init__('TEXT')\n\nclass ModelMeta(type):\n    \"\"\"Métaclasse pour les modèles.\"\"\"\n    def __new__(mcs, name, bases, namespace):\n        fields = {}\n        for key, value in namespace.items():\n            if isinstance(value, Field):\n                value.name = key\n                fields[key] = value\n        namespace['_fields'] = fields\n        namespace['_table_name'] = name.lower() + 's'\n        return super().__new__(mcs, name, bases, namespace)\n\nclass Model(metaclass=ModelMeta):\n    \"\"\"Classe de base pour les modèles.\"\"\"\n    _connection: Optional[sqlite3.Connection] = None\n    \n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n    \n    @classmethod\n    def connect(cls, db_path: str):\n        cls._connection = sqlite3.connect(db_path)\n    \n    @classmethod\n    def create_table(cls):\n        columns = []\n        for name, field in cls._fields.items():\n            col = f\"{name} {field.field_type}\"\n            if field.primary_key:\n                col += \" PRIMARY KEY AUTOINCREMENT\"\n            columns.append(col)\n        sql = f\"CREATE TABLE IF NOT EXISTS {cls._table_name} ({', '.join(columns)})\"\n        cls._connection.execute(sql)\n        cls._connection.commit()\n    \n    def save(self):\n        fields = [f for f in self._fields if not self._fields[f].primary_key]\n        values = [getattr(self, f, None) for f in fields]\n        placeholders = ', '.join(['?' for _ in fields])\n        sql = f\"INSERT INTO {self._table_name} ({', '.join(fields)}) VALUES ({placeholders})\"\n        cursor = self._connection.execute(sql, values)\n        self.id = cursor.lastrowid\n        self._connection.commit()\n    \n    @classmethod\n    def all(cls) -> List['Model']:\n        cursor = cls._connection.execute(f\"SELECT * FROM {cls._table_name}\")\n        results = []\n        for row in cursor.fetchall():\n            obj = cls()\n            for i, field_name in enumerate(cls._fields.keys()):\n                setattr(obj, field_name, row[i])\n            results.append(obj)\n        return results\n\n# Utilisation\nclass User(Model):\n    id = IntegerField(primary_key=True)\n    name = TextField()\n    email = TextField()\n\nModel.connect(':memory:')\nUser.create_table()\n\nuser = User(name=\"Alice\", email=\"alice@example.com\")\nuser.save()\n\nfor u in User.all():\n    print(f\"{u.id}: {u.name} ({u.email})\")\n```"}
{"input": "Comment implémenter le pattern State en Python ?", "target": "Le **pattern State** pour gérer les états d'un objet :\n\n```python\nfrom abc import ABC, abstractmethod\n\nclass State(ABC):\n    \"\"\"Interface pour les états.\"\"\"\n    \n    @abstractmethod\n    def handle_request(self, context: 'Context') -> None:\n        pass\n    \n    @abstractmethod\n    def __str__(self) -> str:\n        pass\n\nclass Context:\n    \"\"\"Contexte qui maintient l'état courant.\"\"\"\n    \n    def __init__(self, initial_state: State):\n        self._state = initial_state\n    \n    @property\n    def state(self) -> State:\n        return self._state\n    \n    @state.setter\n    def state(self, new_state: State) -> None:\n        print(f\"Transition: {self._state} → {new_state}\")\n        self._state = new_state\n    \n    def request(self) -> None:\n        self._state.handle_request(self)\n\n# Exemple: Machine à états d'une commande\nclass OrderState(State):\n    pass\n\nclass DraftState(OrderState):\n    def handle_request(self, context: Context) -> None:\n        print(\"Commande soumise\")\n        context.state = PendingState()\n    \n    def __str__(self) -> str:\n        return \"Brouillon\"\n\nclass PendingState(OrderState):\n    def handle_request(self, context: Context) -> None:\n        print(\"Paiement reçu\")\n        context.state = PaidState()\n    \n    def __str__(self) -> str:\n        return \"En attente de paiement\"\n\nclass PaidState(OrderState):\n    def handle_request(self, context: Context) -> None:\n        print(\"Commande expédiée\")\n        context.state = ShippedState()\n    \n    def __str__(self) -> str:\n        return \"Payée\"\n\nclass ShippedState(OrderState):\n    def handle_request(self, context: Context) -> None:\n        print(\"Commande livrée\")\n        context.state = DeliveredState()\n    \n    def __str__(self) -> str:\n        return \"Expédiée\"\n\nclass DeliveredState(OrderState):\n    def handle_request(self, context: Context) -> None:\n        print(\"Commande déjà livrée !\")\n    \n    def __str__(self) -> str:\n        return \"Livrée\"\n\n# Utilisation\norder = Context(DraftState())\n\nfor _ in range(5):\n    print(f\"État actuel: {order.state}\")\n    order.request()\n```"}
{"input": "Comment créer un système de plugins en Python ?", "target": "Un **système de plugins** dynamique en Python :\n\n```python\nimport importlib\nimport pkgutil\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Type, List\nfrom pathlib import Path\nimport sys\n\nclass Plugin(ABC):\n    \"\"\"Interface pour tous les plugins.\"\"\"\n    \n    @property\n    @abstractmethod\n    def name(self) -> str:\n        pass\n    \n    @property\n    @abstractmethod\n    def version(self) -> str:\n        pass\n    \n    @abstractmethod\n    def execute(self, *args, **kwargs) -> any:\n        pass\n\nclass PluginManager:\n    \"\"\"Gestionnaire de plugins.\"\"\"\n    \n    def __init__(self, plugins_dir: str = \"plugins\"):\n        self.plugins_dir = Path(plugins_dir)\n        self._plugins: Dict[str, Plugin] = {}\n        self._registry: Dict[str, Type[Plugin]] = {}\n    \n    def discover_plugins(self) -> List[str]:\n        \"\"\"Découvre les plugins dans le répertoire.\"\"\"\n        discovered = []\n        \n        # Ajouter le dossier plugins au path\n        if str(self.plugins_dir) not in sys.path:\n            sys.path.insert(0, str(self.plugins_dir))\n        \n        for finder, name, ispkg in pkgutil.iter_modules([str(self.plugins_dir)]):\n            try:\n                module = importlib.import_module(name)\n                \n                # Chercher les classes Plugin\n                for attr_name in dir(module):\n                    attr = getattr(module, attr_name)\n                    if (isinstance(attr, type) and \n                        issubclass(attr, Plugin) and \n                        attr is not Plugin):\n                        self._registry[attr_name] = attr\n                        discovered.append(attr_name)\n                        print(f\"Plugin découvert: {attr_name}\")\n            except Exception as e:\n                print(f\"Erreur chargement {name}: {e}\")\n        \n        return discovered\n    \n    def load_plugin(self, name: str) -> Plugin:\n        \"\"\"Charge et instancie un plugin.\"\"\"\n        if name in self._plugins:\n            return self._plugins[name]\n        \n        if name not in self._registry:\n            raise ValueError(f\"Plugin '{name}' non trouvé\")\n        \n        plugin = self._registry[name]()\n        self._plugins[name] = plugin\n        print(f\"Plugin chargé: {plugin.name} v{plugin.version}\")\n        return plugin\n    \n    def execute_plugin(self, name: str, *args, **kwargs) -> any:\n        \"\"\"Exécute un plugin.\"\"\"\n        plugin = self.load_plugin(name)\n        return plugin.execute(*args, **kwargs)\n    \n    def list_plugins(self) -> List[str]:\n        \"\"\"Liste tous les plugins disponibles.\"\"\"\n        return list(self._registry.keys())\n\n# Exemple de plugin (fichier plugins/hello_plugin.py)\n'''\nfrom plugin_system import Plugin\n\nclass HelloPlugin(Plugin):\n    @property\n    def name(self) -> str:\n        return \"Hello\"\n    \n    @property\n    def version(self) -> str:\n        return \"1.0.0\"\n    \n    def execute(self, name: str = \"World\") -> str:\n        return f\"Hello, {name}!\"\n'''\n\n# Utilisation\nmanager = PluginManager(\"plugins\")\nmanager.discover_plugins()\n\nresult = manager.execute_plugin(\"HelloPlugin\", name=\"Alice\")\nprint(result)  # \"Hello, Alice!\"\n```"}
{"input": "Comment créer des dataclasses avancées en Python ?", "target": "Les **dataclasses** avec fonctionnalités avancées :\n\n```python\nfrom dataclasses import dataclass, field, asdict, astuple\nfrom typing import Optional, List, ClassVar\nfrom datetime import datetime\nimport json\n\n# Dataclass basique avec valeurs par défaut\n@dataclass\nclass User:\n    name: str\n    email: str\n    age: int = 0\n    active: bool = True\n\n# Avec factory pour les valeurs mutables\n@dataclass\nclass Team:\n    name: str\n    members: List[str] = field(default_factory=list)\n    created_at: datetime = field(default_factory=datetime.now)\n\n# Frozen (immutable) + comparaison + tri\n@dataclass(frozen=True, order=True)\nclass Version:\n    major: int\n    minor: int\n    patch: int\n    \n    def __str__(self) -> str:\n        return f\"{self.major}.{self.minor}.{self.patch}\"\n\n# Avec validation et post-init\n@dataclass\nclass Product:\n    name: str\n    price: float\n    quantity: int = 0\n    \n    # Variable de classe (non incluse dans __init__)\n    currency: ClassVar[str] = \"EUR\"\n    \n    # Champ calculé (exclu de __init__)\n    total: float = field(init=False)\n    \n    def __post_init__(self):\n        # Validation\n        if self.price < 0:\n            raise ValueError(\"Le prix ne peut pas être négatif\")\n        # Calcul\n        self.total = self.price * self.quantity\n\n# Héritage\n@dataclass\nclass PremiumProduct(Product):\n    discount: float = 0.0\n    \n    def __post_init__(self):\n        super().__post_init__()\n        self.total = self.total * (1 - self.discount)\n\n# Sérialisation JSON\n@dataclass\nclass Config:\n    debug: bool = False\n    host: str = \"localhost\"\n    port: int = 8080\n    \n    def to_json(self) -> str:\n        return json.dumps(asdict(self))\n    \n    @classmethod\n    def from_json(cls, json_str: str) -> 'Config':\n        return cls(**json.loads(json_str))\n\n# Utilisation\nv1 = Version(1, 0, 0)\nv2 = Version(2, 0, 0)\nprint(v1 < v2)  # True (grâce à order=True)\n\nproduct = PremiumProduct(\"Laptop\", 1000, 2, discount=0.1)\nprint(product.total)  # 1800.0\n\nconfig = Config(debug=True, port=3000)\nprint(config.to_json())  # {\"debug\": true, \"host\": \"localhost\", \"port\": 3000}\n```"}
{"input": "Comment implémenter le pattern Chain of Responsibility ?", "target": "Le **pattern Chain of Responsibility** en Python :\n\n```python\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, Any\nfrom dataclasses import dataclass\n\n@dataclass\nclass Request:\n    \"\"\"Requête à traiter.\"\"\"\n    type: str\n    content: Any\n    handled: bool = False\n\nclass Handler(ABC):\n    \"\"\"Handler abstrait de la chaîne.\"\"\"\n    \n    def __init__(self):\n        self._next_handler: Optional[Handler] = None\n    \n    def set_next(self, handler: 'Handler') -> 'Handler':\n        self._next_handler = handler\n        return handler  # Pour chaînage fluent\n    \n    def handle(self, request: Request) -> Request:\n        \"\"\"Traite ou passe au suivant.\"\"\"\n        if self.can_handle(request):\n            return self.process(request)\n        elif self._next_handler:\n            return self._next_handler.handle(request)\n        else:\n            print(f\"Aucun handler pour: {request.type}\")\n            return request\n    \n    @abstractmethod\n    def can_handle(self, request: Request) -> bool:\n        pass\n    \n    @abstractmethod\n    def process(self, request: Request) -> Request:\n        pass\n\n# Handlers concrets\nclass AuthenticationHandler(Handler):\n    def can_handle(self, request: Request) -> bool:\n        return request.type == \"auth\"\n    \n    def process(self, request: Request) -> Request:\n        print(f\"🔐 Authentification: {request.content}\")\n        request.handled = True\n        return request\n\nclass ValidationHandler(Handler):\n    def can_handle(self, request: Request) -> bool:\n        return request.type == \"validation\"\n    \n    def process(self, request: Request) -> Request:\n        print(f\"✅ Validation: {request.content}\")\n        request.handled = True\n        return request\n\nclass LoggingHandler(Handler):\n    \"\"\"Handler qui log et passe au suivant.\"\"\"\n    \n    def can_handle(self, request: Request) -> bool:\n        return True  # Log tout\n    \n    def process(self, request: Request) -> Request:\n        print(f\"📝 Log: {request.type} - {request.content}\")\n        # Continue la chaîne\n        if self._next_handler:\n            return self._next_handler.handle(request)\n        return request\n\nclass CacheHandler(Handler):\n    def __init__(self):\n        super().__init__()\n        self.cache = {}\n    \n    def can_handle(self, request: Request) -> bool:\n        return request.type == \"cache\"\n    \n    def process(self, request: Request) -> Request:\n        key = request.content.get('key')\n        if key in self.cache:\n            print(f\"💾 Cache hit: {key}\")\n        else:\n            print(f\"💾 Cache miss: {key}\")\n            self.cache[key] = request.content.get('value')\n        request.handled = True\n        return request\n\n# Construction de la chaîne\nlogging = LoggingHandler()\nauth = AuthenticationHandler()\nvalidation = ValidationHandler()\ncache = CacheHandler()\n\nlogging.set_next(auth).set_next(validation).set_next(cache)\n\n# Utilisation\nrequests = [\n    Request(\"auth\", {\"user\": \"admin\", \"pass\": \"secret\"}),\n    Request(\"validation\", {\"email\": \"test@example.com\"}),\n    Request(\"cache\", {\"key\": \"user_1\", \"value\": \"data\"}),\n    Request(\"unknown\", \"test\"),\n]\n\nfor req in requests:\n    result = logging.handle(req)\n    print(f\"Handled: {result.handled}\\n\")\n```"}
{"input": "Comment implémenter un système de middleware en Python ?", "target": "Un **système de middleware** flexible :\n\n```python\nfrom typing import Callable, Any, List\nfrom functools import wraps\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nimport time\n\n@dataclass\nclass Request:\n    path: str\n    method: str\n    headers: dict = field(default_factory=dict)\n    body: Any = None\n    user: Any = None\n    start_time: float = field(default_factory=time.time)\n\n@dataclass\nclass Response:\n    status_code: int = 200\n    body: Any = None\n    headers: dict = field(default_factory=dict)\n\nclass MiddlewareStack:\n    \"\"\"Pile de middlewares.\"\"\"\n    \n    def __init__(self):\n        self._middlewares: List[Callable] = []\n    \n    def use(self, middleware: Callable):\n        \"\"\"Ajoute un middleware à la pile.\"\"\"\n        self._middlewares.append(middleware)\n        return self\n    \n    def __call__(self, handler: Callable) -> Callable:\n        \"\"\"Enveloppe le handler avec tous les middlewares.\"\"\"\n        @wraps(handler)\n        def wrapped(request: Request) -> Response:\n            def create_next(index: int) -> Callable:\n                if index >= len(self._middlewares):\n                    return lambda req: handler(req)\n                \n                def next_middleware(req: Request) -> Response:\n                    middleware = self._middlewares[index]\n                    return middleware(req, create_next(index + 1))\n                \n                return next_middleware\n            \n            return create_next(0)(request)\n        return wrapped\n\n# Middlewares\ndef logging_middleware(request: Request, next: Callable) -> Response:\n    \"\"\"Log les requêtes.\"\"\"\n    print(f\"[{datetime.now()}] → {request.method} {request.path}\")\n    response = next(request)\n    elapsed = time.time() - request.start_time\n    print(f\"[{datetime.now()}] ← {response.status_code} ({elapsed:.3f}s)\")\n    return response\n\ndef auth_middleware(request: Request, next: Callable) -> Response:\n    \"\"\"Vérifie l'authentification.\"\"\"\n    token = request.headers.get('Authorization')\n    if not token:\n        return Response(status_code=401, body=\"Unauthorized\")\n    \n    # Simuler décodage token\n    request.user = {\"id\": 1, \"name\": \"Alice\"}\n    return next(request)\n\ndef rate_limit_middleware(max_requests: int = 100):\n    \"\"\"Factory pour rate limiting.\"\"\"\n    requests_count = {}\n    \n    def middleware(request: Request, next: Callable) -> Response:\n        ip = request.headers.get('X-Forwarded-For', 'unknown')\n        requests_count[ip] = requests_count.get(ip, 0) + 1\n        \n        if requests_count[ip] > max_requests:\n            return Response(status_code=429, body=\"Too Many Requests\")\n        \n        return next(request)\n    \n    return middleware\n\ndef cors_middleware(request: Request, next: Callable) -> Response:\n    \"\"\"Ajoute les headers CORS.\"\"\"\n    response = next(request)\n    response.headers.update({\n        'Access-Control-Allow-Origin': '*',\n        'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE',\n    })\n    return response\n\n# Application\nstack = MiddlewareStack()\nstack.use(logging_middleware)\nstack.use(cors_middleware)\nstack.use(rate_limit_middleware(max_requests=50))\nstack.use(auth_middleware)\n\n@stack\ndef get_user(request: Request) -> Response:\n    \"\"\"Handler principal.\"\"\"\n    return Response(\n        status_code=200,\n        body={\"user\": request.user}\n    )\n\n# Test\nrequest = Request(\n    path=\"/users/1\",\n    method=\"GET\",\n    headers={\"Authorization\": \"Bearer xxx\", \"X-Forwarded-For\": \"1.2.3.4\"}\n)\n\nresponse = get_user(request)\nprint(f\"Response: {response.status_code} - {response.body}\")\n```"}
{"input": "Comment créer un système de validation avec Pydantic ?", "target": "**Validation avancée** avec Pydantic v2 :\n\n```python\nfrom pydantic import (\n    BaseModel, \n    Field, \n    field_validator, \n    model_validator,\n    EmailStr,\n    HttpUrl,\n    ConfigDict\n)\nfrom typing import Optional, List, Annotated\nfrom datetime import datetime, date\nfrom enum import Enum\nimport re\n\nclass UserRole(str, Enum):\n    ADMIN = \"admin\"\n    USER = \"user\"\n    GUEST = \"guest\"\n\nclass Address(BaseModel):\n    \"\"\"Modèle imbriqué.\"\"\"\n    street: str = Field(..., min_length=5)\n    city: str\n    postal_code: str = Field(..., pattern=r'^\\d{5}$')\n    country: str = \"France\"\n\nclass User(BaseModel):\n    \"\"\"Modèle utilisateur avec validations.\"\"\"\n    \n    model_config = ConfigDict(\n        str_strip_whitespace=True,  # Trim les strings\n        validate_assignment=True,    # Valider sur modification\n        extra='forbid'               # Interdire champs supplémentaires\n    )\n    \n    # Champs avec contraintes\n    id: Optional[int] = None\n    username: str = Field(..., min_length=3, max_length=50)\n    email: EmailStr\n    password: str = Field(..., min_length=8)\n    age: int = Field(..., ge=0, le=150)\n    role: UserRole = UserRole.USER\n    website: Optional[HttpUrl] = None\n    tags: List[str] = Field(default_factory=list)\n    address: Optional[Address] = None\n    created_at: datetime = Field(default_factory=datetime.now)\n    \n    # Validateur de champ\n    @field_validator('username')\n    @classmethod\n    def username_alphanumeric(cls, v: str) -> str:\n        if not v.replace('_', '').isalnum():\n            raise ValueError('doit être alphanumérique')\n        return v.lower()\n    \n    @field_validator('password')\n    @classmethod\n    def password_strength(cls, v: str) -> str:\n        if not re.search(r'[A-Z]', v):\n            raise ValueError('doit contenir une majuscule')\n        if not re.search(r'[0-9]', v):\n            raise ValueError('doit contenir un chiffre')\n        if not re.search(r'[!@#$%^&*]', v):\n            raise ValueError('doit contenir un caractère spécial')\n        return v\n    \n    @field_validator('tags', mode='before')\n    @classmethod\n    def split_tags(cls, v):\n        if isinstance(v, str):\n            return [tag.strip() for tag in v.split(',')]\n        return v\n    \n    # Validateur de modèle\n    @model_validator(mode='after')\n    def check_admin_age(self):\n        if self.role == UserRole.ADMIN and self.age < 18:\n            raise ValueError('Admin doit avoir 18 ans minimum')\n        return self\n\n# Utilisation\ntry:\n    user = User(\n        username=\"  Alice_123  \",\n        email=\"alice@example.com\",\n        password=\"Secret123!\",\n        age=25,\n        role=\"admin\",\n        tags=\"python,fastapi,pydantic\",\n        address={\n            \"street\": \"123 Main Street\",\n            \"city\": \"Paris\",\n            \"postal_code\": \"75001\"\n        }\n    )\n    print(user.model_dump_json(indent=2))\n    \nexcept Exception as e:\n    print(f\"Erreur de validation: {e}\")\n\n# Sérialisation\nuser_dict = user.model_dump()\nuser_json = user.model_dump_json()\n\n# Parsing\nUser.model_validate({\"username\": \"bob\", \"email\": \"bob@test.com\", ...})\nUser.model_validate_json(json_string)\n```"}
{"input": "Comment créer un système de logging avancé en Python ?", "target": "Un **système de logging** professionnel :\n\n```python\nimport logging\nimport logging.handlers\nimport json\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Optional\nimport sys\nimport traceback\n\nclass JSONFormatter(logging.Formatter):\n    \"\"\"Formatter JSON pour logs structurés.\"\"\"\n    \n    def format(self, record: logging.LogRecord) -> str:\n        log_data = {\n            \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n            \"level\": record.levelname,\n            \"logger\": record.name,\n            \"message\": record.getMessage(),\n            \"module\": record.module,\n            \"function\": record.funcName,\n            \"line\": record.lineno,\n        }\n        \n        # Ajouter les extras\n        for key, value in record.__dict__.items():\n            if key not in logging.LogRecord.__dict__ and not key.startswith('_'):\n                log_data[key] = value\n        \n        # Ajouter l'exception si présente\n        if record.exc_info:\n            log_data[\"exception\"] = {\n                \"type\": record.exc_info[0].__name__,\n                \"message\": str(record.exc_info[1]),\n                \"traceback\": traceback.format_exception(*record.exc_info)\n            }\n        \n        return json.dumps(log_data, default=str)\n\nclass ColoredFormatter(logging.Formatter):\n    \"\"\"Formatter avec couleurs pour console.\"\"\"\n    \n    COLORS = {\n        'DEBUG': '\\033[36m',    # Cyan\n        'INFO': '\\033[32m',     # Green\n        'WARNING': '\\033[33m',  # Yellow\n        'ERROR': '\\033[31m',    # Red\n        'CRITICAL': '\\033[35m', # Magenta\n    }\n    RESET = '\\033[0m'\n    \n    def format(self, record: logging.LogRecord) -> str:\n        color = self.COLORS.get(record.levelname, '')\n        record.levelname = f\"{color}{record.levelname}{self.RESET}\"\n        return super().format(record)\n\ndef setup_logging(\n    name: str = \"app\",\n    level: int = logging.INFO,\n    log_dir: Optional[Path] = None,\n    json_logs: bool = True\n) -> logging.Logger:\n    \"\"\"Configure le système de logging.\"\"\"\n    \n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n    logger.handlers.clear()\n    \n    # Console handler avec couleurs\n    console = logging.StreamHandler(sys.stdout)\n    console.setLevel(level)\n    console.setFormatter(ColoredFormatter(\n        '%(asctime)s | %(levelname)-8s | %(name)s | %(message)s'\n    ))\n    logger.addHandler(console)\n    \n    if log_dir:\n        log_dir = Path(log_dir)\n        log_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Fichier rotatif (10 MB, 5 backups)\n        file_handler = logging.handlers.RotatingFileHandler(\n            log_dir / f\"{name}.log\",\n            maxBytes=10 * 1024 * 1024,\n            backupCount=5\n        )\n        file_handler.setLevel(level)\n        \n        if json_logs:\n            file_handler.setFormatter(JSONFormatter())\n        else:\n            file_handler.setFormatter(logging.Formatter(\n                '%(asctime)s | %(levelname)s | %(name)s | %(funcName)s | %(message)s'\n            ))\n        \n        logger.addHandler(file_handler)\n        \n        # Handler séparé pour les erreurs\n        error_handler = logging.handlers.RotatingFileHandler(\n            log_dir / f\"{name}_errors.log\",\n            maxBytes=10 * 1024 * 1024,\n            backupCount=5\n        )\n        error_handler.setLevel(logging.ERROR)\n        error_handler.setFormatter(JSONFormatter())\n        logger.addHandler(error_handler)\n    \n    return logger\n\n# Logger contextualisé\nclass ContextLogger:\n    \"\"\"Logger avec contexte persistant.\"\"\"\n    \n    def __init__(self, logger: logging.Logger):\n        self.logger = logger\n        self.context = {}\n    \n    def bind(self, **kwargs) -> 'ContextLogger':\n        new_logger = ContextLogger(self.logger)\n        new_logger.context = {**self.context, **kwargs}\n        return new_logger\n    \n    def _log(self, level: int, message: str, **kwargs):\n        extra = {**self.context, **kwargs}\n        self.logger.log(level, message, extra=extra)\n    \n    def info(self, message: str, **kwargs):\n        self._log(logging.INFO, message, **kwargs)\n    \n    def error(self, message: str, **kwargs):\n        self._log(logging.ERROR, message, **kwargs)\n\n# Utilisation\nlogger = setup_logging(\"myapp\", level=logging.DEBUG, log_dir=Path(\"logs\"))\n\nlogger.info(\"Application démarrée\")\nlogger.warning(\"Attention!\", extra={\"user_id\": 123})\n\ntry:\n    1/0\nexcept Exception:\n    logger.exception(\"Erreur critique!\")\n\n# Logger contextualisé\nctx_logger = ContextLogger(logger)\nrequest_logger = ctx_logger.bind(request_id=\"abc123\", user=\"alice\")\nrequest_logger.info(\"Traitement requête\", endpoint=\"/api/users\")\n```"}
{"input": "Comment implémenter des tests paramétrés avec pytest ?", "target": "**Tests paramétrés** avancés avec pytest :\n\n```python\nimport pytest\nfrom typing import Optional\nfrom dataclasses import dataclass\n\n# Fonction à tester\ndef validate_email(email: str) -> bool:\n    import re\n    pattern = r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$'\n    return bool(re.match(pattern, email))\n\ndef calculate_discount(price: float, discount_percent: float) -> float:\n    if discount_percent < 0 or discount_percent > 100:\n        raise ValueError(\"Discount must be between 0 and 100\")\n    return price * (1 - discount_percent / 100)\n\n# Tests paramétrés simples\n@pytest.mark.parametrize(\"email,expected\", [\n    (\"test@example.com\", True),\n    (\"user.name@domain.org\", True),\n    (\"invalid-email\", False),\n    (\"missing@domain\", False),\n    (\"\", False),\n    (\"spaces @email.com\", False),\n])\ndef test_validate_email(email: str, expected: bool):\n    assert validate_email(email) == expected\n\n# Tests avec IDs explicites\n@pytest.mark.parametrize(\n    \"price,discount,expected\",\n    [\n        (100, 0, 100),\n        (100, 10, 90),\n        (100, 50, 50),\n        (100, 100, 0),\n        (200, 25, 150),\n    ],\n    ids=[\"no_discount\", \"10%_off\", \"half_price\", \"free\", \"quarter_off\"]\n)\ndef test_calculate_discount(price, discount, expected):\n    assert calculate_discount(price, discount) == expected\n\n# Tests d'exceptions\n@pytest.mark.parametrize(\"discount\", [-1, 101, 150])\ndef test_calculate_discount_invalid(discount):\n    with pytest.raises(ValueError):\n        calculate_discount(100, discount)\n\n# Paramètres multiples combinés\n@pytest.mark.parametrize(\"x\", [1, 2])\n@pytest.mark.parametrize(\"y\", [10, 20])\ndef test_combinations(x, y):\n    assert x * y in [10, 20, 20, 40]\n\n# Fixtures paramétrées\n@pytest.fixture(params=[\"sqlite\", \"postgres\", \"mysql\"])\ndef database(request):\n    \"\"\"Teste avec différentes bases de données.\"\"\"\n    db_type = request.param\n    # Setup\n    db = create_db_connection(db_type)\n    yield db\n    # Teardown\n    db.close()\n\ndef test_database_query(database):\n    result = database.query(\"SELECT 1\")\n    assert result is not None\n\n# Classes de test paramétrées\n@dataclass\nclass UserTestCase:\n    name: str\n    age: int\n    expected_adult: bool\n\ntest_cases = [\n    UserTestCase(\"Alice\", 25, True),\n    UserTestCase(\"Bob\", 17, False),\n    UserTestCase(\"Charlie\", 18, True),\n]\n\n@pytest.mark.parametrize(\n    \"test_case\",\n    test_cases,\n    ids=[tc.name for tc in test_cases]\n)\ndef test_is_adult(test_case: UserTestCase):\n    user = User(name=test_case.name, age=test_case.age)\n    assert user.is_adult() == test_case.expected_adult\n\n# Markers pour skip conditionnel\nimport sys\n\n@pytest.mark.parametrize(\"value\", [\n    pytest.param(1, marks=pytest.mark.slow),\n    pytest.param(2, marks=pytest.mark.skip(reason=\"Not implemented\")),\n    pytest.param(3, marks=pytest.mark.skipif(\n        sys.platform == \"win32\", \n        reason=\"Unix only\"\n    )),\n])\ndef test_with_markers(value):\n    assert value > 0\n\n# Indirect parametrization\n@pytest.fixture\ndef user(request):\n    \"\"\"Crée un user selon le paramètre.\"\"\"\n    return User(name=request.param)\n\n@pytest.mark.parametrize(\"user\", [\"admin\", \"guest\"], indirect=True)\ndef test_user_permissions(user):\n    if user.name == \"admin\":\n        assert user.can_delete()\n    else:\n        assert not user.can_delete()\n```"}
{"input": "Explique-moi l'architecture des microservices.", "target": "L'**architecture microservices** décompose une application en services indépendants :\n\n**Caractéristiques :**\n- Services **autonomes** et spécialisés\n- Communication via **API** (REST, gRPC)\n- Déploiement **indépendant**\n- Base de données **par service**\n\n**Comparaison :**\n\n| Monolithique | Microservices |\n|---|---|\n| Une seule unité | Services multiples |\n| Couplage fort | Couplage faible |\n| Scaling global | Scaling granulaire |\n| Déploiement unique | Déploiements indépendants |\n\n**Avantages :**\n- **Scalabilité** ciblée\n- **Résilience** : échec isolé\n- **Flexibilité** technologique\n- Équipes **autonomes**\n\n**Inconvénients :**\n- Complexité **réseau**\n- **Debugging** distribué difficile\n- **Cohérence** des données\n\n**Technologies associées :**\n- Docker, Kubernetes\n- Service mesh (Istio)\n- API Gateway"}
{"input": "Comment fonctionne Docker en détail ?", "target": "**Docker** est une plateforme de conteneurisation :\n\n**Concepts clés :**\n\n1. **Image** :\n   - Template en lecture seule\n   - Couches (layers) empilées\n   - Définie par un `Dockerfile`\n\n2. **Conteneur** :\n   - Instance d'une image\n   - Isolé mais partage le kernel\n   - Éphémère par défaut\n\n3. **Registry** :\n   - Dépôt d'images (Docker Hub)\n\n**Dockerfile exemple :**\n```dockerfile\nFROM python:3.11-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY . .\nCMD [\"python\", \"main.py\"]\n```\n\n**Commandes essentielles :**\n```bash\ndocker build -t mon-app .\ndocker run -d -p 8080:80 mon-app\ndocker ps        # conteneurs actifs\ndocker logs <id> # voir les logs\n```\n\n**vs Machine Virtuelle :**\n- Docker : léger, démarrage rapide, partage kernel\n- VM : isolation complète, OS complet"}
{"input": "Qu'est-ce que Kubernetes et comment ça marche ?", "target": "**Kubernetes** (K8s) orchestre les conteneurs à grande échelle :\n\n**Architecture :**\n\n**Control Plane :**\n- **API Server** : point d'entrée\n- **etcd** : stockage clé-valeur\n- **Scheduler** : placement des pods\n- **Controller Manager** : état désiré\n\n**Worker Nodes :**\n- **Kubelet** : agent sur chaque nœud\n- **Kube-proxy** : réseau\n- **Container runtime** : Docker/containerd\n\n**Objets principaux :**\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mon-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: mon-app\n  template:\n    spec:\n      containers:\n      - name: app\n        image: mon-app:v1\n```\n\n**Concepts :**\n- **Pod** : plus petite unité (1+ conteneurs)\n- **Service** : exposition réseau\n- **Ingress** : routage HTTP\n- **ConfigMap/Secret** : configuration"}
{"input": "Explique le pattern SOLID en programmation.", "target": "**SOLID** : 5 principes de conception orientée objet :\n\n**S - Single Responsibility :**\n- Une classe = **une seule raison** de changer\n```python\n# ❌ Mauvais\nclass User:\n    def save_to_db(self): pass\n    def generate_report(self): pass\n\n# ✅ Bon\nclass User: pass\nclass UserRepository: pass\nclass UserReportGenerator: pass\n```\n\n**O - Open/Closed :**\n- Ouvert à l'**extension**, fermé à la **modification**\n- Utiliser héritage/polymorphisme\n\n**L - Liskov Substitution :**\n- Sous-classes **substituables** aux classes parentes\n- Rectangle/Carré : exemple classique de violation\n\n**I - Interface Segregation :**\n- Interfaces **spécifiques** plutôt que générales\n- Éviter les \"fat interfaces\"\n\n**D - Dependency Inversion :**\n- Dépendre des **abstractions**, pas des implémentations\n```python\n# ✅ Bon\ndef process(repository: IRepository):\n    repository.save(data)\n```"}
{"input": "Comment fonctionne une base de données NoSQL ?", "target": "Les bases **NoSQL** (Not Only SQL) offrent flexibilité et scalabilité :\n\n**Types principaux :**\n\n1. **Document** (MongoDB, CouchDB) :\n```json\n{\n  \"_id\": \"user123\",\n  \"name\": \"Alice\",\n  \"orders\": [{\"id\": 1, \"total\": 99.99}]\n}\n```\n\n2. **Clé-Valeur** (Redis, DynamoDB) :\n```\nuser:123 → {données sérialisées}\n```\n\n3. **Colonnes larges** (Cassandra, HBase) :\n- Optimisé pour lectures/écritures massives\n- Modèle par colonnes\n\n4. **Graphe** (Neo4j, ArangoDB) :\n- Relations complexes (réseaux sociaux)\n- Requêtes de traversée\n\n**Comparaison SQL vs NoSQL :**\n\n| SQL | NoSQL |\n|---|---|\n| Schéma fixe | Schéma flexible |\n| ACID | BASE (eventual consistency) |\n| Scaling vertical | Scaling horizontal |\n| Jointures | Données dénormalisées |\n\n**Cas d'usage NoSQL :**\n- Big Data, temps réel, IoT"}
{"input": "Qu'est-ce que le CI/CD et comment le mettre en place ?", "target": "**CI/CD** automatise le cycle de développement :\n\n**CI - Intégration Continue :**\n- Merge fréquent vers branche principale\n- **Tests automatiques** à chaque commit\n- Détection rapide des conflits\n\n**CD - Déploiement/Livraison Continue :**\n- **Continuous Delivery** : prêt à déployer\n- **Continuous Deployment** : déploiement automatique\n\n**Pipeline typique :**\n```\nCommit → Build → Test → Scan → Deploy (staging) → Deploy (prod)\n```\n\n**Exemple GitHub Actions :**\n```yaml\nname: CI/CD\non: [push]\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Run tests\n        run: pytest\n      - name: Deploy\n        if: github.ref == 'refs/heads/main'\n        run: ./deploy.sh\n```\n\n**Outils populaires :**\n- **GitHub Actions**, GitLab CI\n- **Jenkins**, CircleCI\n- **ArgoCD** (GitOps)"}
{"input": "Explique GraphQL vs REST.", "target": "**GraphQL** et **REST** : deux approches d'API :\n\n**REST :**\n```\nGET /users/123\nGET /users/123/orders\nGET /users/123/friends\n```\n- Plusieurs requêtes\n- Over/under-fetching\n\n**GraphQL :**\n```graphql\nquery {\n  user(id: \"123\") {\n    name\n    orders { total }\n    friends { name }\n  }\n}\n```\n- Une seule requête\n- Données exactes demandées\n\n**Comparaison :**\n\n| Aspect | REST | GraphQL |\n|---|---|---|\n| Endpoints | Multiples | Unique |\n| Données | Fixes | Flexibles |\n| Versioning | URLs | Évolution du schéma |\n| Cache | HTTP natif | Plus complexe |\n| Apprentissage | Simple | Courbe plus raide |\n\n**Quand utiliser :**\n- **REST** : APIs simples, cache HTTP important\n- **GraphQL** : besoins variés, applications mobiles\n\n**Outils GraphQL :**\n- Apollo, Relay, Hasura, Prisma"}
{"input": "Comment fonctionne le machine learning pipeline ?", "target": "Un **ML Pipeline** structure le workflow d'apprentissage automatique :\n\n**Étapes classiques :**\n\n1. **Collecte des données :**\n   - Sources diverses (BDD, APIs, fichiers)\n   - Data lake / warehouse\n\n2. **Préparation :**\n   - Nettoyage (valeurs manquantes, outliers)\n   - Feature engineering\n   - Encoding catégoriel\n\n3. **Entraînement :**\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\n```\n\n4. **Évaluation :**\n   - Métriques : accuracy, precision, recall, F1\n   - Validation croisée\n\n5. **Déploiement :**\n   - Model serving (FastAPI, TensorFlow Serving)\n   - Monitoring (drift detection)\n\n**MLOps :**\n- **MLflow** : tracking expériences\n- **Kubeflow** : orchestration K8s\n- **DVC** : versioning des données"}
{"input": "Qu'est-ce que le WebSocket et comment l'utiliser ?", "target": "**WebSocket** permet une communication **bidirectionnelle** en temps réel :\n\n**Caractéristiques :**\n- Connexion **persistante** (vs HTTP request/response)\n- **Full-duplex** : envoi simultané dans les deux sens\n- Faible latence\n- Protocole : `ws://` ou `wss://` (sécurisé)\n\n**Handshake initial :**\n```\nGET /chat HTTP/1.1\nUpgrade: websocket\nConnection: Upgrade\n```\n\n**Exemple JavaScript (client) :**\n```javascript\nconst ws = new WebSocket('wss://example.com/socket');\n\nws.onopen = () => console.log('Connecté');\nws.onmessage = (event) => console.log(event.data);\nws.send('Hello serveur!');\n```\n\n**Exemple Python (serveur) :**\n```python\nimport asyncio\nimport websockets\n\nasync def handler(websocket):\n    async for message in websocket:\n        await websocket.send(f\"Echo: {message}\")\n\nasyncio.run(websockets.serve(handler, \"localhost\", 8765))\n```\n\n**Cas d'usage :**\n- Chat en temps réel\n- Jeux en ligne\n- Notifications push\n- Trading/finance"}
{"input": "Explique le concept de Clean Architecture.", "target": "La **Clean Architecture** (Robert C. Martin) organise le code en couches :\n\n**Principe fondamental :**\n- **Dépendances vers l'intérieur** uniquement\n- Le cœur métier ne dépend de rien d'externe\n\n**Les couches (de l'intérieur vers l'extérieur) :**\n\n1. **Entities (Domaine) :**\n   - Règles métier fondamentales\n   - Indépendantes de tout framework\n\n2. **Use Cases :**\n   - Logique applicative\n   - Orchestration des entités\n\n3. **Interface Adapters :**\n   - Controllers, Presenters\n   - Conversion de données\n\n4. **Frameworks & Drivers :**\n   - Base de données, Web, UI\n   - Détails d'implémentation\n\n**Structure Python :**\n```\nsrc/\n├── domain/          # Entities\n│   └── user.py\n├── use_cases/       # Application logic\n│   └── create_user.py\n├── adapters/        # Controllers, repos\n│   └── user_repository.py\n└── infrastructure/  # DB, web\n    └── database.py\n```\n\n**Bénéfices :**\n- **Testabilité** maximale\n- **Indépendance** des frameworks\n- **Maintenabilité** long terme"}
{"input": "Comment fonctionne le protocole HTTP/2 ?", "target": "**HTTP/2** améliore significativement HTTP/1.1 :\n\n**Nouveautés majeures :**\n\n1. **Multiplexage :**\n   - Plusieurs requêtes sur **une seule connexion**\n   - Fin du head-of-line blocking\n   - Pas besoin de connexions multiples\n\n2. **Compression des headers :**\n   - Algorithme **HPACK**\n   - Réduction significative de la bande passante\n\n3. **Server Push :**\n   - Serveur envoie des ressources **proactivement**\n   - Ex: CSS/JS avant que le client ne les demande\n\n4. **Priorisation :**\n   - Poids et dépendances entre streams\n   - Ressources critiques en premier\n\n5. **Format binaire :**\n   - Plus efficace que le texte HTTP/1.1\n\n**Comparaison :**\n\n| HTTP/1.1 | HTTP/2 |\n|---|---|\n| Texte | Binaire |\n| 1 requête/connexion | Multiplexé |\n| Headers répétés | Headers compressés |\n| Client-driven | Server push possible |\n\n**HTTP/3 (QUIC) :**\n- Basé sur **UDP** (pas TCP)\n- Encore plus rapide"}
{"input": "Qu'est-ce que le pattern Event-Driven Architecture ?", "target": "L'**architecture événementielle** découple les composants via des événements :\n\n**Concepts clés :**\n- **Événement** : fait passé immutable\n- **Producteur** : émet des événements\n- **Consommateur** : réagit aux événements\n- **Broker** : distribue les événements\n\n**Patterns principaux :**\n\n1. **Pub/Sub :**\n```\nProducteur → Topic → [Consommateur 1, Consommateur 2]\n```\n\n2. **Event Sourcing :**\n   - État = séquence d'événements\n   - Historique complet\n\n3. **CQRS :**\n   - Command Query Responsibility Segregation\n   - Séparation lecture/écriture\n\n**Exemple avec Kafka :**\n```python\n# Producteur\nproducer.send('orders', {'order_id': 123, 'status': 'created'})\n\n# Consommateur\nfor message in consumer:\n    process_order(message.value)\n```\n\n**Avantages :**\n- **Découplage** total\n- **Scalabilité** horizontale\n- **Résilience** : producteurs/consommateurs indépendants\n\n**Outils :**\n- Apache Kafka, RabbitMQ, AWS SNS/SQS"}
{"input": "Explique le concept de OAuth 2.0 et OpenID Connect.", "target": "**OAuth 2.0** et **OpenID Connect** sécurisent l'authentification :\n\n**OAuth 2.0 (Autorisation) :**\n- Standard pour l'**accès délégué**\n- \"Connectez-vous avec Google/Facebook\"\n- Accès aux ressources **sans partager le mot de passe**\n\n**Flux Authorization Code :**\n```\n1. User → App : \"Se connecter avec Google\"\n2. App → Google : Redirection\n3. User → Google : Authentification + Consentement\n4. Google → App : Code d'autorisation\n5. App → Google : Échange code → Access Token\n6. App → API : Requête avec Access Token\n```\n\n**Tokens :**\n- **Access Token** : accès aux ressources (courte durée)\n- **Refresh Token** : obtenir nouveaux access tokens\n\n**OpenID Connect (Authentification) :**\n- Couche **identité** sur OAuth 2.0\n- **ID Token** (JWT) : informations utilisateur\n```json\n{\n  \"sub\": \"user123\",\n  \"email\": \"alice@example.com\",\n  \"name\": \"Alice\"\n}\n```\n\n**Résumé :**\n- OAuth 2.0 : **ce que tu peux faire**\n- OIDC : **qui tu es**"}
{"input": "Comment implémenter un système de cache efficace ?", "target": "Le **caching** améliore drastiquement les performances :\n\n**Niveaux de cache :**\n\n1. **Application (in-memory) :**\n```python\nfrom functools import lru_cache\n\n@lru_cache(maxsize=100)\ndef expensive_function(param):\n    return compute(param)\n```\n\n2. **Distribué (Redis/Memcached) :**\n```python\nimport redis\nr = redis.Redis()\n\n# Cache-aside pattern\ndef get_user(user_id):\n    cached = r.get(f\"user:{user_id}\")\n    if cached:\n        return json.loads(cached)\n    user = db.query(user_id)\n    r.setex(f\"user:{user_id}\", 3600, json.dumps(user))\n    return user\n```\n\n3. **CDN** : assets statiques\n4. **HTTP** : headers Cache-Control\n\n**Stratégies d'invalidation :**\n- **TTL** (Time To Live) : expiration automatique\n- **Write-through** : écriture cache + DB simultanée\n- **Write-behind** : écriture asynchrone\n\n**Problèmes courants :**\n- **Cache stampede** : requêtes simultanées\n- **Incohérence** : données périmées\n- **Cold start** : cache vide\n\n**Règle d'or :**\n- \"Il n'y a que 2 problèmes difficiles : l'invalidation du cache et nommer les choses.\""}
{"input": "Qu'est-ce que le Test-Driven Development (TDD) ?", "target": "**TDD** : écrire les tests **avant** le code :\n\n**Cycle Red-Green-Refactor :**\n\n1. **🔴 Red** : écrire un test qui échoue\n2. **🟢 Green** : code minimal pour passer le test\n3. **🔵 Refactor** : améliorer sans casser les tests\n\n**Exemple Python :**\n```python\n# 1. Test d'abord (RED)\ndef test_add():\n    assert add(2, 3) == 5  # Échoue : add n'existe pas\n\n# 2. Implémentation minimale (GREEN)\ndef add(a, b):\n    return a + b  # Test passe !\n\n# 3. Refactor si nécessaire\n```\n\n**Avantages :**\n- Design guidé par l'**utilisation**\n- **Couverture** de tests élevée\n- **Confiance** dans le code\n- **Documentation** vivante\n- Refactoring **serein**\n\n**Inconvénients :**\n- Courbe d'apprentissage\n- Temps initial plus long\n- Tests peuvent devenir un fardeau\n\n**Variantes :**\n- **BDD** (Behavior-Driven Development) : langage métier\n- **ATDD** (Acceptance TDD) : tests d'acceptation"}
{"input": "Explique le fonctionnement de Git en profondeur.", "target": "**Git** est un système de contrôle de version distribué :\n\n**Concepts fondamentaux :**\n\n1. **Snapshots vs Deltas :**\n   - Git stocke des **snapshots** complets\n   - Références vers fichiers inchangés\n\n2. **Les 3 zones :**\n```\nWorking Directory → Staging Area → Repository\n     (git add)          (git commit)\n```\n\n3. **Objets Git :**\n   - **Blob** : contenu de fichier\n   - **Tree** : structure de répertoire\n   - **Commit** : snapshot + métadonnées\n   - **Tag** : référence nommée\n\n**Commandes avancées :**\n```bash\ngit rebase -i HEAD~3      # Réécriture d'historique\ngit cherry-pick abc123    # Appliquer un commit\ngit bisect                # Trouver un bug par dichotomie\ngit stash                 # Mettre de côté des changements\ngit reflog                # Historique de HEAD\n```\n\n**Stratégies de branches :**\n- **Git Flow** : develop/feature/release/hotfix\n- **GitHub Flow** : main + feature branches\n- **Trunk-Based** : intégration continue sur main"}
{"input": "Comment fonctionne le load balancing ?", "target": "Le **load balancing** distribue le trafic entre serveurs :\n\n**Types de load balancers :**\n\n1. **L4 (Transport - TCP/UDP) :**\n   - Basé sur IP/ports\n   - Rapide, simple\n\n2. **L7 (Application - HTTP) :**\n   - Analyse du contenu (headers, cookies)\n   - Routing intelligent\n\n**Algorithmes :**\n\n| Algorithme | Description |\n|---|---|\n| **Round Robin** | Rotation séquentielle |\n| **Least Connections** | Vers le serveur le moins chargé |\n| **IP Hash** | Basé sur l'IP client (sticky) |\n| **Weighted** | Selon la capacité du serveur |\n| **Random** | Distribution aléatoire |\n\n**Configuration Nginx :**\n```nginx\nupstream backend {\n    least_conn;\n    server backend1:8080 weight=3;\n    server backend2:8080;\n    server backend3:8080 backup;\n}\n\nserver {\n    location / {\n        proxy_pass http://backend;\n    }\n}\n```\n\n**Fonctionnalités avancées :**\n- **Health checks** : détection serveurs défaillants\n- **SSL termination** : décryptage centralisé\n- **Session persistence** : sticky sessions"}
{"input": "Qu'est-ce que le Domain-Driven Design (DDD) ?", "target": "**DDD** aligne le code sur le domaine métier :\n\n**Concepts stratégiques :**\n\n1. **Ubiquitous Language :**\n   - Vocabulaire **partagé** tech/métier\n   - Utilisé dans le code et les discussions\n\n2. **Bounded Context :**\n   - Limite où un modèle est valide\n   - Ex: \"Client\" différent en vente vs support\n\n3. **Context Map :**\n   - Relations entre bounded contexts\n\n**Concepts tactiques :**\n\n1. **Entity** :\n   - Identité unique, cycle de vie\n```python\nclass Order:\n    def __init__(self, order_id: OrderId):\n        self.id = order_id\n```\n\n2. **Value Object** :\n   - Immutable, égalité par valeur\n```python\n@dataclass(frozen=True)\nclass Money:\n    amount: Decimal\n    currency: str\n```\n\n3. **Aggregate** :\n   - Groupe d'entités avec une **racine**\n   - Invariants garantis\n\n4. **Repository** :\n   - Abstraction de la persistance\n\n5. **Domain Event** :\n   - Fait métier important"}
{"input": "Explique le concept de Serverless.", "target": "**Serverless** exécute du code sans gérer de serveurs :\n\n**Caractéristiques :**\n- **Pas de gestion** d'infrastructure\n- Facturation à l'**usage** (pay-per-invocation)\n- **Scaling automatique** (0 → ∞)\n- Exécution **éphémère**\n\n**Types de services serverless :**\n\n1. **FaaS (Functions as a Service) :**\n   - AWS Lambda, Azure Functions, Cloud Functions\n```python\n# AWS Lambda\ndef handler(event, context):\n    return {\n        'statusCode': 200,\n        'body': json.dumps({'message': 'Hello!'})\n    }\n```\n\n2. **BaaS (Backend as a Service) :**\n   - Firebase, Supabase\n   - Auth, DB, Storage gérés\n\n**Avantages :**\n- **Coût** réduit (pas de serveur idle)\n- **Scalabilité** automatique\n- Focus sur le **code métier**\n\n**Limites :**\n- **Cold start** : latence au démarrage\n- Durée d'exécution limitée\n- **Vendor lock-in**\n- Debugging complexe\n\n**Cas d'usage :**\n- APIs légères, webhooks\n- Traitement d'événements\n- Tâches planifiées (cron)"}
{"input": "Comment implémenter une API RESTful correctement ?", "target": "Une **API RESTful** bien conçue suit des conventions précises :\n\n**Principes REST :**\n1. **Stateless** : pas d'état serveur entre requêtes\n2. **Resources** : URLs représentent des ressources\n3. **Méthodes HTTP** : sémantique claire\n\n**Conventions d'URL :**\n```\nGET    /users          # Liste\nGET    /users/123      # Détail\nPOST   /users          # Création\nPUT    /users/123      # Mise à jour complète\nPATCH  /users/123      # Mise à jour partielle\nDELETE /users/123      # Suppression\n\n# Relations\nGET /users/123/orders\n```\n\n**Codes HTTP :**\n\n| Code | Signification |\n|---|---|\n| 200 | OK |\n| 201 | Created |\n| 204 | No Content |\n| 400 | Bad Request |\n| 401 | Unauthorized |\n| 403 | Forbidden |\n| 404 | Not Found |\n| 500 | Server Error |\n\n**Bonnes pratiques :**\n- **Versionning** : `/api/v1/users`\n- **Pagination** : `?page=1&limit=20`\n- **Filtrage** : `?status=active`\n- **HATEOAS** : liens vers actions possibles"}
{"input": "Qu'est-ce que le pattern Repository ?", "target": "Le **Repository pattern** abstrait l'accès aux données :\n\n**Principe :**\n- Interface entre **domaine** et **persistence**\n- Le domaine ne connaît pas la base de données\n\n**Interface Repository :**\n```python\nfrom abc import ABC, abstractmethod\n\nclass UserRepository(ABC):\n    @abstractmethod\n    def get_by_id(self, user_id: str) -> User:\n        pass\n    \n    @abstractmethod\n    def save(self, user: User) -> None:\n        pass\n    \n    @abstractmethod\n    def delete(self, user_id: str) -> None:\n        pass\n```\n\n**Implémentation concrète :**\n```python\nclass SQLUserRepository(UserRepository):\n    def __init__(self, session: Session):\n        self.session = session\n    \n    def get_by_id(self, user_id: str) -> User:\n        return self.session.query(UserModel)\\\n            .filter_by(id=user_id).first()\n    \n    def save(self, user: User) -> None:\n        self.session.add(user)\n        self.session.commit()\n```\n\n**Avantages :**\n- **Testabilité** : mock facile\n- **Changement de DB** : seul le repo change\n- **Centralisation** : logique de requête en un lieu"}
{"input": "Explique le concept de rate limiting.", "target": "Le **rate limiting** protège les APIs contre les abus :\n\n**Objectifs :**\n- Prévenir les **attaques DDoS**\n- Garantir **équité** entre utilisateurs\n- Protéger les **ressources** serveur\n\n**Algorithmes courants :**\n\n1. **Fixed Window :**\n   - X requêtes par fenêtre de temps\n   - Simple mais pics possibles aux frontières\n\n2. **Sliding Window :**\n   - Fenêtre glissante\n   - Plus fluide\n\n3. **Token Bucket :**\n   - Jetons ajoutés à rythme constant\n   - Permet des **bursts** contrôlés\n\n4. **Leaky Bucket :**\n   - Débit de sortie **constant**\n   - Lisse le trafic\n\n**Implémentation Redis :**\n```python\ndef is_rate_limited(user_id: str, limit: int = 100):\n    key = f\"rate:{user_id}:{int(time.time())//60}\"\n    current = redis.incr(key)\n    redis.expire(key, 60)\n    return current > limit\n```\n\n**Headers standard :**\n```\nX-RateLimit-Limit: 100\nX-RateLimit-Remaining: 42\nX-RateLimit-Reset: 1640000000\n```\n\n**HTTP 429** : Too Many Requests"}
{"input": "Comment fonctionne le sharding de base de données ?", "target": "Le **sharding** distribue les données sur plusieurs serveurs :\n\n**Principe :**\n- **Partitionnement horizontal**\n- Chaque shard contient un sous-ensemble des données\n- Scaling **quasi-linéaire**\n\n**Stratégies de sharding :**\n\n1. **Range-based :**\n```\nShard 1: users A-M\nShard 2: users N-Z\n```\n   - Risque : hot spots\n\n2. **Hash-based :**\n```python\nshard_id = hash(user_id) % num_shards\n```\n   - Distribution uniforme\n   - Répartition difficile à prédire\n\n3. **Directory-based :**\n   - Table de mapping\n   - Flexibilité maximale\n\n4. **Géographique :**\n   - Données proches des utilisateurs\n\n**Défis :**\n- **Joins cross-shard** : complexes/impossibles\n- **Transactions** : SAGA pattern\n- **Resharding** : redistribution coûteuse\n- **Hotspots** : certains shards surchargés\n\n**Solutions :**\n- **Consistent hashing** : minimise le resharding\n- **Virtual shards** : flexibilité\n\n**Bases pré-shardées :**\n- MongoDB, Cassandra, CockroachDB, Vitess"}
{"input": "Qu'est-ce que le monitoring et l'observabilité ?", "target": "L'**observabilité** comprend l'état interne d'un système via ses outputs :\n\n**Les 3 piliers :**\n\n1. **Logs :**\n   - Événements discrets horodatés\n```python\nlogger.info(\"User login\", extra={\n    \"user_id\": \"123\",\n    \"ip\": \"192.168.1.1\"\n})\n```\n   - Outils : ELK Stack, Loki\n\n2. **Metrics :**\n   - Valeurs numériques agrégées\n```python\nhttp_requests_total.labels(\n    method=\"GET\",\n    endpoint=\"/api/users\"\n).inc()\n```\n   - Outils : Prometheus, Grafana\n\n3. **Traces :**\n   - Suivi des requêtes distribuées\n   - Span → Trace\n   - Outils : Jaeger, Zipkin, OpenTelemetry\n\n**Métriques clés (RED/USE) :**\n\n**RED (services) :**\n- **R**ate : requêtes/seconde\n- **E**rrors : taux d'erreur\n- **D**uration : latence\n\n**USE (infrastructure) :**\n- **U**tilization : CPU, mémoire\n- **S**aturation : files d'attente\n- **E**rrors : erreurs matérielles\n\n**Alerting :**\n- Définir des **SLOs** (Service Level Objectives)\n- Alertes basées sur **symptoms**, pas causes"}
{"input": "Explique les design patterns créationnels.", "target": "Les **patterns créationnels** gèrent la création d'objets :\n\n**1. Singleton :**\n- Une seule instance globale\n```python\nclass Singleton:\n    _instance = None\n    \n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n        return cls._instance\n```\n\n**2. Factory Method :**\n- Délègue la création aux sous-classes\n```python\nclass Creator(ABC):\n    @abstractmethod\n    def create_product(self) -> Product:\n        pass\n```\n\n**3. Abstract Factory :**\n- Familles d'objets liés\n```python\nclass GUIFactory(ABC):\n    def create_button(self) -> Button: pass\n    def create_checkbox(self) -> Checkbox: pass\n```\n\n**4. Builder :**\n- Construction étape par étape\n```python\nuser = UserBuilder()\\\n    .with_name(\"Alice\")\\\n    .with_email(\"alice@example.com\")\\\n    .with_role(\"admin\")\\\n    .build()\n```\n\n**5. Prototype :**\n- Clonage d'objets existants\n```python\nfrom copy import deepcopy\nnew_config = deepcopy(default_config)\n```\n\n**Quand les utiliser :**\n- Singleton : configuration, logging\n- Factory : création polymorphique\n- Builder : objets complexes\n- Prototype : objets coûteux à créer"}
{"input": "Comment fonctionne le message queuing avec RabbitMQ ?", "target": "**RabbitMQ** est un broker de messages AMQP :\n\n**Concepts clés :**\n\n1. **Producer** : envoie des messages\n2. **Queue** : stocke les messages\n3. **Consumer** : traite les messages\n4. **Exchange** : route les messages\n\n**Types d'Exchange :**\n\n| Type | Routing |\n|---|---|\n| **Direct** | Par routing key exacte |\n| **Fanout** | Broadcast à toutes les queues |\n| **Topic** | Pattern matching (`logs.*`) |\n| **Headers** | Basé sur les headers |\n\n**Exemple Python (pika) :**\n```python\nimport pika\n\n# Producer\nconnection = pika.BlockingConnection()\nchannel = connection.channel()\nchannel.queue_declare(queue='tasks')\nchannel.basic_publish(\n    exchange='',\n    routing_key='tasks',\n    body='Hello World!'\n)\n\n# Consumer\ndef callback(ch, method, props, body):\n    print(f\"Received: {body}\")\n    ch.basic_ack(delivery_tag=method.delivery_tag)\n\nchannel.basic_consume(queue='tasks', on_message_callback=callback)\nchannel.start_consuming()\n```\n\n**Garanties :**\n- **Durability** : messages persistés sur disque\n- **Acknowledgment** : confirmation de traitement\n- **Prefetch** : contrôle du débit"}
{"input": "Qu'est-ce que le Blue-Green Deployment ?", "target": "Le **Blue-Green Deployment** minimise les risques de déploiement :\n\n**Principe :**\n- **Deux environnements** identiques : Blue et Green\n- Un seul actif à la fois\n- Bascule instantanée\n\n**Processus :**\n```\n1. Blue = Production (actif)\n   Green = Idle\n\n2. Déployer nouvelle version sur Green\n\n3. Tester Green (smoke tests)\n\n4. Basculer le load balancer vers Green\n   Blue ← Green (nouveau actif)\n\n5. Blue devient le backup/rollback\n```\n\n**Avantages :**\n- **Zero downtime**\n- **Rollback instantané** : rebascule vers Blue\n- **Tests** en conditions réelles\n\n**Inconvénients :**\n- **Coût** : double infrastructure\n- **Base de données** : migrations complexes\n- **Sessions** : gestion de l'état\n\n**Alternatives :**\n\n| Stratégie | Description |\n|---|---|\n| **Canary** | Déploiement progressif (1% → 100%) |\n| **Rolling** | Mise à jour serveur par serveur |\n| **A/B Testing** | Variantes pour expérimentation |\n\n**Outils :**\n- Kubernetes, AWS CodeDeploy, Spinnaker"}
{"input": "Explique le concept de Twelve-Factor App.", "target": "La méthodologie **Twelve-Factor App** définit les bonnes pratiques pour les apps cloud :\n\n**Les 12 facteurs :**\n\n1. **Codebase** :\n   - Un repo = une app\n   - Déploiements multiples depuis la même base\n\n2. **Dependencies** :\n   - Déclaration explicite (requirements.txt, package.json)\n   - Isolation des dépendances\n\n3. **Config** :\n   - Configuration via **variables d'environnement**\n   - Séparation code/config\n\n4. **Backing Services** :\n   - DB, cache, queues = ressources attachables\n   - Changement sans modification du code\n\n5. **Build, Release, Run** :\n   - Étapes strictement séparées\n\n6. **Processes** :\n   - **Stateless** : pas d'état local\n   - Données persistantes externalisées\n\n7. **Port Binding** :\n   - App auto-hébergée via port\n\n8. **Concurrency** :\n   - Scale via processus multiples\n\n9. **Disposability** :\n   - Démarrage rapide, arrêt gracieux\n\n10. **Dev/Prod Parity** :\n    - Environnements similaires\n\n11. **Logs** :\n    - Flux d'événements vers stdout\n\n12. **Admin Processes** :\n    - Tâches one-off dans le même environnement"}
{"input": "Comment sécuriser une application web ?", "target": "La **sécurité web** suit le principe de défense en profondeur :\n\n**OWASP Top 10 :**\n\n1. **Injection (SQL, XSS)** :\n```python\n# ❌ Vulnérable\nquery = f\"SELECT * FROM users WHERE id = {user_input}\"\n\n# ✅ Paramétré\ncursor.execute(\"SELECT * FROM users WHERE id = ?\", (user_input,))\n```\n\n2. **Broken Authentication** :\n   - MFA, rate limiting, sessions sécurisées\n\n3. **Sensitive Data Exposure** :\n   - HTTPS obligatoire, encryption at rest\n\n4. **XXE** :\n   - Désactiver les entités XML externes\n\n5. **Broken Access Control** :\n   - Vérification côté serveur systématique\n\n**Headers de sécurité :**\n```python\nresponse.headers['X-Content-Type-Options'] = 'nosniff'\nresponse.headers['X-Frame-Options'] = 'DENY'\nresponse.headers['Content-Security-Policy'] = \"default-src 'self'\"\nresponse.headers['Strict-Transport-Security'] = 'max-age=31536000'\n```\n\n**Bonnes pratiques :**\n- **Validation** : côté serveur toujours\n- **CSRF tokens** : formulaires protégés\n- **Rate limiting** : protection DDoS\n- **Dependency scanning** : vulnérabilités connues\n- **Secrets management** : pas de secrets dans le code"}
{"input": "Qu'est-ce que la programmation réactive ?", "target": "La **programmation réactive** gère les flux de données asynchrones :\n\n**Concepts clés :**\n- **Observable** : source de données\n- **Observer** : consommateur\n- **Operators** : transformations\n- **Subscription** : lien observable-observer\n\n**Principes :**\n- **Propagation automatique** des changements\n- **Non-bloquant** et **asynchrone**\n- **Backpressure** : gestion de la surcharge\n\n**Exemple RxPY :**\n```python\nfrom rx import of, operators as ops\n\nof(1, 2, 3, 4, 5).pipe(\n    ops.filter(lambda x: x % 2 == 0),\n    ops.map(lambda x: x * 10)\n).subscribe(print)\n# Output: 20, 40\n```\n\n**Opérateurs courants :**\n- **map** : transformation\n- **filter** : filtrage\n- **merge** : combinaison de streams\n- **debounce** : rate limiting\n- **retry** : gestion d'erreurs\n\n**Manifeste Réactif :**\n- **Responsive** : temps de réponse constant\n- **Resilient** : tolérance aux pannes\n- **Elastic** : adaptation à la charge\n- **Message-driven** : communication asynchrone\n\n**Frameworks :**\n- RxJS, RxPY, Project Reactor, Akka Streams"}
{"input": "Qu'est-ce qu'une API Gateway.", "target": "L'**API Gateway** est le point d'entrée unique pour les APIs :\n\n**Fonctions principales :**\n\n1. **Routing** :\n   - Dirige vers le bon microservice\n```\n/users/* → User Service\n/orders/* → Order Service\n```\n\n2. **Authentification/Autorisation** :\n   - Validation JWT centralisée\n   - OAuth2 / OIDC\n\n3. **Rate Limiting** :\n   - Protection contre les abus\n   - Quotas par API/utilisateur\n\n4. **Transformation** :\n   - Request/response modification\n   - Protocol translation (REST ↔ gRPC)\n\n5. **Load Balancing** :\n   - Distribution du trafic\n\n6. **Caching** :\n   - Réponses fréquentes en cache\n\n7. **Monitoring** :\n   - Logs, métriques, traces centralisés\n\n**Solutions populaires :**\n\n| Solution | Type |\n|---|---|\n| Kong | Open Source |\n| AWS API Gateway | Cloud managed |\n| Apigee | Enterprise |\n| Traefik | Cloud native |\n| NGINX | Load balancer + gateway |\n\n**Pattern BFF (Backend for Frontend) :**\n- Gateway spécifique par type de client\n- Mobile API ≠ Web API"}
{"input": "Comment implémenter la pagination efficacement ?", "target": "La **pagination** optimise le chargement de grandes listes :\n\n**Types de pagination :**\n\n1. **Offset-based :**\n```sql\nSELECT * FROM users\nORDER BY created_at\nLIMIT 20 OFFSET 40  -- Page 3\n```\n- ✅ Simple, accès à n'importe quelle page\n- ❌ Performance dégradée sur grandes tables\n- ❌ Inconsistant si données modifiées\n\n2. **Cursor-based (keyset) :**\n```sql\nSELECT * FROM users\nWHERE created_at > '2024-01-15 10:30:00'\nORDER BY created_at\nLIMIT 20\n```\n- ✅ Performance constante\n- ✅ Consistant\n- ❌ Pas d'accès direct à une page\n\n**API Response :**\n```json\n{\n  \"data\": [...],\n  \"pagination\": {\n    \"total\": 1000,\n    \"page\": 3,\n    \"per_page\": 20,\n    \"next_cursor\": \"eyJpZCI6MTIzfQ==\",\n    \"has_more\": true\n  },\n  \"links\": {\n    \"next\": \"/users?cursor=eyJpZCI6MTIzfQ==\",\n    \"prev\": \"/users?cursor=eyJpZCI6MTAzfQ==\"\n  }\n}\n```\n\n**Recommandation :**\n- Petites tables : **offset**\n- Grandes tables / temps réel : **cursor**"}
{"input": "Qu'est-ce que le feature flagging ?", "target": "Le **feature flagging** contrôle dynamiquement les fonctionnalités :\n\n**Principe :**\n- Activer/désactiver des features **sans déploiement**\n- Code présent mais caché derrière un flag\n\n**Types de flags :**\n\n1. **Release flags** :\n   - Déploiement progressif\n   - Trunk-based development\n\n2. **Experiment flags** :\n   - A/B testing\n   - Mesure d'impact\n\n3. **Ops flags** :\n   - Circuit breakers\n   - Kill switches\n\n4. **Permission flags** :\n   - Features premium/beta\n\n**Implémentation :**\n```python\nfrom feature_flags import FeatureFlags\n\nflags = FeatureFlags()\n\nif flags.is_enabled('new_checkout', user_id=user.id):\n    return new_checkout_flow()\nelse:\n    return legacy_checkout()\n```\n\n**Règles de ciblage :**\n```yaml\nnew_checkout:\n  enabled: true\n  rules:\n    - attribute: country\n      operator: in\n      values: [\"FR\", \"US\"]\n    - attribute: user_percentage\n      value: 10\n```\n\n**Outils :**\n- LaunchDarkly, Unleash, Flipper, ConfigCat\n\n**Bonnes pratiques :**\n- Nettoyer les flags obsolètes\n- Limiter le nombre de flags actifs"}
{"input": "Explique le concept de Data Lake vs Data Warehouse.", "target": "**Data Lake** et **Data Warehouse** servent des besoins différents :\n\n**Data Warehouse :**\n- Données **structurées** et **traitées**\n- Schéma défini à l'avance (**schema-on-write**)\n- Optimisé pour **BI et reporting**\n- SQL comme langage principal\n\n**Data Lake :**\n- Données **brutes** (tous formats)\n- Schéma appliqué à la lecture (**schema-on-read**)\n- Stockage **économique** (object storage)\n- Flexibilité maximale\n\n**Comparaison :**\n\n| Aspect | Data Warehouse | Data Lake |\n|---|---|---|\n| **Données** | Structurées | Toutes (raw) |\n| **Schéma** | Schema-on-write | Schema-on-read |\n| **Utilisateurs** | Analystes BI | Data Scientists |\n| **Coût** | Élevé | Faible |\n| **Performance** | Optimisée | Variable |\n| **Qualité** | Haute | Variable |\n\n**Lakehouse (hybride) :**\n- Combine les deux approches\n- Delta Lake, Iceberg, Hudi\n- ACID sur data lake\n\n**Architecture moderne :**\n```\nSources → Data Lake (raw) → ETL → Data Warehouse (curated)\n                ↓\n         ML/Data Science\n```"}
{"input": "Comment fonctionne le protocole gRPC ?", "target": "**gRPC** est un framework RPC haute performance de Google :\n\n**Caractéristiques :**\n- Basé sur **HTTP/2** (multiplexage, streaming)\n- Sérialisation **Protocol Buffers** (binaire)\n- **Code generation** multi-langages\n- Communication **bidirectionnelle**\n\n**Définition du service (.proto) :**\n```protobuf\nsyntax = \"proto3\";\n\nservice UserService {\n  rpc GetUser(GetUserRequest) returns (User);\n  rpc ListUsers(ListUsersRequest) returns (stream User);\n  rpc Chat(stream Message) returns (stream Message);\n}\n\nmessage User {\n  string id = 1;\n  string name = 2;\n  string email = 3;\n}\n```\n\n**Types de RPC :**\n\n| Type | Description |\n|---|---|\n| Unary | Request-response simple |\n| Server streaming | Réponse en flux |\n| Client streaming | Requête en flux |\n| Bidirectional | Flux dans les deux sens |\n\n**vs REST :**\n\n| gRPC | REST |\n|---|---|\n| Binaire (Protobuf) | Texte (JSON) |\n| Fortement typé | Faiblement typé |\n| HTTP/2 | HTTP/1.1+ |\n| Code généré | OpenAPI optionnel |\n\n**Cas d'usage :**\n- Microservices internes\n- Temps réel, IoT\n- Mobile (efficace en bande passante)"}
